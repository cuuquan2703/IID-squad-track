{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26483d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\\n"
     ]
    }
   ],
   "source": [
    "%cd G:\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c332faef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\MachineLearning\\QAsystem\n"
     ]
    }
   ],
   "source": [
    "%cd MachineLearning/QAsystem/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042c48e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\MachineLearning\\\\QAsystem'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b244c2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\MachineLearning\\QAsystem\\squad\n"
     ]
    }
   ],
   "source": [
    "%cd squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e83a6ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive G is New Volume\n",
      " Volume Serial Number is 26DB-12C9\n",
      "\n",
      " Directory of G:\\MachineLearning\\QAsystem\\squad\n",
      "\n",
      "04/05/2023  03:13 AM    <DIR>          .\n",
      "04/03/2023  08:58 PM    <DIR>          ..\n",
      "03/29/2023  01:35 PM                45 .gitignore\n",
      "04/04/2023  05:26 AM    <DIR>          __pycache__\n",
      "03/29/2023  01:35 PM            10,164 args.py\n",
      "04/03/2023  08:59 PM    <DIR>          data\n",
      "04/05/2023  02:36 AM        34,407,442 dev.csv\n",
      "04/05/2023  02:36 AM        17,318,343 dev_untokenize.csv\n",
      "04/05/2023  03:19 AM         5,510,814 dev10k.npz\n",
      "04/05/2023  03:19 AM         5,510,814 dev20k.npz\n",
      "04/05/2023  03:19 AM         5,510,814 dev30k.npz\n",
      "04/05/2023  03:19 AM         5,510,814 dev40k.npz\n",
      "03/29/2023  01:35 PM               254 environment.yml\n",
      "03/29/2023  01:35 PM             9,190 layers.py\n",
      "03/29/2023  01:35 PM             1,121 LICENSE\n",
      "03/29/2023  01:35 PM             2,918 models.py\n",
      "03/29/2023  01:35 PM             1,380 README.md\n",
      "04/03/2023  08:59 PM    <DIR>          save\n",
      "03/29/2023  01:35 PM            15,622 setup.py\n",
      "04/05/2023  02:36 AM        30,607,861 test.csv\n",
      "03/29/2023  01:35 PM             5,277 test.py\n",
      "04/05/2023  02:36 AM        15,181,563 test_untokenize.csv\n",
      "04/05/2023  02:37 AM       659,326,440 train.csv\n",
      "03/29/2023  01:35 PM             8,057 train.py\n",
      "04/05/2023  02:39 AM        99,891,786 train_untokenize.csv\n",
      "04/05/2023  03:17 AM        36,759,046 train10k.npz\n",
      "04/05/2023  03:17 AM        59,569,618 train20k.npz\n",
      "04/05/2023  03:17 AM        74,561,523 train30k.npz\n",
      "04/05/2023  03:17 AM        85,053,899 train40k.npz\n",
      "03/29/2023  01:35 PM            27,087 util.py\n",
      "              25 File(s)  1,134,801,892 bytes\n",
      "               5 Dir(s)  968,997,552,128 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0836933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda3\\envs\\MachineLeanring\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import json\n",
    "from collections import Counter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c34c9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_idx(text, tokens):\n",
    "    current = 0\n",
    "    spans = []\n",
    "    for token in tokens:\n",
    "        current = text.find(token, current)\n",
    "        if current < 0:\n",
    "            print(f\"Token {token} cannot be found\")\n",
    "            raise Exception()\n",
    "        spans.append((current, current + len(token)))\n",
    "        current += len(token)\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "824f29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "def word_tokenize(sent):\n",
    "    doc = nlp(sent)\n",
    "    return [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25e1535f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process(inn,data_type,word_counter, char_counter):\n",
    "\n",
    "    # writer = csv.writer(csvfile)\n",
    "    # writer.writerow([\"context\",\"question\",\"spans\",\"answers\",\"uuid\"])\n",
    "    print(f\"Pre-processing {data_type} examples...\")\n",
    "    examples = []\n",
    "    eval_examples = {}\n",
    "    total = 0\n",
    "    with open(inn,\"r\") as fh:\n",
    "        source = json.load(fh)\n",
    "        for article in tqdm(source[\"data\"]):\n",
    "                for para in article[\"paragraphs\"]:\n",
    "                    context = para[\"context\"].replace(\n",
    "                        \"''\", '\" ').replace(\"``\", '\" ')\n",
    "                    context_tokens = word_tokenize(context)\n",
    "                    context_chars = [list(token) for token in context_tokens]\n",
    "                    spans = convert_idx(context, context_tokens)\n",
    "                    for token in context_tokens:\n",
    "                        word_counter[token] += len(para[\"qas\"])\n",
    "                        for char in token:\n",
    "                            char_counter[char] += len(para[\"qas\"])\n",
    "                    for qa in para[\"qas\"]:\n",
    "                        total += 1\n",
    "                        ques = qa[\"question\"].replace(\n",
    "                            \"''\", '\" ').replace(\"``\", '\" ')\n",
    "                        ques_tokens = word_tokenize(ques)\n",
    "                        ques_chars = [list(token) for token in ques_tokens]\n",
    "                        for token in ques_tokens:\n",
    "                            word_counter[token] += 1\n",
    "                            for char in token:\n",
    "                                char_counter[char] += 1\n",
    "                        y1s, y2s = [], []\n",
    "                        answer_texts = []\n",
    "                        for answer in qa[\"answers\"]:\n",
    "                            answer_text = answer[\"text\"]\n",
    "                            answer_start = answer['answer_start']\n",
    "                            answer_end = answer_start + len(answer_text)\n",
    "                            answer_texts.append(answer_text)\n",
    "                            answer_span = []\n",
    "                            for idx, span in enumerate(spans):\n",
    "                                if not (answer_end <= span[0] or answer_start >= span[1]):\n",
    "                                    answer_span.append(idx)\n",
    "                            y1, y2 = answer_span[0], answer_span[-1]\n",
    "                            y1s.append(y1)\n",
    "                            y2s.append(y2)\n",
    "                        example = {\"context_tokens\": context_tokens,\n",
    "                                   \"context_chars\": context_chars,\n",
    "                                   \"ques_tokens\": ques_tokens,\n",
    "                                   \"ques_chars\": ques_chars,\n",
    "                                   \"y1s\": y1s,\n",
    "                                   \"y2s\": y2s,\n",
    "                                   \"id\": total}\n",
    "                        examples.append(example)\n",
    "                        eval_examples[str(total)] = {\"context\": context,\n",
    "                                                     \"question\": ques,\n",
    "                                                     \"spans\": spans,\n",
    "                                                     \"answers\": answer_texts,\n",
    "                                                     \"uuid\": qa[\"id\"]}\n",
    "    return examples,eval_examples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24074594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.23it/s]\n"
     ]
    }
   ],
   "source": [
    "test, untokenize_test = process('./data/test-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e0586ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 10.48it/s]\n"
     ]
    }
   ],
   "source": [
    "dev, untokenize_dev = process('./data/dev-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "432301d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:40<00:00, 10.87it/s]\n"
     ]
    }
   ],
   "source": [
    "train,untokenize_train = process('./data/train-v2.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7d92be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev1 = pd.DataFrame(dev)\n",
    "untokenize_dev1 = pd.DataFrame(untokenize_dev)\n",
    "\n",
    "test1 = pd.DataFrame(test)\n",
    "untokenize_test1 = pd.DataFrame(untokenize_test)\n",
    "\n",
    "train1 = pd.DataFrame(train)\n",
    "untokenize_train1 = pd.DataFrame(untokenize_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6f1ba621",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m untokenize_test\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_untokenize.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m train\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43muntokenize_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_untokenize.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\anaconda3\\envs\\MachineLeanring\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mG:\\anaconda3\\envs\\MachineLeanring\\lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3725\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\anaconda3\\envs\\MachineLeanring\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mG:\\anaconda3\\envs\\MachineLeanring\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mG:\\anaconda3\\envs\\MachineLeanring\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:261\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[1;32m--> 261\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\anaconda3\\envs\\MachineLeanring\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:266\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\anaconda3\\envs\\MachineLeanring\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:304\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\anaconda3\\envs\\MachineLeanring\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:315\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    312\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[0;32m    314\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[1;32m--> 315\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\anaconda3\\envs\\MachineLeanring\\lib\\site-packages\\pandas\\_libs\\writers.pyx:75\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dev.to_csv('dev.csv',index=False)\n",
    "untokenize_dev.to_csv('dev_untokenize.csv',index=False)\n",
    "\n",
    "test.to_csv('test.csv',index=False)\n",
    "untokenize_test.to_csv('test_untokenize.csv',index=False)\n",
    "\n",
    "train.to_csv('train.csv',index=False)\n",
    "untokenize_train.to_csv('train_untokenize.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "599a6bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_tokens</th>\n",
       "      <th>context_chars</th>\n",
       "      <th>ques_tokens</th>\n",
       "      <th>ques_chars</th>\n",
       "      <th>y1s</th>\n",
       "      <th>y2s</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>[A, simple, case, of, dynamic, equilibrium, oc...</td>\n",
       "      <td>[[A], [s, i, m, p, l, e], [c, a, s, e], [o, f]...</td>\n",
       "      <td>[What, has, to, accounted, for, that, causes, ...</td>\n",
       "      <td>[[W, h, a, t], [h, a, s], [t, o], [a, c, c, o,...</td>\n",
       "      <td>[88, 53, 88, 88]</td>\n",
       "      <td>[89, 60, 89, 89]</td>\n",
       "      <td>5851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>[The, success, of, any, pathogen, depends, on,...</td>\n",
       "      <td>[[T, h, e], [s, u, c, c, e, s, s], [o, f], [a,...</td>\n",
       "      <td>[In, a, type, III, secretion, system, ,, prote...</td>\n",
       "      <td>[[I, n], [a], [t, y, p, e], [I, I, I], [s, e, ...</td>\n",
       "      <td>[105, 105, 105]</td>\n",
       "      <td>[108, 108, 109]</td>\n",
       "      <td>3544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5713</th>\n",
       "      <td>[With, modern, insights, into, quantum, mechan...</td>\n",
       "      <td>[[W, i, t, h], [m, o, d, e, r, n], [i, n, s, i...</td>\n",
       "      <td>[What, is, the, strongest, main, interaction, ?]</td>\n",
       "      <td>[[W, h, a, t], [i, s], [t, h, e], [s, t, r, o,...</td>\n",
       "      <td>[73, 73, 73, 73, 73, 73]</td>\n",
       "      <td>[73, 73, 74, 73, 73, 75]</td>\n",
       "      <td>5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>[The, French, population, numbered, about, 75,...</td>\n",
       "      <td>[[T, h, e], [F, r, e, n, c, h], [p, o, p, u, l...</td>\n",
       "      <td>[Where, did, French, fur, trappers, travel, ?]</td>\n",
       "      <td>[[W, h, e, r, e], [d, i, d], [F, r, e, n, c, h...</td>\n",
       "      <td>[88, 88, 86, 88, 87]</td>\n",
       "      <td>[104, 92, 92, 91, 92]</td>\n",
       "      <td>5364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>[Disorders, of, the, immune, system, can, resu...</td>\n",
       "      <td>[[D, i, s, o, r, d, e, r, s], [o, f], [t, h, e...</td>\n",
       "      <td>[What, kind, of, medicine, can, cause, autoimm...</td>\n",
       "      <td>[[W, h, a, t], [k, i, n, d], [o, f], [m, e, d,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3842</th>\n",
       "      <td>[The, Presiding, Officer, (, or, Deputy, Presi...</td>\n",
       "      <td>[[T, h, e], [P, r, e, s, i, d, i, n, g], [O, f...</td>\n",
       "      <td>[What, members, typically, open, debates, ?]</td>\n",
       "      <td>[[W, h, a, t], [m, e, m, b, e, r, s], [t, y, p...</td>\n",
       "      <td>[52, 52, 52]</td>\n",
       "      <td>[55, 55, 55]</td>\n",
       "      <td>3843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>[For, the, complexity, classes, defined, in, t...</td>\n",
       "      <td>[[F, o, r], [t, h, e], [c, o, m, p, l, e, x, i...</td>\n",
       "      <td>[In, what, expression, can, one, expect, to, f...</td>\n",
       "      <td>[[I, n], [w, h, a, t], [e, x, p, r, e, s, s, i...</td>\n",
       "      <td>[41, 41, 41]</td>\n",
       "      <td>[42, 42, 42]</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5812</th>\n",
       "      <td>[Historically, ,, forces, were, first, quantit...</td>\n",
       "      <td>[[H, i, s, t, o, r, i, c, a, l, l, y], [,], [f...</td>\n",
       "      <td>[What, must, be, specified, in, order, to, acc...</td>\n",
       "      <td>[[W, h, a, t], [m, u, s, t], [b, e], [s, p, e,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>[where,  , is, the, mass, of, the, object, ,, ...</td>\n",
       "      <td>[[w, h, e, r, e], [ ], [i, s], [t, h, e], [m, ...</td>\n",
       "      <td>[What, is, another, word, for, centripetal, fo...</td>\n",
       "      <td>[[W, h, a, t], [i, s], [a, n, o, t, h, e, r], ...</td>\n",
       "      <td>[160, 160, 160, 160]</td>\n",
       "      <td>[160, 164, 160, 160]</td>\n",
       "      <td>6038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517</th>\n",
       "      <td>[An, early, important, political, response, to...</td>\n",
       "      <td>[[A, n], [e, a, r, l, y], [i, m, p, o, r, t, a...</td>\n",
       "      <td>[What, political, response, was, convening, in...</td>\n",
       "      <td>[[W, h, a, t], [p, o, l, i, t, i, c, a, l], [r...</td>\n",
       "      <td>[15, 15, 6, 15, 15]</td>\n",
       "      <td>[16, 16, 9, 16, 16]</td>\n",
       "      <td>5518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6078 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         context_tokens  \\\n",
       "5850  [A, simple, case, of, dynamic, equilibrium, oc...   \n",
       "3543  [The, success, of, any, pathogen, depends, on,...   \n",
       "5713  [With, modern, insights, into, quantum, mechan...   \n",
       "5363  [The, French, population, numbered, about, 75,...   \n",
       "3268  [Disorders, of, the, immune, system, can, resu...   \n",
       "...                                                 ...   \n",
       "3842  [The, Presiding, Officer, (, or, Deputy, Presi...   \n",
       "444   [For, the, complexity, classes, defined, in, t...   \n",
       "5812  [Historically, ,, forces, were, first, quantit...   \n",
       "6037  [where,  , is, the, mass, of, the, object, ,, ...   \n",
       "5517  [An, early, important, political, response, to...   \n",
       "\n",
       "                                          context_chars  \\\n",
       "5850  [[A], [s, i, m, p, l, e], [c, a, s, e], [o, f]...   \n",
       "3543  [[T, h, e], [s, u, c, c, e, s, s], [o, f], [a,...   \n",
       "5713  [[W, i, t, h], [m, o, d, e, r, n], [i, n, s, i...   \n",
       "5363  [[T, h, e], [F, r, e, n, c, h], [p, o, p, u, l...   \n",
       "3268  [[D, i, s, o, r, d, e, r, s], [o, f], [t, h, e...   \n",
       "...                                                 ...   \n",
       "3842  [[T, h, e], [P, r, e, s, i, d, i, n, g], [O, f...   \n",
       "444   [[F, o, r], [t, h, e], [c, o, m, p, l, e, x, i...   \n",
       "5812  [[H, i, s, t, o, r, i, c, a, l, l, y], [,], [f...   \n",
       "6037  [[w, h, e, r, e], [ ], [i, s], [t, h, e], [m, ...   \n",
       "5517  [[A, n], [e, a, r, l, y], [i, m, p, o, r, t, a...   \n",
       "\n",
       "                                            ques_tokens  \\\n",
       "5850  [What, has, to, accounted, for, that, causes, ...   \n",
       "3543  [In, a, type, III, secretion, system, ,, prote...   \n",
       "5713   [What, is, the, strongest, main, interaction, ?]   \n",
       "5363     [Where, did, French, fur, trappers, travel, ?]   \n",
       "3268  [What, kind, of, medicine, can, cause, autoimm...   \n",
       "...                                                 ...   \n",
       "3842       [What, members, typically, open, debates, ?]   \n",
       "444   [In, what, expression, can, one, expect, to, f...   \n",
       "5812  [What, must, be, specified, in, order, to, acc...   \n",
       "6037  [What, is, another, word, for, centripetal, fo...   \n",
       "5517  [What, political, response, was, convening, in...   \n",
       "\n",
       "                                             ques_chars  \\\n",
       "5850  [[W, h, a, t], [h, a, s], [t, o], [a, c, c, o,...   \n",
       "3543  [[I, n], [a], [t, y, p, e], [I, I, I], [s, e, ...   \n",
       "5713  [[W, h, a, t], [i, s], [t, h, e], [s, t, r, o,...   \n",
       "5363  [[W, h, e, r, e], [d, i, d], [F, r, e, n, c, h...   \n",
       "3268  [[W, h, a, t], [k, i, n, d], [o, f], [m, e, d,...   \n",
       "...                                                 ...   \n",
       "3842  [[W, h, a, t], [m, e, m, b, e, r, s], [t, y, p...   \n",
       "444   [[I, n], [w, h, a, t], [e, x, p, r, e, s, s, i...   \n",
       "5812  [[W, h, a, t], [m, u, s, t], [b, e], [s, p, e,...   \n",
       "6037  [[W, h, a, t], [i, s], [a, n, o, t, h, e, r], ...   \n",
       "5517  [[W, h, a, t], [p, o, l, i, t, i, c, a, l], [r...   \n",
       "\n",
       "                           y1s                       y2s    id  \n",
       "5850          [88, 53, 88, 88]          [89, 60, 89, 89]  5851  \n",
       "3543           [105, 105, 105]           [108, 108, 109]  3544  \n",
       "5713  [73, 73, 73, 73, 73, 73]  [73, 73, 74, 73, 73, 75]  5714  \n",
       "5363      [88, 88, 86, 88, 87]     [104, 92, 92, 91, 92]  5364  \n",
       "3268                        []                        []  3269  \n",
       "...                        ...                       ...   ...  \n",
       "3842              [52, 52, 52]              [55, 55, 55]  3843  \n",
       "444               [41, 41, 41]              [42, 42, 42]   445  \n",
       "5812                        []                        []  5813  \n",
       "6037      [160, 160, 160, 160]      [160, 164, 160, 160]  6038  \n",
       "5517       [15, 15, 6, 15, 15]       [16, 16, 9, 16, 16]  5518  \n",
       "\n",
       "[6078 rows x 7 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = dev.sample(frac=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1405abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_tokens = np.array(a['context_tokens'])\n",
    "context_chars = np.array(a['context_chars'])\n",
    "ques_tokens = np.array(a['ques_tokens'])\n",
    "ques_chars = np.array(a['ques_chars'])\n",
    "y1s = np.array(a['y1s'])\n",
    "y2s = np.array(a['y2s'])\n",
    "id = np.array(a['id'])\n",
    "\n",
    "np.savez('dev10k.npz',context_tokens=context_tokens[:10000],context_chars=context_chars[:10000],ques_tokens=ques_tokens[:10000],ques_chars=ques_chars[:10000],y1s=y1s[:10000],y2s=y2s[:10000],id=id[:10000])\n",
    "np.savez('dev20k.npz',context_tokens=context_tokens[:20000],context_chars=context_chars[:20000],ques_tokens=ques_tokens[:20000],ques_chars=ques_chars[:20000],y1s=y1s[:20000],y2s=y2s[:20000],id=id[:20000])\n",
    "np.savez('dev30k.npz',context_tokens=context_tokens[:30000],context_chars=context_chars[:30000],ques_tokens=ques_tokens[:30000],ques_chars=ques_chars[:30000],y1s=y1s[:30000],y2s=y2s[:30000],id=id[:30000])\n",
    "np.savez('dev40k.npz',context_tokens=context_tokens[:40000],context_chars=context_chars[:40000],ques_tokens=ques_tokens[:40000],ques_chars=ques_chars[:40000],y1s=y1s[:40000],y2s=y2s[:40000],id=id[:40000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "eba7146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_tokens</th>\n",
       "      <th>context_chars</th>\n",
       "      <th>ques_tokens</th>\n",
       "      <th>ques_chars</th>\n",
       "      <th>y1s</th>\n",
       "      <th>y2s</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64308</th>\n",
       "      <td>[Ann, Arbor, was, founded, in, 1824, by, land,...</td>\n",
       "      <td>[[A, n, n], [A, r, b, o, r], [w, a, s], [f, o,...</td>\n",
       "      <td>[What, were, the, names, of, the, founders, wi...</td>\n",
       "      <td>[[W, h, a, t], [w, e, r, e], [t, h, e], [n, a,...</td>\n",
       "      <td>[59]</td>\n",
       "      <td>[59]</td>\n",
       "      <td>64309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48735</th>\n",
       "      <td>[In, Alberta, ,, five, bitumen, upgraders, pro...</td>\n",
       "      <td>[[I, n], [A, l, b, e, r, t, a], [,], [f, i, v,...</td>\n",
       "      <td>[Where, is, the, Shell, Oil, upgrader, located...</td>\n",
       "      <td>[[W, h, e, r, e], [i, s], [t, h, e], [S, h, e,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>48736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100067</th>\n",
       "      <td>[The, concept, of, ', education, through, recr...</td>\n",
       "      <td>[[T, h, e], [c, o, n, c, e, p, t], [o, f], [']...</td>\n",
       "      <td>[Who, said,  , \", A, master, in, the, art, of,...</td>\n",
       "      <td>[[W, h, o], [s, a, i, d], [ ], [\"], [A], [m, a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>100068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123833</th>\n",
       "      <td>[From, the, early, 16th, century, ,, both, Wes...</td>\n",
       "      <td>[[F, r, o, m], [t, h, e], [e, a, r, l, y], [1,...</td>\n",
       "      <td>[Why, did, Western, and, Eastern, Armenia, com...</td>\n",
       "      <td>[[W, h, y], [d, i, d], [W, e, s, t, e, r, n], ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>123834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69681</th>\n",
       "      <td>[In, modern, Iran, ,, he, is, considered, a, n...</td>\n",
       "      <td>[[I, n], [m, o, d, e, r, n], [I, r, a, n], [,]...</td>\n",
       "      <td>[In, what, European, hospital, does, Avicenna,...</td>\n",
       "      <td>[[I, n], [w, h, a, t], [E, u, r, o, p, e, a, n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>69682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71204</th>\n",
       "      <td>[Since, the, beginning, of, the, study, of, el...</td>\n",
       "      <td>[[S, i, n, c, e], [t, h, e], [b, e, g, i, n, n...</td>\n",
       "      <td>[For, what, use, were, non, conductive, materi...</td>\n",
       "      <td>[[F, o, r], [w, h, a, t], [u, s, e], [w, e, r,...</td>\n",
       "      <td>[38]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>71205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71806</th>\n",
       "      <td>[Ibn, Khaldun, can, be, regarded, as, the, ear...</td>\n",
       "      <td>[[I, b, n], [K, h, a, l, d, u, n], [c, a, n], ...</td>\n",
       "      <td>[What, was, Ibn, Khaldun, 's, profession, ?]</td>\n",
       "      <td>[[W, h, a, t], [w, a, s], [I, b, n], [K, h, a,...</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>71807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77680</th>\n",
       "      <td>[Mīmāṃsā, gave, rise, to, the, study, of, phil...</td>\n",
       "      <td>[[M, ī, m, ā, ṃ, s, ā], [g, a, v, e], [r, i, s...</td>\n",
       "      <td>[What, parts, of, the, Vedas, did, the, Mimams...</td>\n",
       "      <td>[[W, h, a, t], [p, a, r, t, s], [o, f], [t, h,...</td>\n",
       "      <td>[145]</td>\n",
       "      <td>[146]</td>\n",
       "      <td>77681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33971</th>\n",
       "      <td>[In, 1907, ,, the, newly, established, Board, ...</td>\n",
       "      <td>[[I, n], [1, 9, 0, 7], [,], [t, h, e], [n, e, ...</td>\n",
       "      <td>[Who, granted, the, Royal, Charted, for, the, ...</td>\n",
       "      <td>[[W, h, o], [g, r, a, n, t, e, d], [t, h, e], ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>33972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49400</th>\n",
       "      <td>[Victoria, was, physically, unprepossessing, —...</td>\n",
       "      <td>[[V, i, c, t, o, r, i, a], [w, a, s], [p, h, y...</td>\n",
       "      <td>[Who, wrote, the, biography, about, Queen, Vic...</td>\n",
       "      <td>[[W, h, o], [w, r, o, t, e], [t, h, e], [b, i,...</td>\n",
       "      <td>[97]</td>\n",
       "      <td>[98]</td>\n",
       "      <td>49401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130319 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           context_tokens  \\\n",
       "64308   [Ann, Arbor, was, founded, in, 1824, by, land,...   \n",
       "48735   [In, Alberta, ,, five, bitumen, upgraders, pro...   \n",
       "100067  [The, concept, of, ', education, through, recr...   \n",
       "123833  [From, the, early, 16th, century, ,, both, Wes...   \n",
       "69681   [In, modern, Iran, ,, he, is, considered, a, n...   \n",
       "...                                                   ...   \n",
       "71204   [Since, the, beginning, of, the, study, of, el...   \n",
       "71806   [Ibn, Khaldun, can, be, regarded, as, the, ear...   \n",
       "77680   [Mīmāṃsā, gave, rise, to, the, study, of, phil...   \n",
       "33971   [In, 1907, ,, the, newly, established, Board, ...   \n",
       "49400   [Victoria, was, physically, unprepossessing, —...   \n",
       "\n",
       "                                            context_chars  \\\n",
       "64308   [[A, n, n], [A, r, b, o, r], [w, a, s], [f, o,...   \n",
       "48735   [[I, n], [A, l, b, e, r, t, a], [,], [f, i, v,...   \n",
       "100067  [[T, h, e], [c, o, n, c, e, p, t], [o, f], [']...   \n",
       "123833  [[F, r, o, m], [t, h, e], [e, a, r, l, y], [1,...   \n",
       "69681   [[I, n], [m, o, d, e, r, n], [I, r, a, n], [,]...   \n",
       "...                                                   ...   \n",
       "71204   [[S, i, n, c, e], [t, h, e], [b, e, g, i, n, n...   \n",
       "71806   [[I, b, n], [K, h, a, l, d, u, n], [c, a, n], ...   \n",
       "77680   [[M, ī, m, ā, ṃ, s, ā], [g, a, v, e], [r, i, s...   \n",
       "33971   [[I, n], [1, 9, 0, 7], [,], [t, h, e], [n, e, ...   \n",
       "49400   [[V, i, c, t, o, r, i, a], [w, a, s], [p, h, y...   \n",
       "\n",
       "                                              ques_tokens  \\\n",
       "64308   [What, were, the, names, of, the, founders, wi...   \n",
       "48735   [Where, is, the, Shell, Oil, upgrader, located...   \n",
       "100067  [Who, said,  , \", A, master, in, the, art, of,...   \n",
       "123833  [Why, did, Western, and, Eastern, Armenia, com...   \n",
       "69681   [In, what, European, hospital, does, Avicenna,...   \n",
       "...                                                   ...   \n",
       "71204   [For, what, use, were, non, conductive, materi...   \n",
       "71806        [What, was, Ibn, Khaldun, 's, profession, ?]   \n",
       "77680   [What, parts, of, the, Vedas, did, the, Mimams...   \n",
       "33971   [Who, granted, the, Royal, Charted, for, the, ...   \n",
       "49400   [Who, wrote, the, biography, about, Queen, Vic...   \n",
       "\n",
       "                                               ques_chars    y1s    y2s  \\\n",
       "64308   [[W, h, a, t], [w, e, r, e], [t, h, e], [n, a,...   [59]   [59]   \n",
       "48735   [[W, h, e, r, e], [i, s], [t, h, e], [S, h, e,...     []     []   \n",
       "100067  [[W, h, o], [s, a, i, d], [ ], [\"], [A], [m, a...     []     []   \n",
       "123833  [[W, h, y], [d, i, d], [W, e, s, t, e, r, n], ...     []     []   \n",
       "69681   [[I, n], [w, h, a, t], [E, u, r, o, p, e, a, n...     []     []   \n",
       "...                                                   ...    ...    ...   \n",
       "71204   [[F, o, r], [w, h, a, t], [u, s, e], [w, e, r,...   [38]   [40]   \n",
       "71806   [[W, h, a, t], [w, a, s], [I, b, n], [K, h, a,...    [8]   [10]   \n",
       "77680   [[W, h, a, t], [p, a, r, t, s], [o, f], [t, h,...  [145]  [146]   \n",
       "33971   [[W, h, o], [g, r, a, n, t, e, d], [t, h, e], ...     []     []   \n",
       "49400   [[W, h, o], [w, r, o, t, e], [t, h, e], [b, i,...   [97]   [98]   \n",
       "\n",
       "            id  \n",
       "64308    64309  \n",
       "48735    48736  \n",
       "100067  100068  \n",
       "123833  123834  \n",
       "69681    69682  \n",
       "...        ...  \n",
       "71204    71205  \n",
       "71806    71807  \n",
       "77680    77681  \n",
       "33971    33972  \n",
       "49400    49401  \n",
       "\n",
       "[130319 rows x 7 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = train.sample(frac=1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e6340d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_tokens = np.array(b['context_tokens'])\n",
    "context_chars = np.array(b['context_chars'])\n",
    "ques_tokens = np.array(b['ques_tokens'])\n",
    "ques_chars = np.array(b['ques_chars'])\n",
    "y1s = np.array(b['y1s'])\n",
    "y2s = np.array(b['y2s'])\n",
    "id = np.array(b['id'])\n",
    "\n",
    "np.savez('train10k.npz',context_tokens=context_tokens[:10000],context_chars=context_chars[:10000],ques_tokens=ques_tokens[:10000],ques_chars=ques_chars[:10000],y1s=y1s[:10000],y2s=y2s[:10000],id=id[:10000])\n",
    "np.savez('train20k.npz',context_tokens=context_tokens[:20000],context_chars=context_chars[:20000],ques_tokens=ques_tokens[:20000],ques_chars=ques_chars[:20000],y1s=y1s[:20000],y2s=y2s[:20000],id=id[:20000])\n",
    "np.savez('train30k.npz',context_tokens=context_tokens[:30000],context_chars=context_chars[:30000],ques_tokens=ques_tokens[:30000],ques_chars=ques_chars[:30000],y1s=y1s[:30000],y2s=y2s[:30000],id=id[:30000])\n",
    "np.savez('train40k.npz',context_tokens=context_tokens[:40000],context_chars=context_chars[:40000],ques_tokens=ques_tokens[:40000],ques_chars=ques_chars[:40000],y1s=y1s[:40000],y2s=y2s[:40000],id=id[:40000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "48813744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9a36b683",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__main__.<lambda>() got multiple values for keyword argument 'allow_pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[222], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain10.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[218], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(*a, **k)\u001b[0m\n\u001b[0;32m      1\u001b[0m np_load_old \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload\n\u001b[1;32m----> 2\u001b[0m np\u001b[38;5;241m.\u001b[39mload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39ma,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk: np_load_old(\u001b[38;5;241m*\u001b[39ma, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk)\n\u001b[0;32m      3\u001b[0m c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain10k.npz\u001b[39m\u001b[38;5;124m'\u001b[39m,allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[217], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(*a, **k)\u001b[0m\n\u001b[0;32m      1\u001b[0m np_load_old \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload\n\u001b[1;32m----> 2\u001b[0m np\u001b[38;5;241m.\u001b[39mload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39ma,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk: np_load_old(\u001b[38;5;241m*\u001b[39ma, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk)\n\u001b[0;32m      3\u001b[0m c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain10k.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __main__.<lambda>() got multiple values for keyword argument 'allow_pickle'"
     ]
    }
   ],
   "source": [
    "with np.load('train10.npz') as data:\n",
    "    print(data['context_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "09083591",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_load_old = np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "36547647",
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[226], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain10.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[225], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(*a, **k)\u001b[0m\n\u001b[0;32m      1\u001b[0m np_load_old \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload\n\u001b[1;32m----> 2\u001b[0m np\u001b[38;5;241m.\u001b[39mload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39ma,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk: np_load_old(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk)\n",
      "Cell \u001b[1;32mIn[225], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(*a, **k)\u001b[0m\n\u001b[0;32m      1\u001b[0m np_load_old \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload\n\u001b[1;32m----> 2\u001b[0m np\u001b[38;5;241m.\u001b[39mload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39ma,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk: np_load_old(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk)\n",
      "    \u001b[1;31m[... skipping similar frames: <lambda> at line 2 (2970 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[225], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(*a, **k)\u001b[0m\n\u001b[0;32m      1\u001b[0m np_load_old \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload\n\u001b[1;32m----> 2\u001b[0m np\u001b[38;5;241m.\u001b[39mload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39ma,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk: np_load_old(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk)\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "with np.load('train10.npz') as data:\n",
    "    print(data['context_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc55002b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Train a model on SQuAD [-h] [--train_record_file TRAIN_RECORD_FILE]\n",
      "                              [--dev_record_file DEV_RECORD_FILE]\n",
      "                              [--test_record_file TEST_RECORD_FILE]\n",
      "                              [--word_emb_file WORD_EMB_FILE]\n",
      "                              [--char_emb_file CHAR_EMB_FILE]\n",
      "                              [--train_eval_file TRAIN_EVAL_FILE]\n",
      "                              [--dev_eval_file DEV_EVAL_FILE]\n",
      "                              [--test_eval_file TEST_EVAL_FILE] --name NAME\n",
      "                              [--max_ans_len MAX_ANS_LEN]\n",
      "                              [--num_workers NUM_WORKERS]\n",
      "                              [--save_dir SAVE_DIR] [--batch_size BATCH_SIZE]\n",
      "                              [--use_squad_v2 USE_SQUAD_V2]\n",
      "                              [--hidden_size HIDDEN_SIZE]\n",
      "                              [--num_visuals NUM_VISUALS]\n",
      "                              [--load_path LOAD_PATH]\n",
      "                              [--eval_steps EVAL_STEPS] [--lr LR]\n",
      "                              [--l2_wd L2_WD] [--num_epochs NUM_EPOCHS]\n",
      "                              [--drop_prob DROP_PROB]\n",
      "                              [--metric_name {NLL,EM,F1}]\n",
      "                              [--max_checkpoints MAX_CHECKPOINTS]\n",
      "                              [--max_grad_norm MAX_GRAD_NORM] [--seed SEED]\n",
      "                              [--ema_decay EMA_DECAY]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --train_record_file TRAIN_RECORD_FILE\n",
      "  --dev_record_file DEV_RECORD_FILE\n",
      "  --test_record_file TEST_RECORD_FILE\n",
      "  --word_emb_file WORD_EMB_FILE\n",
      "  --char_emb_file CHAR_EMB_FILE\n",
      "  --train_eval_file TRAIN_EVAL_FILE\n",
      "  --dev_eval_file DEV_EVAL_FILE\n",
      "  --test_eval_file TEST_EVAL_FILE\n",
      "  --name NAME, -n NAME  Name to identify training or test run.\n",
      "  --max_ans_len MAX_ANS_LEN\n",
      "                        Maximum length of a predicted answer.\n",
      "  --num_workers NUM_WORKERS\n",
      "                        Number of sub-processes to use per data loader.\n",
      "  --save_dir SAVE_DIR   Base directory for saving information.\n",
      "  --batch_size BATCH_SIZE\n",
      "                        Batch size per GPU. Scales automatically when multiple\n",
      "                        GPUs are available.\n",
      "  --use_squad_v2 USE_SQUAD_V2\n",
      "                        Whether to use SQuAD 2.0 (unanswerable) questions.\n",
      "  --hidden_size HIDDEN_SIZE\n",
      "                        Number of features in encoder hidden layers.\n",
      "  --num_visuals NUM_VISUALS\n",
      "                        Number of examples to visualize in TensorBoard.\n",
      "  --load_path LOAD_PATH\n",
      "                        Path to load as a model checkpoint.\n",
      "  --eval_steps EVAL_STEPS\n",
      "                        Number of steps between successive evaluations.\n",
      "  --lr LR               Learning rate.\n",
      "  --l2_wd L2_WD         L2 weight decay.\n",
      "  --num_epochs NUM_EPOCHS\n",
      "                        Number of epochs for which to train. Negative means\n",
      "                        forever.\n",
      "  --drop_prob DROP_PROB\n",
      "                        Probability of zeroing an activation in dropout\n",
      "                        layers.\n",
      "  --metric_name {NLL,EM,F1}\n",
      "                        Name of dev metric to determine best checkpoint.\n",
      "  --max_checkpoints MAX_CHECKPOINTS\n",
      "                        Maximum number of checkpoints to keep on disk.\n",
      "  --max_grad_norm MAX_GRAD_NORM\n",
      "                        Maximum gradient norm for gradient clipping.\n",
      "  --seed SEED           Random seed for reproducibility.\n",
      "  --ema_decay EMA_DECAY\n",
      "                        Decay rate for exponential moving average of\n",
      "                        parameters.\n"
     ]
    }
   ],
   "source": [
    "!python train.py -hq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d7fa9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>5906</th>\n",
       "      <th>5907</th>\n",
       "      <th>5908</th>\n",
       "      <th>5909</th>\n",
       "      <th>5910</th>\n",
       "      <th>5911</th>\n",
       "      <th>5912</th>\n",
       "      <th>5913</th>\n",
       "      <th>5914</th>\n",
       "      <th>5915</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>context</th>\n",
       "      <td>A prime number (or a prime) is a natural numbe...</td>\n",
       "      <td>A prime number (or a prime) is a natural numbe...</td>\n",
       "      <td>A prime number (or a prime) is a natural numbe...</td>\n",
       "      <td>A prime number (or a prime) is a natural numbe...</td>\n",
       "      <td>A prime number (or a prime) is a natural numbe...</td>\n",
       "      <td>A prime number (or a prime) is a natural numbe...</td>\n",
       "      <td>A prime number (or a prime) is a natural numbe...</td>\n",
       "      <td>A prime number (or a prime) is a natural numbe...</td>\n",
       "      <td>A prime number (or a prime) is a natural numbe...</td>\n",
       "      <td>A prime number (or a prime) is a natural numbe...</td>\n",
       "      <td>...</td>\n",
       "      <td>Alaska Natives are indigenous peoples of Alask...</td>\n",
       "      <td>Alaska Natives are indigenous peoples of Alask...</td>\n",
       "      <td>Alaska Natives are indigenous peoples of Alask...</td>\n",
       "      <td>Alaska Natives are indigenous peoples of Alask...</td>\n",
       "      <td>Alaska Natives are indigenous peoples of Alask...</td>\n",
       "      <td>Alaska Natives are indigenous peoples of Alask...</td>\n",
       "      <td>Alaska Natives are indigenous peoples of Alask...</td>\n",
       "      <td>Alaska Natives are indigenous peoples of Alask...</td>\n",
       "      <td>Alaska Natives are indigenous peoples of Alask...</td>\n",
       "      <td>Alaska Natives are indigenous peoples of Alask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <td>What is the only divisor besides 1 that a prim...</td>\n",
       "      <td>What are numbers greater than 1 that can be di...</td>\n",
       "      <td>What theorem defines the main role of primes i...</td>\n",
       "      <td>Any number larger than 1 can be represented as...</td>\n",
       "      <td>Why must one be excluded in order to preserve ...</td>\n",
       "      <td>What is the only divisor besides 1 that a prod...</td>\n",
       "      <td>What are numbers greater than 1 that can be di...</td>\n",
       "      <td>What can any number larger than 6 can be repre...</td>\n",
       "      <td>A number larger than -3 can be represented as ...</td>\n",
       "      <td>Why must -1 be excluded in order to preserve t...</td>\n",
       "      <td>...</td>\n",
       "      <td>How are Alaskan Natives defined?</td>\n",
       "      <td>How many Alaska Native Regional Corporations a...</td>\n",
       "      <td>When did Ancestors of Alaska Natives migrate i...</td>\n",
       "      <td>Where did the descendants of the third wave of...</td>\n",
       "      <td>Alaska Natives comprise over what percentage o...</td>\n",
       "      <td>Why didnt the Alaskan Natives migrate to the S...</td>\n",
       "      <td>How many language groups do the Natives have?</td>\n",
       "      <td>How many Alaska Natives are enrolled in federa...</td>\n",
       "      <td>Alaska is part of which country?</td>\n",
       "      <td>Where did the descendants of the third wave of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spans</th>\n",
       "      <td>[(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...</td>\n",
       "      <td>[(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...</td>\n",
       "      <td>[(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...</td>\n",
       "      <td>[(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...</td>\n",
       "      <td>[(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...</td>\n",
       "      <td>[(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...</td>\n",
       "      <td>[(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...</td>\n",
       "      <td>[(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...</td>\n",
       "      <td>[(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...</td>\n",
       "      <td>[(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...</td>\n",
       "      <td>[(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...</td>\n",
       "      <td>[(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...</td>\n",
       "      <td>[(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...</td>\n",
       "      <td>[(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...</td>\n",
       "      <td>[(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...</td>\n",
       "      <td>[(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...</td>\n",
       "      <td>[(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...</td>\n",
       "      <td>[(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...</td>\n",
       "      <td>[(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answers</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uuid</th>\n",
       "      <td>84172fcbff821b3efe4c1d9eb</td>\n",
       "      <td>cac4b7f786f7a2cfda50e3b82</td>\n",
       "      <td>3b5bd07c3f7c33aaf32249d06</td>\n",
       "      <td>d8cb92a78d5231a3ecead9f8d</td>\n",
       "      <td>d2854c0eaa7cbfbdba6be22d1</td>\n",
       "      <td>c9fa1ea9b93143aefcd6c45a0</td>\n",
       "      <td>3451b734d34aeae3cbffcd87e</td>\n",
       "      <td>ff1ed5ace0342fdb8e58255f4</td>\n",
       "      <td>dd0e6e3717ffb6a6be7fe7ffe</td>\n",
       "      <td>d5a77fa6639f62de8cec0779d</td>\n",
       "      <td>...</td>\n",
       "      <td>cccd3fec3e9b6f7a29feca9bc</td>\n",
       "      <td>d5bcaf6dedadb6008bed45a95</td>\n",
       "      <td>ff97ce04e7cccded8542b186b</td>\n",
       "      <td>846dbfc429f9e667fcfc5dbdf</td>\n",
       "      <td>cc7acf690ad1cacfe042abc7c</td>\n",
       "      <td>b98cbfe8a1264dbafca6103bc</td>\n",
       "      <td>5bdbb4bc9d411a02ce5567fad</td>\n",
       "      <td>9147fdb4d1ef0570bff794d3f</td>\n",
       "      <td>8e6b2c2cc7194faafb1da5b5a</td>\n",
       "      <td>e95cf81c19f8ac430fdd35cac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5915 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          1  \\\n",
       "context   A prime number (or a prime) is a natural numbe...   \n",
       "question  What is the only divisor besides 1 that a prim...   \n",
       "spans     [(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...   \n",
       "answers                                                  []   \n",
       "uuid                              84172fcbff821b3efe4c1d9eb   \n",
       "\n",
       "                                                          2  \\\n",
       "context   A prime number (or a prime) is a natural numbe...   \n",
       "question  What are numbers greater than 1 that can be di...   \n",
       "spans     [(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...   \n",
       "answers                                                  []   \n",
       "uuid                              cac4b7f786f7a2cfda50e3b82   \n",
       "\n",
       "                                                          3  \\\n",
       "context   A prime number (or a prime) is a natural numbe...   \n",
       "question  What theorem defines the main role of primes i...   \n",
       "spans     [(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...   \n",
       "answers                                                  []   \n",
       "uuid                              3b5bd07c3f7c33aaf32249d06   \n",
       "\n",
       "                                                          4  \\\n",
       "context   A prime number (or a prime) is a natural numbe...   \n",
       "question  Any number larger than 1 can be represented as...   \n",
       "spans     [(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...   \n",
       "answers                                                  []   \n",
       "uuid                              d8cb92a78d5231a3ecead9f8d   \n",
       "\n",
       "                                                          5  \\\n",
       "context   A prime number (or a prime) is a natural numbe...   \n",
       "question  Why must one be excluded in order to preserve ...   \n",
       "spans     [(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...   \n",
       "answers                                                  []   \n",
       "uuid                              d2854c0eaa7cbfbdba6be22d1   \n",
       "\n",
       "                                                          6  \\\n",
       "context   A prime number (or a prime) is a natural numbe...   \n",
       "question  What is the only divisor besides 1 that a prod...   \n",
       "spans     [(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...   \n",
       "answers                                                  []   \n",
       "uuid                              c9fa1ea9b93143aefcd6c45a0   \n",
       "\n",
       "                                                          7  \\\n",
       "context   A prime number (or a prime) is a natural numbe...   \n",
       "question  What are numbers greater than 1 that can be di...   \n",
       "spans     [(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...   \n",
       "answers                                                  []   \n",
       "uuid                              3451b734d34aeae3cbffcd87e   \n",
       "\n",
       "                                                          8  \\\n",
       "context   A prime number (or a prime) is a natural numbe...   \n",
       "question  What can any number larger than 6 can be repre...   \n",
       "spans     [(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...   \n",
       "answers                                                  []   \n",
       "uuid                              ff1ed5ace0342fdb8e58255f4   \n",
       "\n",
       "                                                          9  \\\n",
       "context   A prime number (or a prime) is a natural numbe...   \n",
       "question  A number larger than -3 can be represented as ...   \n",
       "spans     [(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...   \n",
       "answers                                                  []   \n",
       "uuid                              dd0e6e3717ffb6a6be7fe7ffe   \n",
       "\n",
       "                                                         10  ...  \\\n",
       "context   A prime number (or a prime) is a natural numbe...  ...   \n",
       "question  Why must -1 be excluded in order to preserve t...  ...   \n",
       "spans     [(0, 1), (2, 7), (8, 14), (15, 16), (16, 18), ...  ...   \n",
       "answers                                                  []  ...   \n",
       "uuid                              d5a77fa6639f62de8cec0779d  ...   \n",
       "\n",
       "                                                       5906  \\\n",
       "context   Alaska Natives are indigenous peoples of Alask...   \n",
       "question                   How are Alaskan Natives defined?   \n",
       "spans     [(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...   \n",
       "answers                                                  []   \n",
       "uuid                              cccd3fec3e9b6f7a29feca9bc   \n",
       "\n",
       "                                                       5907  \\\n",
       "context   Alaska Natives are indigenous peoples of Alask...   \n",
       "question  How many Alaska Native Regional Corporations a...   \n",
       "spans     [(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...   \n",
       "answers                                                  []   \n",
       "uuid                              d5bcaf6dedadb6008bed45a95   \n",
       "\n",
       "                                                       5908  \\\n",
       "context   Alaska Natives are indigenous peoples of Alask...   \n",
       "question  When did Ancestors of Alaska Natives migrate i...   \n",
       "spans     [(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...   \n",
       "answers                                                  []   \n",
       "uuid                              ff97ce04e7cccded8542b186b   \n",
       "\n",
       "                                                       5909  \\\n",
       "context   Alaska Natives are indigenous peoples of Alask...   \n",
       "question  Where did the descendants of the third wave of...   \n",
       "spans     [(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...   \n",
       "answers                                                  []   \n",
       "uuid                              846dbfc429f9e667fcfc5dbdf   \n",
       "\n",
       "                                                       5910  \\\n",
       "context   Alaska Natives are indigenous peoples of Alask...   \n",
       "question  Alaska Natives comprise over what percentage o...   \n",
       "spans     [(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...   \n",
       "answers                                                  []   \n",
       "uuid                              cc7acf690ad1cacfe042abc7c   \n",
       "\n",
       "                                                       5911  \\\n",
       "context   Alaska Natives are indigenous peoples of Alask...   \n",
       "question  Why didnt the Alaskan Natives migrate to the S...   \n",
       "spans     [(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...   \n",
       "answers                                                  []   \n",
       "uuid                              b98cbfe8a1264dbafca6103bc   \n",
       "\n",
       "                                                       5912  \\\n",
       "context   Alaska Natives are indigenous peoples of Alask...   \n",
       "question      How many language groups do the Natives have?   \n",
       "spans     [(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...   \n",
       "answers                                                  []   \n",
       "uuid                              5bdbb4bc9d411a02ce5567fad   \n",
       "\n",
       "                                                       5913  \\\n",
       "context   Alaska Natives are indigenous peoples of Alask...   \n",
       "question  How many Alaska Natives are enrolled in federa...   \n",
       "spans     [(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...   \n",
       "answers                                                  []   \n",
       "uuid                              9147fdb4d1ef0570bff794d3f   \n",
       "\n",
       "                                                       5914  \\\n",
       "context   Alaska Natives are indigenous peoples of Alask...   \n",
       "question                   Alaska is part of which country?   \n",
       "spans     [(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...   \n",
       "answers                                                  []   \n",
       "uuid                              8e6b2c2cc7194faafb1da5b5a   \n",
       "\n",
       "                                                       5915  \n",
       "context   Alaska Natives are indigenous peoples of Alask...  \n",
       "question  Where did the descendants of the third wave of...  \n",
       "spans     [(0, 6), (7, 14), (15, 18), (19, 29), (30, 37)...  \n",
       "answers                                                  []  \n",
       "uuid                              e95cf81c19f8ac430fdd35cac  \n",
       "\n",
       "[5 rows x 5915 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untokenize_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78848ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(counter, data_type, limit=-1, emb_file=None, vec_size=None, num_vectors=None):\n",
    "    print(f\"Pre-processing {data_type} vectors...\")\n",
    "    embedding_dict = {}\n",
    "    filtered_elements = [k for k, v in counter.items() if v > limit]\n",
    "    if emb_file is not None:\n",
    "        assert vec_size is not None\n",
    "        with open(emb_file, \"r\", encoding=\"utf-8\") as fh:\n",
    "            for line in tqdm(fh, total=num_vectors):\n",
    "                array = line.split()\n",
    "                word = \"\".join(array[0:-vec_size])\n",
    "                vector = list(map(float, array[-vec_size:]))\n",
    "                if word in counter and counter[word] > limit:\n",
    "                    embedding_dict[word] = vector\n",
    "        print(f\"{len(embedding_dict)} / {len(filtered_elements)} tokens have corresponding {data_type} embedding vector\")\n",
    "    else:\n",
    "        assert vec_size is not None\n",
    "        for token in filtered_elements:\n",
    "            embedding_dict[token] = [np.random.normal(\n",
    "                scale=0.1) for _ in range(vec_size)]\n",
    "        print(f\"{len(filtered_elements)} tokens have corresponding {data_type} embedding vector\")\n",
    "\n",
    "    NULL = \"--NULL--\"\n",
    "    OOV = \"--OOV--\"\n",
    "    token2idx_dict = {token: idx for idx, token in enumerate(embedding_dict.keys(), 2)}\n",
    "    token2idx_dict[NULL] = 0\n",
    "    token2idx_dict[OOV] = 1\n",
    "    embedding_dict[NULL] = [0. for _ in range(vec_size)]\n",
    "    embedding_dict[OOV] = [0. for _ in range(vec_size)]\n",
    "    idx2emb_dict = {idx: embedding_dict[token]\n",
    "                    for token, idx in token2idx_dict.items()}\n",
    "    emb_mat = [idx2emb_dict[idx] for idx in range(len(idx2emb_dict))]\n",
    "    return emb_mat, token2idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c6c1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_features(args, data, word2idx_dict, char2idx_dict, is_test):\n",
    "    example = {}\n",
    "    context, question = data\n",
    "    context = context.replace(\"''\", '\" ').replace(\"``\", '\" ')\n",
    "    question = question.replace(\"''\", '\" ').replace(\"``\", '\" ')\n",
    "    example['context_tokens'] = word_tokenize(context)\n",
    "    example['ques_tokens'] = word_tokenize(question)\n",
    "    example['context_chars'] = [list(token) for token in example['context_tokens']]\n",
    "    example['ques_chars'] = [list(token) for token in example['ques_tokens']]\n",
    "\n",
    "    para_limit = args.test_para_limit if is_test else args.para_limit\n",
    "    ques_limit = args.test_ques_limit if is_test else args.ques_limit\n",
    "    char_limit = args.char_limit\n",
    "\n",
    "    def filter_func(example):\n",
    "        return len(example[\"context_tokens\"]) > para_limit or \\\n",
    "               len(example[\"ques_tokens\"]) > ques_limit\n",
    "\n",
    "    if filter_func(example):\n",
    "        raise ValueError(\"Context/Questions lengths are over the limit\")\n",
    "\n",
    "    context_idxs = np.zeros([para_limit], dtype=np.int32)\n",
    "    context_char_idxs = np.zeros([para_limit, char_limit], dtype=np.int32)\n",
    "    ques_idxs = np.zeros([ques_limit], dtype=np.int32)\n",
    "    ques_char_idxs = np.zeros([ques_limit, char_limit], dtype=np.int32)\n",
    "\n",
    "    def _get_word(word):\n",
    "        for each in (word, word.lower(), word.capitalize(), word.upper()):\n",
    "            if each in word2idx_dict:\n",
    "                return word2idx_dict[each]\n",
    "        return 1\n",
    "\n",
    "    def _get_char(char):\n",
    "        if char in char2idx_dict:\n",
    "            return char2idx_dict[char]\n",
    "        return 1\n",
    "\n",
    "    for i, token in enumerate(example[\"context_tokens\"]):\n",
    "        context_idxs[i] = _get_word(token)\n",
    "\n",
    "    for i, token in enumerate(example[\"ques_tokens\"]):\n",
    "        ques_idxs[i] = _get_word(token)\n",
    "\n",
    "    for i, token in enumerate(example[\"context_chars\"]):\n",
    "        for j, char in enumerate(token):\n",
    "            if j == char_limit:\n",
    "                break\n",
    "            context_char_idxs[i, j] = _get_char(char)\n",
    "\n",
    "    for i, token in enumerate(example[\"ques_chars\"]):\n",
    "        for j, char in enumerate(token):\n",
    "            if j == char_limit:\n",
    "                break\n",
    "            ques_char_idxs[i, j] = _get_char(char)\n",
    "\n",
    "    return context_idxs, context_char_idxs, ques_idxs, ques_char_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b744fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_answerable(example):\n",
    "    return len(example['y2s']) > 0 and len(example['y1s']) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63a100b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(examples, data_type, out_file, word2idx_dict, char2idx_dict, is_test=False):\n",
    "    para_limit = 1000 if is_test else 400\n",
    "    ques_limit = 100 if is_test else 50\n",
    "    ans_limit = 30\n",
    "    char_limit = 16\n",
    "\n",
    "    def drop_example(ex, is_test_=False):\n",
    "        if is_test_:\n",
    "            drop = False\n",
    "        else:\n",
    "            drop = len(ex[\"context_tokens\"]) > para_limit or \\\n",
    "                   len(ex[\"ques_tokens\"]) > ques_limit or \\\n",
    "                   (is_answerable(ex) and\n",
    "                    ex[\"y2s\"][0] - ex[\"y1s\"][0] > ans_limit)\n",
    "\n",
    "        return drop\n",
    "\n",
    "    print(f\"Converting {data_type} examples to indices...\")\n",
    "    total = 0\n",
    "    total_ = 0\n",
    "    meta = {}\n",
    "    context_idxs = []\n",
    "    context_char_idxs = []\n",
    "    ques_idxs = []\n",
    "    ques_char_idxs = []\n",
    "    y1s = []\n",
    "    y2s = []\n",
    "    ids = []\n",
    "    for n, example in tqdm(enumerate(examples)):\n",
    "        total_ += 1\n",
    "\n",
    "        if drop_example(example, is_test):\n",
    "            continue\n",
    "\n",
    "        total += 1\n",
    "\n",
    "        def _get_word(word):\n",
    "            for each in (word, word.lower(), word.capitalize(), word.upper()):\n",
    "                if each in word2idx_dict:\n",
    "                    return word2idx_dict[each]\n",
    "            return 1\n",
    "\n",
    "        def _get_char(char):\n",
    "            if char in char2idx_dict:\n",
    "                return char2idx_dict[char]\n",
    "            return 1\n",
    "\n",
    "        context_idx = np.zeros([para_limit], dtype=np.int32)\n",
    "        context_char_idx = np.zeros([para_limit, char_limit], dtype=np.int32)\n",
    "        ques_idx = np.zeros([ques_limit], dtype=np.int32)\n",
    "        ques_char_idx = np.zeros([ques_limit, char_limit], dtype=np.int32)\n",
    "\n",
    "        for i, token in enumerate(example[\"context_tokens\"]):\n",
    "            context_idx[i] = _get_word(token)\n",
    "        context_idxs.append(context_idx)\n",
    "\n",
    "        for i, token in enumerate(example[\"ques_tokens\"]):\n",
    "            ques_idx[i] = _get_word(token)\n",
    "        ques_idxs.append(ques_idx)\n",
    "\n",
    "        for i, token in enumerate(example[\"context_chars\"]):\n",
    "            for j, char in enumerate(token):\n",
    "                if j == char_limit:\n",
    "                    break\n",
    "                context_char_idx[i, j] = _get_char(char)\n",
    "        context_char_idxs.append(context_char_idx)\n",
    "\n",
    "        for i, token in enumerate(example[\"ques_chars\"]):\n",
    "            for j, char in enumerate(token):\n",
    "                if j == char_limit:\n",
    "                    break\n",
    "                ques_char_idx[i, j] = _get_char(char)\n",
    "        ques_char_idxs.append(ques_char_idx)\n",
    "\n",
    "        if is_answerable(example):\n",
    "            start, end = example[\"y1s\"][-1], example[\"y2s\"][-1]\n",
    "        else:\n",
    "            start, end = -1, -1\n",
    "\n",
    "        y1s.append(start)\n",
    "        y2s.append(end)\n",
    "        ids.append(example[\"id\"])\n",
    "\n",
    "    np.savez(out_file,\n",
    "             context_idxs=np.array(context_idxs),\n",
    "             context_char_idxs=np.array(context_char_idxs),\n",
    "             ques_idxs=np.array(ques_idxs),\n",
    "             ques_char_idxs=np.array(ques_char_idxs),\n",
    "             y1s=np.array(y1s),\n",
    "             y2s=np.array(y2s),\n",
    "             ids=np.array(ids))\n",
    "    print(f\"Built {total} / {total_} instances of features in total\")\n",
    "    meta[\"total\"] = total\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d34c29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing train examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:33<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing word vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2196017/2196017 [06:18<00:00, 5807.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88427 / 106876 tokens have corresponding word embedding vector\n",
      "Pre-processing char vectors...\n",
      "1374 tokens have corresponding char embedding vector\n",
      "Pre-processing dev examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 16.99it/s]\n"
     ]
    }
   ],
   "source": [
    "word_counter, char_counter = Counter(), Counter()\n",
    "train_examples, train_eval = process('./data/train-v2.0.json',\"train\", word_counter, char_counter)\n",
    "word_emb_mat, word2idx_dict = get_embedding(word_counter, 'word', emb_file='./data/glove.840B.300d/glove.840B.300d.txt', vec_size=300, num_vectors=2196017)\n",
    "char_emb_mat, char2idx_dict = get_embedding(char_counter, 'char', emb_file=None, vec_size=64)\n",
    "\n",
    "dev_examples, dev_eval = process('./data/dev-v2.0.json',\"dev\", word_counter, char_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01858f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb33389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.choice(a,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c425cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choice_K (K,examples):\n",
    "    a = np.array(examples)\n",
    "    b = np.random.choice(a,K)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2275c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c  = random_choice_K(10000,train_examples)\n",
    "c1 = random_choice_K(20000,train_examples)\n",
    "c2 = random_choice_K(30000,train_examples)\n",
    "c3 = random_choice_K(40000,train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6fd28bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'context_tokens': ['The', 'British', 'declaration', 'of', 'war', 'on', 'Germany', 'and', 'its', 'allies', 'also', 'committed', 'the', 'colonies', 'and', 'Dominions', ',', 'which', 'provided', 'invaluable', 'military', ',', 'financial', 'and', 'material', 'support', '.', 'Over', '2.5', 'million', 'men', 'served', 'in', 'the', 'armies', 'of', 'the', 'Dominions', ',', 'as', 'well', 'as', 'many', 'thousands', 'of', 'volunteers', 'from', 'the', 'Crown', 'colonies', '.', 'The', 'contributions', 'of', 'Australian', 'and', 'New', 'Zealand', 'troops', 'during', 'the', '1915', 'Gallipoli', 'Campaign', 'against', 'the', 'Ottoman', 'Empire', 'had', 'a', 'great', 'impact', 'on', 'the', 'national', 'consciousness', 'at', 'home', ',', 'and', 'marked', 'a', 'watershed', 'in', 'the', 'transition', 'of', 'Australia', 'and', 'New', 'Zealand', 'from', 'colonies', 'to', 'nations', 'in', 'their', 'own', 'right', '.', 'The', 'countries', 'continue', 'to', 'commemorate', 'this', 'occasion', 'on', 'Anzac', 'Day', '.', 'Canadians', 'viewed', 'the', 'Battle', 'of', 'Vimy', 'Ridge', 'in', 'a', 'similar', 'light', '.', 'The', 'important', 'contribution', 'of', 'the', 'Dominions', 'to', 'the', 'war', 'effort', 'was', 'recognised', 'in', '1917', 'by', 'the', 'British', 'Prime', 'Minister', 'David', 'Lloyd', 'George', 'when', 'he', 'invited', 'each', 'of', 'the', 'Dominion', 'Prime', 'Ministers', 'to', 'join', 'an', 'Imperial', 'War', 'Cabinet', 'to', 'co', '-', 'ordinate', 'imperial', 'policy', '.'], 'context_chars': [['T', 'h', 'e'], ['B', 'r', 'i', 't', 'i', 's', 'h'], ['d', 'e', 'c', 'l', 'a', 'r', 'a', 't', 'i', 'o', 'n'], ['o', 'f'], ['w', 'a', 'r'], ['o', 'n'], ['G', 'e', 'r', 'm', 'a', 'n', 'y'], ['a', 'n', 'd'], ['i', 't', 's'], ['a', 'l', 'l', 'i', 'e', 's'], ['a', 'l', 's', 'o'], ['c', 'o', 'm', 'm', 'i', 't', 't', 'e', 'd'], ['t', 'h', 'e'], ['c', 'o', 'l', 'o', 'n', 'i', 'e', 's'], ['a', 'n', 'd'], ['D', 'o', 'm', 'i', 'n', 'i', 'o', 'n', 's'], [','], ['w', 'h', 'i', 'c', 'h'], ['p', 'r', 'o', 'v', 'i', 'd', 'e', 'd'], ['i', 'n', 'v', 'a', 'l', 'u', 'a', 'b', 'l', 'e'], ['m', 'i', 'l', 'i', 't', 'a', 'r', 'y'], [','], ['f', 'i', 'n', 'a', 'n', 'c', 'i', 'a', 'l'], ['a', 'n', 'd'], ['m', 'a', 't', 'e', 'r', 'i', 'a', 'l'], ['s', 'u', 'p', 'p', 'o', 'r', 't'], ['.'], ['O', 'v', 'e', 'r'], ['2', '.', '5'], ['m', 'i', 'l', 'l', 'i', 'o', 'n'], ['m', 'e', 'n'], ['s', 'e', 'r', 'v', 'e', 'd'], ['i', 'n'], ['t', 'h', 'e'], ['a', 'r', 'm', 'i', 'e', 's'], ['o', 'f'], ['t', 'h', 'e'], ['D', 'o', 'm', 'i', 'n', 'i', 'o', 'n', 's'], [','], ['a', 's'], ['w', 'e', 'l', 'l'], ['a', 's'], ['m', 'a', 'n', 'y'], ['t', 'h', 'o', 'u', 's', 'a', 'n', 'd', 's'], ['o', 'f'], ['v', 'o', 'l', 'u', 'n', 't', 'e', 'e', 'r', 's'], ['f', 'r', 'o', 'm'], ['t', 'h', 'e'], ['C', 'r', 'o', 'w', 'n'], ['c', 'o', 'l', 'o', 'n', 'i', 'e', 's'], ['.'], ['T', 'h', 'e'], ['c', 'o', 'n', 't', 'r', 'i', 'b', 'u', 't', 'i', 'o', 'n', 's'], ['o', 'f'], ['A', 'u', 's', 't', 'r', 'a', 'l', 'i', 'a', 'n'], ['a', 'n', 'd'], ['N', 'e', 'w'], ['Z', 'e', 'a', 'l', 'a', 'n', 'd'], ['t', 'r', 'o', 'o', 'p', 's'], ['d', 'u', 'r', 'i', 'n', 'g'], ['t', 'h', 'e'], ['1', '9', '1', '5'], ['G', 'a', 'l', 'l', 'i', 'p', 'o', 'l', 'i'], ['C', 'a', 'm', 'p', 'a', 'i', 'g', 'n'], ['a', 'g', 'a', 'i', 'n', 's', 't'], ['t', 'h', 'e'], ['O', 't', 't', 'o', 'm', 'a', 'n'], ['E', 'm', 'p', 'i', 'r', 'e'], ['h', 'a', 'd'], ['a'], ['g', 'r', 'e', 'a', 't'], ['i', 'm', 'p', 'a', 'c', 't'], ['o', 'n'], ['t', 'h', 'e'], ['n', 'a', 't', 'i', 'o', 'n', 'a', 'l'], ['c', 'o', 'n', 's', 'c', 'i', 'o', 'u', 's', 'n', 'e', 's', 's'], ['a', 't'], ['h', 'o', 'm', 'e'], [','], ['a', 'n', 'd'], ['m', 'a', 'r', 'k', 'e', 'd'], ['a'], ['w', 'a', 't', 'e', 'r', 's', 'h', 'e', 'd'], ['i', 'n'], ['t', 'h', 'e'], ['t', 'r', 'a', 'n', 's', 'i', 't', 'i', 'o', 'n'], ['o', 'f'], ['A', 'u', 's', 't', 'r', 'a', 'l', 'i', 'a'], ['a', 'n', 'd'], ['N', 'e', 'w'], ['Z', 'e', 'a', 'l', 'a', 'n', 'd'], ['f', 'r', 'o', 'm'], ['c', 'o', 'l', 'o', 'n', 'i', 'e', 's'], ['t', 'o'], ['n', 'a', 't', 'i', 'o', 'n', 's'], ['i', 'n'], ['t', 'h', 'e', 'i', 'r'], ['o', 'w', 'n'], ['r', 'i', 'g', 'h', 't'], ['.'], ['T', 'h', 'e'], ['c', 'o', 'u', 'n', 't', 'r', 'i', 'e', 's'], ['c', 'o', 'n', 't', 'i', 'n', 'u', 'e'], ['t', 'o'], ['c', 'o', 'm', 'm', 'e', 'm', 'o', 'r', 'a', 't', 'e'], ['t', 'h', 'i', 's'], ['o', 'c', 'c', 'a', 's', 'i', 'o', 'n'], ['o', 'n'], ['A', 'n', 'z', 'a', 'c'], ['D', 'a', 'y'], ['.'], ['C', 'a', 'n', 'a', 'd', 'i', 'a', 'n', 's'], ['v', 'i', 'e', 'w', 'e', 'd'], ['t', 'h', 'e'], ['B', 'a', 't', 't', 'l', 'e'], ['o', 'f'], ['V', 'i', 'm', 'y'], ['R', 'i', 'd', 'g', 'e'], ['i', 'n'], ['a'], ['s', 'i', 'm', 'i', 'l', 'a', 'r'], ['l', 'i', 'g', 'h', 't'], ['.'], ['T', 'h', 'e'], ['i', 'm', 'p', 'o', 'r', 't', 'a', 'n', 't'], ['c', 'o', 'n', 't', 'r', 'i', 'b', 'u', 't', 'i', 'o', 'n'], ['o', 'f'], ['t', 'h', 'e'], ['D', 'o', 'm', 'i', 'n', 'i', 'o', 'n', 's'], ['t', 'o'], ['t', 'h', 'e'], ['w', 'a', 'r'], ['e', 'f', 'f', 'o', 'r', 't'], ['w', 'a', 's'], ['r', 'e', 'c', 'o', 'g', 'n', 'i', 's', 'e', 'd'], ['i', 'n'], ['1', '9', '1', '7'], ['b', 'y'], ['t', 'h', 'e'], ['B', 'r', 'i', 't', 'i', 's', 'h'], ['P', 'r', 'i', 'm', 'e'], ['M', 'i', 'n', 'i', 's', 't', 'e', 'r'], ['D', 'a', 'v', 'i', 'd'], ['L', 'l', 'o', 'y', 'd'], ['G', 'e', 'o', 'r', 'g', 'e'], ['w', 'h', 'e', 'n'], ['h', 'e'], ['i', 'n', 'v', 'i', 't', 'e', 'd'], ['e', 'a', 'c', 'h'], ['o', 'f'], ['t', 'h', 'e'], ['D', 'o', 'm', 'i', 'n', 'i', 'o', 'n'], ['P', 'r', 'i', 'm', 'e'], ['M', 'i', 'n', 'i', 's', 't', 'e', 'r', 's'], ['t', 'o'], ['j', 'o', 'i', 'n'], ['a', 'n'], ['I', 'm', 'p', 'e', 'r', 'i', 'a', 'l'], ['W', 'a', 'r'], ['C', 'a', 'b', 'i', 'n', 'e', 't'], ['t', 'o'], ['c', 'o'], ['-'], ['o', 'r', 'd', 'i', 'n', 'a', 't', 'e'], ['i', 'm', 'p', 'e', 'r', 'i', 'a', 'l'], ['p', 'o', 'l', 'i', 'c', 'y'], ['.']], 'ques_tokens': ['Which', 'British', 'Prime', 'Minister', 'recognized', 'the', 'Dominions', \"'\", 'contributions', 'in', '1917', '?'], 'ques_chars': [['W', 'h', 'i', 'c', 'h'], ['B', 'r', 'i', 't', 'i', 's', 'h'], ['P', 'r', 'i', 'm', 'e'], ['M', 'i', 'n', 'i', 's', 't', 'e', 'r'], ['r', 'e', 'c', 'o', 'g', 'n', 'i', 'z', 'e', 'd'], ['t', 'h', 'e'], ['D', 'o', 'm', 'i', 'n', 'i', 'o', 'n', 's'], [\"'\"], ['c', 'o', 'n', 't', 'r', 'i', 'b', 'u', 't', 'i', 'o', 'n', 's'], ['i', 'n'], ['1', '9', '1', '7'], ['?']], 'y1s': [142], 'y2s': [144], 'id': 60446},\n",
       "       {'context_tokens': ['The', 'United', 'Nations', 'Population', 'Fund', '(', 'UNFPA', ')', ',', 'formerly', 'the', 'United', 'Nations', 'Fund', 'for', 'Population', 'Activities', ',', 'is', 'a', 'UN', 'organization', '.', 'The', 'UNFPA', 'says', 'it', '\"', 'is', 'the', 'lead', 'UN', 'agency', 'for', 'delivering', 'a', 'world', 'where', 'every', 'pregnancy', 'is', 'wanted', ',', 'every', 'childbirth', 'is', 'safe', 'and', 'every', 'young', 'person', \"'s\", 'potential', 'is', 'fulfilled', '.', '\"', ' ', 'Their', 'work', 'involves', 'the', 'improvement', 'of', 'reproductive', 'health', ';', 'including', 'creation', 'of', 'national', 'strategies', 'and', 'protocols', ',', 'and', 'providing', 'supplies', 'and', 'services', '.', 'The', 'organization', 'has', 'recently', 'been', 'known', 'for', 'its', 'worldwide', 'campaign', 'against', 'obstetric', 'fistula', 'and', 'female', 'genital', 'mutilation', '.'], 'context_chars': [['T', 'h', 'e'], ['U', 'n', 'i', 't', 'e', 'd'], ['N', 'a', 't', 'i', 'o', 'n', 's'], ['P', 'o', 'p', 'u', 'l', 'a', 't', 'i', 'o', 'n'], ['F', 'u', 'n', 'd'], ['('], ['U', 'N', 'F', 'P', 'A'], [')'], [','], ['f', 'o', 'r', 'm', 'e', 'r', 'l', 'y'], ['t', 'h', 'e'], ['U', 'n', 'i', 't', 'e', 'd'], ['N', 'a', 't', 'i', 'o', 'n', 's'], ['F', 'u', 'n', 'd'], ['f', 'o', 'r'], ['P', 'o', 'p', 'u', 'l', 'a', 't', 'i', 'o', 'n'], ['A', 'c', 't', 'i', 'v', 'i', 't', 'i', 'e', 's'], [','], ['i', 's'], ['a'], ['U', 'N'], ['o', 'r', 'g', 'a', 'n', 'i', 'z', 'a', 't', 'i', 'o', 'n'], ['.'], ['T', 'h', 'e'], ['U', 'N', 'F', 'P', 'A'], ['s', 'a', 'y', 's'], ['i', 't'], ['\"'], ['i', 's'], ['t', 'h', 'e'], ['l', 'e', 'a', 'd'], ['U', 'N'], ['a', 'g', 'e', 'n', 'c', 'y'], ['f', 'o', 'r'], ['d', 'e', 'l', 'i', 'v', 'e', 'r', 'i', 'n', 'g'], ['a'], ['w', 'o', 'r', 'l', 'd'], ['w', 'h', 'e', 'r', 'e'], ['e', 'v', 'e', 'r', 'y'], ['p', 'r', 'e', 'g', 'n', 'a', 'n', 'c', 'y'], ['i', 's'], ['w', 'a', 'n', 't', 'e', 'd'], [','], ['e', 'v', 'e', 'r', 'y'], ['c', 'h', 'i', 'l', 'd', 'b', 'i', 'r', 't', 'h'], ['i', 's'], ['s', 'a', 'f', 'e'], ['a', 'n', 'd'], ['e', 'v', 'e', 'r', 'y'], ['y', 'o', 'u', 'n', 'g'], ['p', 'e', 'r', 's', 'o', 'n'], [\"'\", 's'], ['p', 'o', 't', 'e', 'n', 't', 'i', 'a', 'l'], ['i', 's'], ['f', 'u', 'l', 'f', 'i', 'l', 'l', 'e', 'd'], ['.'], ['\"'], [' '], ['T', 'h', 'e', 'i', 'r'], ['w', 'o', 'r', 'k'], ['i', 'n', 'v', 'o', 'l', 'v', 'e', 's'], ['t', 'h', 'e'], ['i', 'm', 'p', 'r', 'o', 'v', 'e', 'm', 'e', 'n', 't'], ['o', 'f'], ['r', 'e', 'p', 'r', 'o', 'd', 'u', 'c', 't', 'i', 'v', 'e'], ['h', 'e', 'a', 'l', 't', 'h'], [';'], ['i', 'n', 'c', 'l', 'u', 'd', 'i', 'n', 'g'], ['c', 'r', 'e', 'a', 't', 'i', 'o', 'n'], ['o', 'f'], ['n', 'a', 't', 'i', 'o', 'n', 'a', 'l'], ['s', 't', 'r', 'a', 't', 'e', 'g', 'i', 'e', 's'], ['a', 'n', 'd'], ['p', 'r', 'o', 't', 'o', 'c', 'o', 'l', 's'], [','], ['a', 'n', 'd'], ['p', 'r', 'o', 'v', 'i', 'd', 'i', 'n', 'g'], ['s', 'u', 'p', 'p', 'l', 'i', 'e', 's'], ['a', 'n', 'd'], ['s', 'e', 'r', 'v', 'i', 'c', 'e', 's'], ['.'], ['T', 'h', 'e'], ['o', 'r', 'g', 'a', 'n', 'i', 'z', 'a', 't', 'i', 'o', 'n'], ['h', 'a', 's'], ['r', 'e', 'c', 'e', 'n', 't', 'l', 'y'], ['b', 'e', 'e', 'n'], ['k', 'n', 'o', 'w', 'n'], ['f', 'o', 'r'], ['i', 't', 's'], ['w', 'o', 'r', 'l', 'd', 'w', 'i', 'd', 'e'], ['c', 'a', 'm', 'p', 'a', 'i', 'g', 'n'], ['a', 'g', 'a', 'i', 'n', 's', 't'], ['o', 'b', 's', 't', 'e', 't', 'r', 'i', 'c'], ['f', 'i', 's', 't', 'u', 'l', 'a'], ['a', 'n', 'd'], ['f', 'e', 'm', 'a', 'l', 'e'], ['g', 'e', 'n', 'i', 't', 'a', 'l'], ['m', 'u', 't', 'i', 'l', 'a', 't', 'i', 'o', 'n'], ['.']], 'ques_tokens': ['Another', 'of', 'UNFPA', \"'s\", 'goals', 'is', 'to', 'make', 'all', 'childbirths', 'what', '?'], 'ques_chars': [['A', 'n', 'o', 't', 'h', 'e', 'r'], ['o', 'f'], ['U', 'N', 'F', 'P', 'A'], [\"'\", 's'], ['g', 'o', 'a', 'l', 's'], ['i', 's'], ['t', 'o'], ['m', 'a', 'k', 'e'], ['a', 'l', 'l'], ['c', 'h', 'i', 'l', 'd', 'b', 'i', 'r', 't', 'h', 's'], ['w', 'h', 'a', 't'], ['?']], 'y1s': [46], 'y2s': [46], 'id': 13380},\n",
       "       {'context_tokens': ['To', 'the', 'south', ',', 'the', 'Sahara', 'is', 'bounded', 'by', 'the', 'Sahel', ',', 'a', 'belt', 'of', 'dry', 'tropical', 'savanna', 'with', 'a', 'summer', 'rainy', 'season', 'that', 'extends', 'across', 'Africa', 'from', 'east', 'to', 'west', '.', 'The', 'southern', 'limit', 'of', 'the', 'Sahara', 'is', 'indicated', 'botanically', 'by', 'the', 'southern', 'limit', 'of', 'Cornulaca', 'monacantha', '(', 'a', 'drought', '-', 'tolerant', 'member', 'of', 'the', 'Chenopodiaceae', ')', ',', 'or', 'northern', 'limit', 'of', 'Cenchrus', 'biflorus', ',', 'a', 'grass', 'typical', 'of', 'the', 'Sahel', '.', 'According', 'to', 'climatic', 'criteria', ',', 'the', 'southern', 'limit', 'of', 'the', 'Sahara', 'corresponds', 'to', 'the', '150', 'mm', '(', '5.9', 'in', ')', 'isohyet', 'of', 'annual', 'precipitation', '(', 'this', 'is', 'a', 'long', '-', 'term', 'average', ',', 'since', 'precipitation', 'varies', 'annually', ')', '.'], 'context_chars': [['T', 'o'], ['t', 'h', 'e'], ['s', 'o', 'u', 't', 'h'], [','], ['t', 'h', 'e'], ['S', 'a', 'h', 'a', 'r', 'a'], ['i', 's'], ['b', 'o', 'u', 'n', 'd', 'e', 'd'], ['b', 'y'], ['t', 'h', 'e'], ['S', 'a', 'h', 'e', 'l'], [','], ['a'], ['b', 'e', 'l', 't'], ['o', 'f'], ['d', 'r', 'y'], ['t', 'r', 'o', 'p', 'i', 'c', 'a', 'l'], ['s', 'a', 'v', 'a', 'n', 'n', 'a'], ['w', 'i', 't', 'h'], ['a'], ['s', 'u', 'm', 'm', 'e', 'r'], ['r', 'a', 'i', 'n', 'y'], ['s', 'e', 'a', 's', 'o', 'n'], ['t', 'h', 'a', 't'], ['e', 'x', 't', 'e', 'n', 'd', 's'], ['a', 'c', 'r', 'o', 's', 's'], ['A', 'f', 'r', 'i', 'c', 'a'], ['f', 'r', 'o', 'm'], ['e', 'a', 's', 't'], ['t', 'o'], ['w', 'e', 's', 't'], ['.'], ['T', 'h', 'e'], ['s', 'o', 'u', 't', 'h', 'e', 'r', 'n'], ['l', 'i', 'm', 'i', 't'], ['o', 'f'], ['t', 'h', 'e'], ['S', 'a', 'h', 'a', 'r', 'a'], ['i', 's'], ['i', 'n', 'd', 'i', 'c', 'a', 't', 'e', 'd'], ['b', 'o', 't', 'a', 'n', 'i', 'c', 'a', 'l', 'l', 'y'], ['b', 'y'], ['t', 'h', 'e'], ['s', 'o', 'u', 't', 'h', 'e', 'r', 'n'], ['l', 'i', 'm', 'i', 't'], ['o', 'f'], ['C', 'o', 'r', 'n', 'u', 'l', 'a', 'c', 'a'], ['m', 'o', 'n', 'a', 'c', 'a', 'n', 't', 'h', 'a'], ['('], ['a'], ['d', 'r', 'o', 'u', 'g', 'h', 't'], ['-'], ['t', 'o', 'l', 'e', 'r', 'a', 'n', 't'], ['m', 'e', 'm', 'b', 'e', 'r'], ['o', 'f'], ['t', 'h', 'e'], ['C', 'h', 'e', 'n', 'o', 'p', 'o', 'd', 'i', 'a', 'c', 'e', 'a', 'e'], [')'], [','], ['o', 'r'], ['n', 'o', 'r', 't', 'h', 'e', 'r', 'n'], ['l', 'i', 'm', 'i', 't'], ['o', 'f'], ['C', 'e', 'n', 'c', 'h', 'r', 'u', 's'], ['b', 'i', 'f', 'l', 'o', 'r', 'u', 's'], [','], ['a'], ['g', 'r', 'a', 's', 's'], ['t', 'y', 'p', 'i', 'c', 'a', 'l'], ['o', 'f'], ['t', 'h', 'e'], ['S', 'a', 'h', 'e', 'l'], ['.'], ['A', 'c', 'c', 'o', 'r', 'd', 'i', 'n', 'g'], ['t', 'o'], ['c', 'l', 'i', 'm', 'a', 't', 'i', 'c'], ['c', 'r', 'i', 't', 'e', 'r', 'i', 'a'], [','], ['t', 'h', 'e'], ['s', 'o', 'u', 't', 'h', 'e', 'r', 'n'], ['l', 'i', 'm', 'i', 't'], ['o', 'f'], ['t', 'h', 'e'], ['S', 'a', 'h', 'a', 'r', 'a'], ['c', 'o', 'r', 'r', 'e', 's', 'p', 'o', 'n', 'd', 's'], ['t', 'o'], ['t', 'h', 'e'], ['1', '5', '0'], ['m', 'm'], ['('], ['5', '.', '9'], ['i', 'n'], [')'], ['i', 's', 'o', 'h', 'y', 'e', 't'], ['o', 'f'], ['a', 'n', 'n', 'u', 'a', 'l'], ['p', 'r', 'e', 'c', 'i', 'p', 'i', 't', 'a', 't', 'i', 'o', 'n'], ['('], ['t', 'h', 'i', 's'], ['i', 's'], ['a'], ['l', 'o', 'n', 'g'], ['-'], ['t', 'e', 'r', 'm'], ['a', 'v', 'e', 'r', 'a', 'g', 'e'], [','], ['s', 'i', 'n', 'c', 'e'], ['p', 'r', 'e', 'c', 'i', 'p', 'i', 't', 'a', 't', 'i', 'o', 'n'], ['v', 'a', 'r', 'i', 'e', 's'], ['a', 'n', 'n', 'u', 'a', 'l', 'l', 'y'], [')'], ['.']], 'ques_tokens': ['What', 'type', 'of', 'grass', 'is', 'atypical', 'to', 'the', 'Sahel', '?'], 'ques_chars': [['W', 'h', 'a', 't'], ['t', 'y', 'p', 'e'], ['o', 'f'], ['g', 'r', 'a', 's', 's'], ['i', 's'], ['a', 't', 'y', 'p', 'i', 'c', 'a', 'l'], ['t', 'o'], ['t', 'h', 'e'], ['S', 'a', 'h', 'e', 'l'], ['?']], 'y1s': [], 'y2s': [], 'id': 81447},\n",
       "       ...,\n",
       "       {'context_tokens': ['Unlike', 'the', 'heavier', 'guns', ',', 'these', 'smaller', 'weapons', 'are', 'in', 'widespread', 'use', 'due', 'to', 'their', 'low', 'cost', 'and', 'ability', 'to', 'quickly', 'follow', 'the', 'target', '.', 'Classic', 'examples', 'of', 'autocannons', 'and', 'large', 'caliber', 'guns', 'are', 'the', '40', 'mm', 'autocannon', 'and', 'the', '8.8', 'cm', 'FlaK', '18', ',', '36', 'gun', ',', 'both', 'designed', 'by', 'Bofors', 'of', 'Sweden', '.', 'Artillery', 'weapons', 'of', 'this', 'sort', 'have', 'for', 'the', 'most', 'part', 'been', 'superseded', 'by', 'the', 'effective', 'surface', '-', 'to', '-', 'air', 'missile', 'systems', 'that', 'were', 'introduced', 'in', 'the', '1950s', ',', 'although', 'they', 'were', 'still', 'retained', 'by', 'many', 'nations', '.', 'The', 'development', 'of', 'surface', '-', 'to', '-', 'air', 'missiles', 'began', 'in', 'Nazi', 'Germany', 'during', 'the', 'late', 'World', 'War', 'II', 'with', 'missiles', 'such', 'as', 'the', 'Wasserfall', ',', 'though', 'no', 'working', 'system', 'was', 'deployed', 'before', 'the', 'war', \"'s\", 'end', ',', 'and', 'represented', 'new', 'attempts', 'to', 'increase', 'effectiveness', 'of', 'the', 'anti', '-', 'aircraft', 'systems', 'faced', 'with', 'growing', 'threat', 'from', '[', 'bomber]s', '.', 'Land', '-', 'based', 'SAMs', 'can', 'be', 'deployed', 'from', 'fixed', 'installations', 'or', 'mobile', 'launchers', ',', 'either', 'wheeled', 'or', 'tracked', '.', 'The', 'tracked', 'vehicles', 'are', 'usually', 'armoured', 'vehicles', 'specifically', 'designed', 'to', 'carry', 'SAMs', '.'], 'context_chars': [['U', 'n', 'l', 'i', 'k', 'e'], ['t', 'h', 'e'], ['h', 'e', 'a', 'v', 'i', 'e', 'r'], ['g', 'u', 'n', 's'], [','], ['t', 'h', 'e', 's', 'e'], ['s', 'm', 'a', 'l', 'l', 'e', 'r'], ['w', 'e', 'a', 'p', 'o', 'n', 's'], ['a', 'r', 'e'], ['i', 'n'], ['w', 'i', 'd', 'e', 's', 'p', 'r', 'e', 'a', 'd'], ['u', 's', 'e'], ['d', 'u', 'e'], ['t', 'o'], ['t', 'h', 'e', 'i', 'r'], ['l', 'o', 'w'], ['c', 'o', 's', 't'], ['a', 'n', 'd'], ['a', 'b', 'i', 'l', 'i', 't', 'y'], ['t', 'o'], ['q', 'u', 'i', 'c', 'k', 'l', 'y'], ['f', 'o', 'l', 'l', 'o', 'w'], ['t', 'h', 'e'], ['t', 'a', 'r', 'g', 'e', 't'], ['.'], ['C', 'l', 'a', 's', 's', 'i', 'c'], ['e', 'x', 'a', 'm', 'p', 'l', 'e', 's'], ['o', 'f'], ['a', 'u', 't', 'o', 'c', 'a', 'n', 'n', 'o', 'n', 's'], ['a', 'n', 'd'], ['l', 'a', 'r', 'g', 'e'], ['c', 'a', 'l', 'i', 'b', 'e', 'r'], ['g', 'u', 'n', 's'], ['a', 'r', 'e'], ['t', 'h', 'e'], ['4', '0'], ['m', 'm'], ['a', 'u', 't', 'o', 'c', 'a', 'n', 'n', 'o', 'n'], ['a', 'n', 'd'], ['t', 'h', 'e'], ['8', '.', '8'], ['c', 'm'], ['F', 'l', 'a', 'K'], ['1', '8'], [','], ['3', '6'], ['g', 'u', 'n'], [','], ['b', 'o', 't', 'h'], ['d', 'e', 's', 'i', 'g', 'n', 'e', 'd'], ['b', 'y'], ['B', 'o', 'f', 'o', 'r', 's'], ['o', 'f'], ['S', 'w', 'e', 'd', 'e', 'n'], ['.'], ['A', 'r', 't', 'i', 'l', 'l', 'e', 'r', 'y'], ['w', 'e', 'a', 'p', 'o', 'n', 's'], ['o', 'f'], ['t', 'h', 'i', 's'], ['s', 'o', 'r', 't'], ['h', 'a', 'v', 'e'], ['f', 'o', 'r'], ['t', 'h', 'e'], ['m', 'o', 's', 't'], ['p', 'a', 'r', 't'], ['b', 'e', 'e', 'n'], ['s', 'u', 'p', 'e', 'r', 's', 'e', 'd', 'e', 'd'], ['b', 'y'], ['t', 'h', 'e'], ['e', 'f', 'f', 'e', 'c', 't', 'i', 'v', 'e'], ['s', 'u', 'r', 'f', 'a', 'c', 'e'], ['-'], ['t', 'o'], ['-'], ['a', 'i', 'r'], ['m', 'i', 's', 's', 'i', 'l', 'e'], ['s', 'y', 's', 't', 'e', 'm', 's'], ['t', 'h', 'a', 't'], ['w', 'e', 'r', 'e'], ['i', 'n', 't', 'r', 'o', 'd', 'u', 'c', 'e', 'd'], ['i', 'n'], ['t', 'h', 'e'], ['1', '9', '5', '0', 's'], [','], ['a', 'l', 't', 'h', 'o', 'u', 'g', 'h'], ['t', 'h', 'e', 'y'], ['w', 'e', 'r', 'e'], ['s', 't', 'i', 'l', 'l'], ['r', 'e', 't', 'a', 'i', 'n', 'e', 'd'], ['b', 'y'], ['m', 'a', 'n', 'y'], ['n', 'a', 't', 'i', 'o', 'n', 's'], ['.'], ['T', 'h', 'e'], ['d', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't'], ['o', 'f'], ['s', 'u', 'r', 'f', 'a', 'c', 'e'], ['-'], ['t', 'o'], ['-'], ['a', 'i', 'r'], ['m', 'i', 's', 's', 'i', 'l', 'e', 's'], ['b', 'e', 'g', 'a', 'n'], ['i', 'n'], ['N', 'a', 'z', 'i'], ['G', 'e', 'r', 'm', 'a', 'n', 'y'], ['d', 'u', 'r', 'i', 'n', 'g'], ['t', 'h', 'e'], ['l', 'a', 't', 'e'], ['W', 'o', 'r', 'l', 'd'], ['W', 'a', 'r'], ['I', 'I'], ['w', 'i', 't', 'h'], ['m', 'i', 's', 's', 'i', 'l', 'e', 's'], ['s', 'u', 'c', 'h'], ['a', 's'], ['t', 'h', 'e'], ['W', 'a', 's', 's', 'e', 'r', 'f', 'a', 'l', 'l'], [','], ['t', 'h', 'o', 'u', 'g', 'h'], ['n', 'o'], ['w', 'o', 'r', 'k', 'i', 'n', 'g'], ['s', 'y', 's', 't', 'e', 'm'], ['w', 'a', 's'], ['d', 'e', 'p', 'l', 'o', 'y', 'e', 'd'], ['b', 'e', 'f', 'o', 'r', 'e'], ['t', 'h', 'e'], ['w', 'a', 'r'], [\"'\", 's'], ['e', 'n', 'd'], [','], ['a', 'n', 'd'], ['r', 'e', 'p', 'r', 'e', 's', 'e', 'n', 't', 'e', 'd'], ['n', 'e', 'w'], ['a', 't', 't', 'e', 'm', 'p', 't', 's'], ['t', 'o'], ['i', 'n', 'c', 'r', 'e', 'a', 's', 'e'], ['e', 'f', 'f', 'e', 'c', 't', 'i', 'v', 'e', 'n', 'e', 's', 's'], ['o', 'f'], ['t', 'h', 'e'], ['a', 'n', 't', 'i'], ['-'], ['a', 'i', 'r', 'c', 'r', 'a', 'f', 't'], ['s', 'y', 's', 't', 'e', 'm', 's'], ['f', 'a', 'c', 'e', 'd'], ['w', 'i', 't', 'h'], ['g', 'r', 'o', 'w', 'i', 'n', 'g'], ['t', 'h', 'r', 'e', 'a', 't'], ['f', 'r', 'o', 'm'], ['['], ['b', 'o', 'm', 'b', 'e', 'r', ']', 's'], ['.'], ['L', 'a', 'n', 'd'], ['-'], ['b', 'a', 's', 'e', 'd'], ['S', 'A', 'M', 's'], ['c', 'a', 'n'], ['b', 'e'], ['d', 'e', 'p', 'l', 'o', 'y', 'e', 'd'], ['f', 'r', 'o', 'm'], ['f', 'i', 'x', 'e', 'd'], ['i', 'n', 's', 't', 'a', 'l', 'l', 'a', 't', 'i', 'o', 'n', 's'], ['o', 'r'], ['m', 'o', 'b', 'i', 'l', 'e'], ['l', 'a', 'u', 'n', 'c', 'h', 'e', 'r', 's'], [','], ['e', 'i', 't', 'h', 'e', 'r'], ['w', 'h', 'e', 'e', 'l', 'e', 'd'], ['o', 'r'], ['t', 'r', 'a', 'c', 'k', 'e', 'd'], ['.'], ['T', 'h', 'e'], ['t', 'r', 'a', 'c', 'k', 'e', 'd'], ['v', 'e', 'h', 'i', 'c', 'l', 'e', 's'], ['a', 'r', 'e'], ['u', 's', 'u', 'a', 'l', 'l', 'y'], ['a', 'r', 'm', 'o', 'u', 'r', 'e', 'd'], ['v', 'e', 'h', 'i', 'c', 'l', 'e', 's'], ['s', 'p', 'e', 'c', 'i', 'f', 'i', 'c', 'a', 'l', 'l', 'y'], ['d', 'e', 's', 'i', 'g', 'n', 'e', 'd'], ['t', 'o'], ['c', 'a', 'r', 'r', 'y'], ['S', 'A', 'M', 's'], ['.']], 'ques_tokens': ['Where', 'were', 'surface', '-', 'to', '-', 'air', 'missiles', 'first', 'developed', '?'], 'ques_chars': [['W', 'h', 'e', 'r', 'e'], ['w', 'e', 'r', 'e'], ['s', 'u', 'r', 'f', 'a', 'c', 'e'], ['-'], ['t', 'o'], ['-'], ['a', 'i', 'r'], ['m', 'i', 's', 's', 'i', 'l', 'e', 's'], ['f', 'i', 'r', 's', 't'], ['d', 'e', 'v', 'e', 'l', 'o', 'p', 'e', 'd'], ['?']], 'y1s': [103], 'y2s': [105], 'id': 40549},\n",
       "       {'context_tokens': ['The', 'movement', 'was', 'pioneered', 'by', 'Georges', 'Braque', 'and', 'Pablo', 'Picasso', ',', 'joined', 'by', 'Jean', 'Metzinger', ',', 'Albert', 'Gleizes', ',', 'Robert', 'Delaunay', ',', 'Henri', 'Le', 'Fauconnier', ',', 'Fernand', 'Léger', 'and', 'Juan', 'Gris', '.', 'A', 'primary', 'influence', 'that', 'led', 'to', 'Cubism', 'was', 'the', 'representation', 'of', 'three', '-', 'dimensional', 'form', 'in', 'the', 'late', 'works', 'of', 'Paul', 'Cézanne', '.', 'A', 'retrospective', 'of', 'Cézanne', \"'s\", 'paintings', 'had', 'been', 'held', 'at', 'the', 'Salon', \"d'Automne\", 'of', '1904', ',', 'current', 'works', 'were', 'displayed', 'at', 'the', '1905', 'and', '1906', 'Salon', \"d'Automne\", ',', 'followed', 'by', 'two', 'commemorative', 'retrospectives', 'after', 'his', 'death', 'in', '1907', '.'], 'context_chars': [['T', 'h', 'e'], ['m', 'o', 'v', 'e', 'm', 'e', 'n', 't'], ['w', 'a', 's'], ['p', 'i', 'o', 'n', 'e', 'e', 'r', 'e', 'd'], ['b', 'y'], ['G', 'e', 'o', 'r', 'g', 'e', 's'], ['B', 'r', 'a', 'q', 'u', 'e'], ['a', 'n', 'd'], ['P', 'a', 'b', 'l', 'o'], ['P', 'i', 'c', 'a', 's', 's', 'o'], [','], ['j', 'o', 'i', 'n', 'e', 'd'], ['b', 'y'], ['J', 'e', 'a', 'n'], ['M', 'e', 't', 'z', 'i', 'n', 'g', 'e', 'r'], [','], ['A', 'l', 'b', 'e', 'r', 't'], ['G', 'l', 'e', 'i', 'z', 'e', 's'], [','], ['R', 'o', 'b', 'e', 'r', 't'], ['D', 'e', 'l', 'a', 'u', 'n', 'a', 'y'], [','], ['H', 'e', 'n', 'r', 'i'], ['L', 'e'], ['F', 'a', 'u', 'c', 'o', 'n', 'n', 'i', 'e', 'r'], [','], ['F', 'e', 'r', 'n', 'a', 'n', 'd'], ['L', 'é', 'g', 'e', 'r'], ['a', 'n', 'd'], ['J', 'u', 'a', 'n'], ['G', 'r', 'i', 's'], ['.'], ['A'], ['p', 'r', 'i', 'm', 'a', 'r', 'y'], ['i', 'n', 'f', 'l', 'u', 'e', 'n', 'c', 'e'], ['t', 'h', 'a', 't'], ['l', 'e', 'd'], ['t', 'o'], ['C', 'u', 'b', 'i', 's', 'm'], ['w', 'a', 's'], ['t', 'h', 'e'], ['r', 'e', 'p', 'r', 'e', 's', 'e', 'n', 't', 'a', 't', 'i', 'o', 'n'], ['o', 'f'], ['t', 'h', 'r', 'e', 'e'], ['-'], ['d', 'i', 'm', 'e', 'n', 's', 'i', 'o', 'n', 'a', 'l'], ['f', 'o', 'r', 'm'], ['i', 'n'], ['t', 'h', 'e'], ['l', 'a', 't', 'e'], ['w', 'o', 'r', 'k', 's'], ['o', 'f'], ['P', 'a', 'u', 'l'], ['C', 'é', 'z', 'a', 'n', 'n', 'e'], ['.'], ['A'], ['r', 'e', 't', 'r', 'o', 's', 'p', 'e', 'c', 't', 'i', 'v', 'e'], ['o', 'f'], ['C', 'é', 'z', 'a', 'n', 'n', 'e'], [\"'\", 's'], ['p', 'a', 'i', 'n', 't', 'i', 'n', 'g', 's'], ['h', 'a', 'd'], ['b', 'e', 'e', 'n'], ['h', 'e', 'l', 'd'], ['a', 't'], ['t', 'h', 'e'], ['S', 'a', 'l', 'o', 'n'], ['d', \"'\", 'A', 'u', 't', 'o', 'm', 'n', 'e'], ['o', 'f'], ['1', '9', '0', '4'], [','], ['c', 'u', 'r', 'r', 'e', 'n', 't'], ['w', 'o', 'r', 'k', 's'], ['w', 'e', 'r', 'e'], ['d', 'i', 's', 'p', 'l', 'a', 'y', 'e', 'd'], ['a', 't'], ['t', 'h', 'e'], ['1', '9', '0', '5'], ['a', 'n', 'd'], ['1', '9', '0', '6'], ['S', 'a', 'l', 'o', 'n'], ['d', \"'\", 'A', 'u', 't', 'o', 'm', 'n', 'e'], [','], ['f', 'o', 'l', 'l', 'o', 'w', 'e', 'd'], ['b', 'y'], ['t', 'w', 'o'], ['c', 'o', 'm', 'm', 'e', 'm', 'o', 'r', 'a', 't', 'i', 'v', 'e'], ['r', 'e', 't', 'r', 'o', 's', 'p', 'e', 'c', 't', 'i', 'v', 'e', 's'], ['a', 'f', 't', 'e', 'r'], ['h', 'i', 's'], ['d', 'e', 'a', 't', 'h'], ['i', 'n'], ['1', '9', '0', '7'], ['.']], 'ques_tokens': ['Which', 'person', 'was', 'the', 'least', 'influential', 'in', 'beginning', 'the', 'movement', 'with', 'is', 'three', 'dimensional', 'forms', '?'], 'ques_chars': [['W', 'h', 'i', 'c', 'h'], ['p', 'e', 'r', 's', 'o', 'n'], ['w', 'a', 's'], ['t', 'h', 'e'], ['l', 'e', 'a', 's', 't'], ['i', 'n', 'f', 'l', 'u', 'e', 'n', 't', 'i', 'a', 'l'], ['i', 'n'], ['b', 'e', 'g', 'i', 'n', 'n', 'i', 'n', 'g'], ['t', 'h', 'e'], ['m', 'o', 'v', 'e', 'm', 'e', 'n', 't'], ['w', 'i', 't', 'h'], ['i', 's'], ['t', 'h', 'r', 'e', 'e'], ['d', 'i', 'm', 'e', 'n', 's', 'i', 'o', 'n', 'a', 'l'], ['f', 'o', 'r', 'm', 's'], ['?']], 'y1s': [], 'y2s': [], 'id': 64939},\n",
       "       {'context_tokens': ['Neither', 'John', 'nor', 'the', 'rebel', 'barons', 'seriously', 'attempted', 'to', 'implement', 'the', 'peace', 'accord', '.', 'The', 'rebel', 'barons', 'suspected', 'that', 'the', 'proposed', 'baronial', 'council', 'would', 'be', 'unacceptable', 'to', 'John', 'and', 'that', 'he', 'would', 'challenge', 'the', 'legality', 'of', 'the', 'charter', ';', 'they', 'packed', 'the', 'baronial', 'council', 'with', 'their', 'own', 'hardliners', 'and', 'refused', 'to', 'demobilise', 'their', 'forces', 'or', 'surrender', 'London', 'as', 'agreed', '.', 'Despite', 'his', 'promises', 'to', 'the', 'contrary', ',', 'John', 'appealed', 'to', 'Innocent', 'for', 'help', ',', 'observing', 'that', 'the', 'charter', 'compromised', 'the', 'pope', \"'s\", 'rights', 'under', 'the', '1213', 'agreement', 'that', 'had', 'appointed', 'him', 'John', \"'s\", 'feudal', 'lord', '.', 'Innocent', 'obliged', ';', 'he', 'declared', 'the', 'charter', '\"', 'not', 'only', 'shameful', 'and', 'demeaning', ',', 'but', 'illegal', 'and', 'unjust', '\"', 'and', 'excommunicated', 'the', 'rebel', 'barons', '.', 'The', 'failure', 'of', 'the', 'agreement', 'led', 'rapidly', 'to', 'the', 'First', 'Barons', \"'\", 'War', '.'], 'context_chars': [['N', 'e', 'i', 't', 'h', 'e', 'r'], ['J', 'o', 'h', 'n'], ['n', 'o', 'r'], ['t', 'h', 'e'], ['r', 'e', 'b', 'e', 'l'], ['b', 'a', 'r', 'o', 'n', 's'], ['s', 'e', 'r', 'i', 'o', 'u', 's', 'l', 'y'], ['a', 't', 't', 'e', 'm', 'p', 't', 'e', 'd'], ['t', 'o'], ['i', 'm', 'p', 'l', 'e', 'm', 'e', 'n', 't'], ['t', 'h', 'e'], ['p', 'e', 'a', 'c', 'e'], ['a', 'c', 'c', 'o', 'r', 'd'], ['.'], ['T', 'h', 'e'], ['r', 'e', 'b', 'e', 'l'], ['b', 'a', 'r', 'o', 'n', 's'], ['s', 'u', 's', 'p', 'e', 'c', 't', 'e', 'd'], ['t', 'h', 'a', 't'], ['t', 'h', 'e'], ['p', 'r', 'o', 'p', 'o', 's', 'e', 'd'], ['b', 'a', 'r', 'o', 'n', 'i', 'a', 'l'], ['c', 'o', 'u', 'n', 'c', 'i', 'l'], ['w', 'o', 'u', 'l', 'd'], ['b', 'e'], ['u', 'n', 'a', 'c', 'c', 'e', 'p', 't', 'a', 'b', 'l', 'e'], ['t', 'o'], ['J', 'o', 'h', 'n'], ['a', 'n', 'd'], ['t', 'h', 'a', 't'], ['h', 'e'], ['w', 'o', 'u', 'l', 'd'], ['c', 'h', 'a', 'l', 'l', 'e', 'n', 'g', 'e'], ['t', 'h', 'e'], ['l', 'e', 'g', 'a', 'l', 'i', 't', 'y'], ['o', 'f'], ['t', 'h', 'e'], ['c', 'h', 'a', 'r', 't', 'e', 'r'], [';'], ['t', 'h', 'e', 'y'], ['p', 'a', 'c', 'k', 'e', 'd'], ['t', 'h', 'e'], ['b', 'a', 'r', 'o', 'n', 'i', 'a', 'l'], ['c', 'o', 'u', 'n', 'c', 'i', 'l'], ['w', 'i', 't', 'h'], ['t', 'h', 'e', 'i', 'r'], ['o', 'w', 'n'], ['h', 'a', 'r', 'd', 'l', 'i', 'n', 'e', 'r', 's'], ['a', 'n', 'd'], ['r', 'e', 'f', 'u', 's', 'e', 'd'], ['t', 'o'], ['d', 'e', 'm', 'o', 'b', 'i', 'l', 'i', 's', 'e'], ['t', 'h', 'e', 'i', 'r'], ['f', 'o', 'r', 'c', 'e', 's'], ['o', 'r'], ['s', 'u', 'r', 'r', 'e', 'n', 'd', 'e', 'r'], ['L', 'o', 'n', 'd', 'o', 'n'], ['a', 's'], ['a', 'g', 'r', 'e', 'e', 'd'], ['.'], ['D', 'e', 's', 'p', 'i', 't', 'e'], ['h', 'i', 's'], ['p', 'r', 'o', 'm', 'i', 's', 'e', 's'], ['t', 'o'], ['t', 'h', 'e'], ['c', 'o', 'n', 't', 'r', 'a', 'r', 'y'], [','], ['J', 'o', 'h', 'n'], ['a', 'p', 'p', 'e', 'a', 'l', 'e', 'd'], ['t', 'o'], ['I', 'n', 'n', 'o', 'c', 'e', 'n', 't'], ['f', 'o', 'r'], ['h', 'e', 'l', 'p'], [','], ['o', 'b', 's', 'e', 'r', 'v', 'i', 'n', 'g'], ['t', 'h', 'a', 't'], ['t', 'h', 'e'], ['c', 'h', 'a', 'r', 't', 'e', 'r'], ['c', 'o', 'm', 'p', 'r', 'o', 'm', 'i', 's', 'e', 'd'], ['t', 'h', 'e'], ['p', 'o', 'p', 'e'], [\"'\", 's'], ['r', 'i', 'g', 'h', 't', 's'], ['u', 'n', 'd', 'e', 'r'], ['t', 'h', 'e'], ['1', '2', '1', '3'], ['a', 'g', 'r', 'e', 'e', 'm', 'e', 'n', 't'], ['t', 'h', 'a', 't'], ['h', 'a', 'd'], ['a', 'p', 'p', 'o', 'i', 'n', 't', 'e', 'd'], ['h', 'i', 'm'], ['J', 'o', 'h', 'n'], [\"'\", 's'], ['f', 'e', 'u', 'd', 'a', 'l'], ['l', 'o', 'r', 'd'], ['.'], ['I', 'n', 'n', 'o', 'c', 'e', 'n', 't'], ['o', 'b', 'l', 'i', 'g', 'e', 'd'], [';'], ['h', 'e'], ['d', 'e', 'c', 'l', 'a', 'r', 'e', 'd'], ['t', 'h', 'e'], ['c', 'h', 'a', 'r', 't', 'e', 'r'], ['\"'], ['n', 'o', 't'], ['o', 'n', 'l', 'y'], ['s', 'h', 'a', 'm', 'e', 'f', 'u', 'l'], ['a', 'n', 'd'], ['d', 'e', 'm', 'e', 'a', 'n', 'i', 'n', 'g'], [','], ['b', 'u', 't'], ['i', 'l', 'l', 'e', 'g', 'a', 'l'], ['a', 'n', 'd'], ['u', 'n', 'j', 'u', 's', 't'], ['\"'], ['a', 'n', 'd'], ['e', 'x', 'c', 'o', 'm', 'm', 'u', 'n', 'i', 'c', 'a', 't', 'e', 'd'], ['t', 'h', 'e'], ['r', 'e', 'b', 'e', 'l'], ['b', 'a', 'r', 'o', 'n', 's'], ['.'], ['T', 'h', 'e'], ['f', 'a', 'i', 'l', 'u', 'r', 'e'], ['o', 'f'], ['t', 'h', 'e'], ['a', 'g', 'r', 'e', 'e', 'm', 'e', 'n', 't'], ['l', 'e', 'd'], ['r', 'a', 'p', 'i', 'd', 'l', 'y'], ['t', 'o'], ['t', 'h', 'e'], ['F', 'i', 'r', 's', 't'], ['B', 'a', 'r', 'o', 'n', 's'], [\"'\"], ['W', 'a', 'r'], ['.']], 'ques_tokens': ['John', 'appealed', 'to', 'who', 'for', 'help', '?'], 'ques_chars': [['J', 'o', 'h', 'n'], ['a', 'p', 'p', 'e', 'a', 'l', 'e', 'd'], ['t', 'o'], ['w', 'h', 'o'], ['f', 'o', 'r'], ['h', 'e', 'l', 'p'], ['?']], 'y1s': [70], 'y2s': [70], 'id': 39806}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d972efb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing test examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 30.73it/s]\n"
     ]
    }
   ],
   "source": [
    " test_examples, test_eval = process('./data/test-v2.0.json', \"test\", word_counter, char_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed98e911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': 2,\n",
       " 'e': 3,\n",
       " 'y': 4,\n",
       " 'o': 5,\n",
       " 'n': 6,\n",
       " 'c': 7,\n",
       " 'é': 8,\n",
       " 'G': 9,\n",
       " 'i': 10,\n",
       " 's': 11,\n",
       " 'l': 12,\n",
       " 'K': 13,\n",
       " 'w': 14,\n",
       " '-': 15,\n",
       " 'C': 16,\n",
       " 'a': 17,\n",
       " 'r': 18,\n",
       " 't': 19,\n",
       " '(': 20,\n",
       " '/': 21,\n",
       " 'b': 22,\n",
       " 'ː': 23,\n",
       " 'ˈ': 24,\n",
       " 'j': 25,\n",
       " 'ɒ': 26,\n",
       " 'ɪ': 27,\n",
       " 'Y': 28,\n",
       " 'O': 29,\n",
       " 'N': 30,\n",
       " ')': 31,\n",
       " 'S': 32,\n",
       " 'p': 33,\n",
       " 'm': 34,\n",
       " '4': 35,\n",
       " ',': 36,\n",
       " '1': 37,\n",
       " '9': 38,\n",
       " '8': 39,\n",
       " 'A': 40,\n",
       " 'g': 41,\n",
       " 'd': 42,\n",
       " 'u': 43,\n",
       " '.': 44,\n",
       " 'H': 45,\n",
       " 'T': 46,\n",
       " 'x': 47,\n",
       " 'h': 48,\n",
       " 'f': 49,\n",
       " 'v': 50,\n",
       " '0': 51,\n",
       " 'R': 52,\n",
       " '&': 53,\n",
       " 'D': 54,\n",
       " \"'\": 55,\n",
       " 'M': 56,\n",
       " 'L': 57,\n",
       " '2': 58,\n",
       " '3': 59,\n",
       " '\"': 60,\n",
       " 'z': 61,\n",
       " 'W': 62,\n",
       " '?': 63,\n",
       " 'I': 64,\n",
       " ' ': 65,\n",
       " 'k': 66,\n",
       " 'F': 67,\n",
       " 'J': 68,\n",
       " '5': 69,\n",
       " '6': 70,\n",
       " 'à': 71,\n",
       " 'V': 72,\n",
       " 'P': 73,\n",
       " 'Z': 74,\n",
       " 'E': 75,\n",
       " ';': 76,\n",
       " 'q': 77,\n",
       " '7': 78,\n",
       " 'X': 79,\n",
       " 'U': 80,\n",
       " ':': 81,\n",
       " '$': 82,\n",
       " '[': 83,\n",
       " ']': 84,\n",
       " '—': 85,\n",
       " 'Q': 86,\n",
       " '#': 87,\n",
       " '–': 88,\n",
       " '%': 89,\n",
       " 'è': 90,\n",
       " 'ç': 91,\n",
       " 'ʃ': 92,\n",
       " 'ʊ': 93,\n",
       " 'æ': 94,\n",
       " '\\u200b': 95,\n",
       " 'ʁ': 96,\n",
       " 'ɑ': 97,\n",
       " '̃': 98,\n",
       " 'ɔ': 99,\n",
       " 'ɛ': 100,\n",
       " 'ń': 101,\n",
       " 'Ż': 102,\n",
       " 'ż': 103,\n",
       " 'ó': 104,\n",
       " 'ü': 105,\n",
       " 'ś': 106,\n",
       " 'ł': 107,\n",
       " 'ò': 108,\n",
       " 'É': 109,\n",
       " '!': 110,\n",
       " 'ô': 111,\n",
       " '£': 112,\n",
       " 'Ł': 113,\n",
       " 'ä': 114,\n",
       " 'í': 115,\n",
       " 'ř': 116,\n",
       " 'á': 117,\n",
       " 'ů': 118,\n",
       " 'ö': 119,\n",
       " 'Ö': 120,\n",
       " 'ì': 121,\n",
       " 'ī': 122,\n",
       " '俄': 123,\n",
       " '力': 124,\n",
       " '思': 125,\n",
       " '軍': 126,\n",
       " '民': 127,\n",
       " '元': 128,\n",
       " '帥': 129,\n",
       " '府': 130,\n",
       " 'Ü': 131,\n",
       " '法': 132,\n",
       " '王': 133,\n",
       " '大': 134,\n",
       " '國': 135,\n",
       " '師': 136,\n",
       " '候': 137,\n",
       " '顯': 138,\n",
       " 'ā': 139,\n",
       " 'š': 140,\n",
       " '沐': 141,\n",
       " '英': 142,\n",
       " '’': 143,\n",
       " 'ã': 144,\n",
       " '½': 145,\n",
       " '+': 146,\n",
       " '¢': 147,\n",
       " 'ゼ': 148,\n",
       " 'ル': 149,\n",
       " 'ダ': 150,\n",
       " 'の': 151,\n",
       " '伝': 152,\n",
       " '説': 153,\n",
       " 'ト': 154,\n",
       " 'ワ': 155,\n",
       " 'イ': 156,\n",
       " 'ラ': 157,\n",
       " 'プ': 158,\n",
       " 'リ': 159,\n",
       " 'ン': 160,\n",
       " 'セ': 161,\n",
       " 'ス': 162,\n",
       " 'ō': 163,\n",
       " 'Ō': 164,\n",
       " '−': 165,\n",
       " '“': 166,\n",
       " '”': 167,\n",
       " '汶': 168,\n",
       " '川': 169,\n",
       " '地': 170,\n",
       " '震': 171,\n",
       " '°': 172,\n",
       " '耿': 173,\n",
       " '庆': 174,\n",
       " '国': 175,\n",
       " '>': 176,\n",
       " '紫': 177,\n",
       " '坪': 178,\n",
       " '铺': 179,\n",
       " '水': 180,\n",
       " '库': 181,\n",
       " '鋪': 182,\n",
       " '庫': 183,\n",
       " '朱': 184,\n",
       " '紹': 185,\n",
       " '維': 186,\n",
       " '绍': 187,\n",
       " '维': 188,\n",
       " 'ū': 189,\n",
       " '书': 190,\n",
       " '剑': 191,\n",
       " '子': 192,\n",
       " '€': 193,\n",
       " '《': 194,\n",
       " '灾': 195,\n",
       " '后': 196,\n",
       " '恢': 197,\n",
       " '复': 198,\n",
       " '重': 199,\n",
       " '建': 200,\n",
       " '对': 201,\n",
       " '口': 202,\n",
       " '支': 203,\n",
       " '援': 204,\n",
       " '方': 205,\n",
       " '案': 206,\n",
       " '》': 207,\n",
       " '±': 208,\n",
       " '豆': 209,\n",
       " '腐': 210,\n",
       " '渣': 211,\n",
       " '校': 212,\n",
       " '舍': 213,\n",
       " '爱': 214,\n",
       " '的': 215,\n",
       " '奉': 216,\n",
       " '献': 217,\n",
       " '愛': 218,\n",
       " '獻': 219,\n",
       " '~': 220,\n",
       " '¥': 221,\n",
       " '让': 222,\n",
       " '流': 223,\n",
       " '不': 224,\n",
       " '息': 225,\n",
       " '刘': 226,\n",
       " '坤': 227,\n",
       " '工': 228,\n",
       " '程': 229,\n",
       " 'ê': 230,\n",
       " '²': 231,\n",
       " '紐': 232,\n",
       " '約': 233,\n",
       " '華': 234,\n",
       " '埠': 235,\n",
       " '布': 236,\n",
       " '鲁': 237,\n",
       " '克': 238,\n",
       " '林': 239,\n",
       " '拉': 240,\n",
       " '盛': 241,\n",
       " '拿': 242,\n",
       " '騷': 243,\n",
       " '縣': 244,\n",
       " '長': 245,\n",
       " '島': 246,\n",
       " '朝': 247,\n",
       " '鲜': 248,\n",
       " '族': 249,\n",
       " '조': 250,\n",
       " '선': 251,\n",
       " '족': 252,\n",
       " '❤': 253,\n",
       " 'ɹ': 254,\n",
       " 'ə': 255,\n",
       " 'ʌ': 256,\n",
       " 'ɾ': 257,\n",
       " 'ɜ': 258,\n",
       " '=': 259,\n",
       " 'ï': 260,\n",
       " 'ध': 261,\n",
       " 'र': 262,\n",
       " '्': 263,\n",
       " 'म': 264,\n",
       " 'ṣ': 265,\n",
       " 'Ś': 266,\n",
       " 'ṇ': 267,\n",
       " 'ṃ': 268,\n",
       " 'ṅ': 269,\n",
       " 'Ā': 270,\n",
       " 'द': 271,\n",
       " 'ु': 272,\n",
       " 'क': 273,\n",
       " 'ख': 274,\n",
       " 'ः': 275,\n",
       " 'ḥ': 276,\n",
       " '緣': 277,\n",
       " '起': 278,\n",
       " 'ñ': 279,\n",
       " 'ब': 280,\n",
       " 'ॊ': 281,\n",
       " 'ि': 282,\n",
       " '\\n': 283,\n",
       " '安': 284,\n",
       " '樂': 285,\n",
       " '淨': 286,\n",
       " '土': 287,\n",
       " 'ṭ': 288,\n",
       " 'य': 289,\n",
       " 'ा': 290,\n",
       " 'न': 291,\n",
       " '禅': 292,\n",
       " '臨': 293,\n",
       " '済': 294,\n",
       " '宗': 295,\n",
       " '曹': 296,\n",
       " '洞': 297,\n",
       " '公': 298,\n",
       " 'ṛ': 299,\n",
       " 'ḍ': 300,\n",
       " '\\u200d': 301,\n",
       " '\\u200c': 302,\n",
       " '*': 303,\n",
       " 'ŵ': 304,\n",
       " '‘': 305,\n",
       " 'ễ': 306,\n",
       " 'ấ': 307,\n",
       " 'ũ': 308,\n",
       " 'Đ': 309,\n",
       " 'ế': 310,\n",
       " 'ă': 311,\n",
       " 'ả': 312,\n",
       " 'ø': 313,\n",
       " '\\u3000': 314,\n",
       " 'Φ': 315,\n",
       " '总': 316,\n",
       " '理': 317,\n",
       " 'ŏ': 318,\n",
       " 'ĭ': 319,\n",
       " 'π': 320,\n",
       " 'ο': 321,\n",
       " 'λ': 322,\n",
       " 'ύ': 323,\n",
       " 'ú': 324,\n",
       " 'ý': 325,\n",
       " 'τ': 326,\n",
       " 'ε': 327,\n",
       " 'χ': 328,\n",
       " 'ν': 329,\n",
       " 'ι': 330,\n",
       " 'κ': 331,\n",
       " 'ό': 332,\n",
       " 'ς': 333,\n",
       " 'İ': 334,\n",
       " '•': 335,\n",
       " '`': 336,\n",
       " 'Å': 337,\n",
       " 'Α': 338,\n",
       " 'ώ': 339,\n",
       " 'α': 340,\n",
       " 'Τ': 341,\n",
       " 'γ': 342,\n",
       " 'ά': 343,\n",
       " 'Ε': 344,\n",
       " 'δ': 345,\n",
       " 'υ': 346,\n",
       " 'Ι': 347,\n",
       " 'ρ': 348,\n",
       " 'μ': 349,\n",
       " 'Ν': 350,\n",
       " '業': 351,\n",
       " '学': 352,\n",
       " 'Š': 353,\n",
       " 'ë': 354,\n",
       " 'σ': 355,\n",
       " 'β': 356,\n",
       " 'ί': 357,\n",
       " 'ω': 358,\n",
       " 'ć': 359,\n",
       " 'ź': 360,\n",
       " 'â': 361,\n",
       " 'د': 362,\n",
       " 'ر': 363,\n",
       " 'ب': 364,\n",
       " 'ا': 365,\n",
       " '<': 366,\n",
       " '§': 367,\n",
       " '⁄': 368,\n",
       " 'ἀ': 369,\n",
       " 'έ': 370,\n",
       " 'Ç': 371,\n",
       " 'ˌ': 372,\n",
       " 'ɡ': 373,\n",
       " 'ɐ': 374,\n",
       " '̯': 375,\n",
       " 'ʏ': 376,\n",
       " '̩': 377,\n",
       " '…': 378,\n",
       " 'θ': 379,\n",
       " 'ἵ': 380,\n",
       " 'ὀ': 381,\n",
       " 'ξ': 382,\n",
       " '·': 383,\n",
       " 'Χ': 384,\n",
       " 'מ': 385,\n",
       " 'ָ': 386,\n",
       " 'ש': 387,\n",
       " 'ִ': 388,\n",
       " 'ׁ': 389,\n",
       " 'י': 390,\n",
       " 'ח': 391,\n",
       " 'ַ': 392,\n",
       " 'נ': 393,\n",
       " 'ו': 394,\n",
       " 'ּ': 395,\n",
       " 'צ': 396,\n",
       " 'ְ': 397,\n",
       " 'ר': 398,\n",
       " 'ה': 399,\n",
       " 'ד': 400,\n",
       " 'ם': 401,\n",
       " 'ن': 402,\n",
       " 'ص': 403,\n",
       " 'ي': 404,\n",
       " 'ى': 405,\n",
       " 'م': 406,\n",
       " 'س': 407,\n",
       " 'ح': 408,\n",
       " 'Ṣ': 409,\n",
       " 'ل': 410,\n",
       " 'ف': 411,\n",
       " 'ج': 412,\n",
       " 'ّ': 413,\n",
       " 'ة': 414,\n",
       " 'ی': 415,\n",
       " 'ت': 416,\n",
       " 'ई': 417,\n",
       " 'स': 418,\n",
       " 'ع': 419,\n",
       " 'ئ': 420,\n",
       " '\\u200e': 421,\n",
       " '基': 422,\n",
       " '督': 423,\n",
       " '徒': 424,\n",
       " 'ơ': 425,\n",
       " 'đ': 426,\n",
       " 'ố': 427,\n",
       " 'ồ': 428,\n",
       " '吉': 429,\n",
       " '利': 430,\n",
       " '丹': 431,\n",
       " '切': 432,\n",
       " 'キ': 433,\n",
       " 'シ': 434,\n",
       " 'タ': 435,\n",
       " '教': 436,\n",
       " 'ク': 437,\n",
       " 'チ': 438,\n",
       " 'ャ': 439,\n",
       " '기': 440,\n",
       " '독': 441,\n",
       " '교': 442,\n",
       " '도': 443,\n",
       " '그': 444,\n",
       " '리': 445,\n",
       " '스': 446,\n",
       " 'В': 447,\n",
       " 'е': 448,\n",
       " 'л': 449,\n",
       " 'и': 450,\n",
       " 'к': 451,\n",
       " 'о': 452,\n",
       " 'н': 453,\n",
       " 'я': 454,\n",
       " 'ж': 455,\n",
       " 'с': 456,\n",
       " 'т': 457,\n",
       " 'в': 458,\n",
       " 'Р': 459,\n",
       " 'у': 460,\n",
       " 'х': 461,\n",
       " 'р': 462,\n",
       " 'а': 463,\n",
       " 'ь': 464,\n",
       " 'п': 465,\n",
       " 'з': 466,\n",
       " 'й': 467,\n",
       " 'С': 468,\n",
       " 'Ф': 469,\n",
       " 'д': 470,\n",
       " 'ц': 471,\n",
       " 'ч': 472,\n",
       " 'б': 473,\n",
       " 'œ': 474,\n",
       " 'î': 475,\n",
       " 'К': 476,\n",
       " 'м': 477,\n",
       " 'ʰ': 478,\n",
       " '⟨': 479,\n",
       " '◌': 480,\n",
       " '⟩': 481,\n",
       " 'ʻ': 482,\n",
       " '˭': 483,\n",
       " 'ɕ': 484,\n",
       " 'ʂ': 485,\n",
       " 'ʱ': 486,\n",
       " '͡': 487,\n",
       " 'ɢ': 488,\n",
       " 'ᶢ': 489,\n",
       " 'ʘ': 490,\n",
       " 'ǀ': 491,\n",
       " 'ǁ': 492,\n",
       " 'ǃ': 493,\n",
       " 'ǂ': 494,\n",
       " '陽': 495,\n",
       " 'ψ': 496,\n",
       " 'ʷ': 497,\n",
       " 'ð': 498,\n",
       " 'ʔ': 499,\n",
       " 'ɦ': 500,\n",
       " '̤': 501,\n",
       " '♠': 502,\n",
       " 'ὑ': 503,\n",
       " 'ή': 504,\n",
       " '北': 505,\n",
       " '斗': 506,\n",
       " '卫': 507,\n",
       " '星': 508,\n",
       " '导': 509,\n",
       " '航': 510,\n",
       " '系': 511,\n",
       " '统': 512,\n",
       " '衛': 513,\n",
       " '導': 514,\n",
       " '統': 515,\n",
       " 'ě': 516,\n",
       " 'ǒ': 517,\n",
       " 'ǎ': 518,\n",
       " '试': 519,\n",
       " '验': 520,\n",
       " '試': 521,\n",
       " '驗': 522,\n",
       " '_': 523,\n",
       " 'ق': 524,\n",
       " 'و': 525,\n",
       " 'ק': 526,\n",
       " 'ὠ': 527,\n",
       " 'ē': 528,\n",
       " 'Π': 529,\n",
       " 'η': 530,\n",
       " 'ɫ': 531,\n",
       " '∅': 532,\n",
       " 'ˑ': 533,\n",
       " 'õ': 534,\n",
       " 'ž': 535,\n",
       " 'Ä': 536,\n",
       " 'ɤ': 537,\n",
       " 'ъ': 538,\n",
       " '̞': 539,\n",
       " 'ы': 540,\n",
       " 'Х': 541,\n",
       " '×': 542,\n",
       " '′': 543,\n",
       " '南': 544,\n",
       " '京': 545,\n",
       " '江': 546,\n",
       " '寧': 547,\n",
       " '宁': 548,\n",
       " '金': 549,\n",
       " '陵': 550,\n",
       " '冶': 551,\n",
       " '城': 552,\n",
       " '越': 553,\n",
       " '邑': 554,\n",
       " '秣': 555,\n",
       " '康': 556,\n",
       " '昇': 557,\n",
       " '州': 558,\n",
       " '渤': 559,\n",
       " '泥': 560,\n",
       " '天': 561,\n",
       " '下': 562,\n",
       " '淮': 563,\n",
       " '浙': 564,\n",
       " '東': 565,\n",
       " '长': 566,\n",
       " '域': 567,\n",
       " '三': 568,\n",
       " '火': 569,\n",
       " '炉': 570,\n",
       " '鄴': 571,\n",
       " 'א': 572,\n",
       " 'פ': 573,\n",
       " 'ך': 574,\n",
       " 'ז': 575,\n",
       " 'ל': 576,\n",
       " 'ע': 577,\n",
       " 'ט': 578,\n",
       " 'ן': 579,\n",
       " 'ײ': 580,\n",
       " 'ֿ': 581,\n",
       " 'ţ': 582,\n",
       " '̥': 583,\n",
       " '″': 584,\n",
       " '\\ufeff': 585,\n",
       " '´': 586,\n",
       " 'ѣ': 587,\n",
       " 'Σ': 588,\n",
       " 'ῖ': 589,\n",
       " 'ḱ': 590,\n",
       " 'ῆ': 591,\n",
       " '^': 592,\n",
       " 'č': 593,\n",
       " 'ę': 594,\n",
       " 'Б': 595,\n",
       " 'А': 596,\n",
       " 'М': 597,\n",
       " 'Ј': 598,\n",
       " 'Т': 599,\n",
       " 'ș': 600,\n",
       " 'Ž': 601,\n",
       " '̧': 602,\n",
       " 'ļ': 603,\n",
       " 'Á': 604,\n",
       " '̄': 605,\n",
       " 'ė': 606,\n",
       " 'ʒ': 607,\n",
       " 'ᵻ': 608,\n",
       " '→': 609,\n",
       " '‑': 610,\n",
       " '折': 611,\n",
       " '氵': 612,\n",
       " '人': 613,\n",
       " '歌': 614,\n",
       " '女': 615,\n",
       " 'ǚ': 616,\n",
       " '魏': 617,\n",
       " '蜀': 618,\n",
       " '惰': 619,\n",
       " '劇': 620,\n",
       " '上': 621,\n",
       " '有': 622,\n",
       " '堂': 623,\n",
       " '，': 624,\n",
       " '苏': 625,\n",
       " '杭': 626,\n",
       " 'ф': 627,\n",
       " 'Î': 628,\n",
       " 'φ': 629,\n",
       " 'ḗ': 630,\n",
       " 'ı': 631,\n",
       " '₹': 632,\n",
       " '\\u202f': 633,\n",
       " 'Г': 634,\n",
       " 'Δ': 635,\n",
       " 'Є': 636,\n",
       " 'З': 637,\n",
       " 'И': 638,\n",
       " 'إ': 639,\n",
       " 'ʿ': 640,\n",
       " 'û': 641,\n",
       " '♯': 642,\n",
       " 'ת': 643,\n",
       " 'ס': 644,\n",
       " 'ň': 645,\n",
       " 'þ': 646,\n",
       " '₂': 647,\n",
       " 'ą': 648,\n",
       " '₥': 649,\n",
       " 'ታ': 650,\n",
       " 'ላ': 651,\n",
       " 'ሪ': 652,\n",
       " 'ß': 653,\n",
       " 'Æ': 654,\n",
       " 'ƿ': 655,\n",
       " '⁊': 656,\n",
       " 'ċ': 657,\n",
       " 'ġ': 658,\n",
       " 'µ': 659,\n",
       " '\\u2009': 660,\n",
       " '{': 661,\n",
       " '}': 662,\n",
       " '|': 663,\n",
       " 'å': 664,\n",
       " 'ζ': 665,\n",
       " 'ş': 666,\n",
       " 'Μ': 667,\n",
       " 'Θ': 668,\n",
       " 'ῦ': 669,\n",
       " 'Ρ': 670,\n",
       " 'Υ': 671,\n",
       " '@': 672,\n",
       " 'П': 673,\n",
       " '́': 674,\n",
       " 'ш': 675,\n",
       " '̪': 676,\n",
       " 'आ': 677,\n",
       " 'ष': 678,\n",
       " '剎': 679,\n",
       " '那': 680,\n",
       " 'ण': 681,\n",
       " 'ቡ': 682,\n",
       " 'ን': 683,\n",
       " 'ሻ': 684,\n",
       " 'ሂ': 685,\n",
       " 'Ἐ': 686,\n",
       " 'ὰ': 687,\n",
       " 'ἐ': 688,\n",
       " '‚': 689,\n",
       " 'Ô': 690,\n",
       " '›': 691,\n",
       " 'フ': 692,\n",
       " 'ァ': 693,\n",
       " 'ミ': 694,\n",
       " 'ー': 695,\n",
       " 'コ': 696,\n",
       " 'ピ': 697,\n",
       " 'ュ': 698,\n",
       " '현': 699,\n",
       " '대': 700,\n",
       " '컴': 701,\n",
       " '보': 702,\n",
       " '이': 703,\n",
       " '仕': 704,\n",
       " '様': 705,\n",
       " 'Д': 706,\n",
       " '小': 707,\n",
       " '才': 708,\n",
       " 'Ἀ': 709,\n",
       " 'Β': 710,\n",
       " 'ὶ': 711,\n",
       " 'ὸ': 712,\n",
       " 'ÿ': 713,\n",
       " 'ő': 714,\n",
       " 'Ó': 715,\n",
       " 'خ': 716,\n",
       " 'أ': 717,\n",
       " 'ʾ': 718,\n",
       " 'ἄ': 719,\n",
       " 'ׂ': 720,\n",
       " 'ֵ': 721,\n",
       " 'ِ': 722,\n",
       " 'ْ': 723,\n",
       " 'َ': 724,\n",
       " 'ʼ': 725,\n",
       " 'Ἰ': 726,\n",
       " 'ỉ': 727,\n",
       " 'ꜣ': 728,\n",
       " 'Ἑ': 729,\n",
       " 'ﬁ': 730,\n",
       " 'ﬂ': 731,\n",
       " '手': 732,\n",
       " '羽': 733,\n",
       " '先': 734,\n",
       " 'ɣ': 735,\n",
       " '한': 736,\n",
       " '국': 737,\n",
       " '전': 738,\n",
       " '쟁': 739,\n",
       " '韓': 740,\n",
       " '戰': 741,\n",
       " '爭': 742,\n",
       " '해': 743,\n",
       " '방': 744,\n",
       " '抗': 745,\n",
       " '美': 746,\n",
       " '战': 747,\n",
       " '争': 748,\n",
       " '鮮': 749,\n",
       " '韩': 750,\n",
       " 'Γ': 751,\n",
       " 'Λ': 752,\n",
       " 'Κ': 753,\n",
       " 'ù': 754,\n",
       " 'Η': 755,\n",
       " 'Ψ': 756,\n",
       " 'Í': 757,\n",
       " '福': 758,\n",
       " '話': 759,\n",
       " '话': 760,\n",
       " '̍': 761,\n",
       " '˥': 762,\n",
       " '˨': 763,\n",
       " '˩': 764,\n",
       " '泉': 765,\n",
       " '漳': 766,\n",
       " '片': 767,\n",
       " '閩': 768,\n",
       " '語': 769,\n",
       " '闽': 770,\n",
       " '语': 771,\n",
       " 'ǐ': 772,\n",
       " 'ǔ': 773,\n",
       " '佬': 774,\n",
       " '陳': 775,\n",
       " '政': 776,\n",
       " '光': 777,\n",
       " '潮': 778,\n",
       " '審': 779,\n",
       " '知': 780,\n",
       " '竹': 781,\n",
       " '文': 782,\n",
       " '白': 783,\n",
       " '異': 784,\n",
       " '讀': 785,\n",
       " '音': 786,\n",
       " '漢': 787,\n",
       " '字': 788,\n",
       " '替': 789,\n",
       " '媠': 790,\n",
       " '婎': 791,\n",
       " '高': 792,\n",
       " '懸': 793,\n",
       " '毋': 794,\n",
       " '呣': 795,\n",
       " '唔': 796,\n",
       " '𪜶': 797,\n",
       " '肉': 798,\n",
       " '呷': 799,\n",
       " '食': 800,\n",
       " '言': 801,\n",
       " '普': 802,\n",
       " '通': 803,\n",
       " '詞': 804,\n",
       " '典': 805,\n",
       " 'Ú': 806,\n",
       " 'ロ': 807,\n",
       " 'レ': 808,\n",
       " '¡': 809,\n",
       " '√': 810,\n",
       " 'Ć': 811,\n",
       " 'г': 812,\n",
       " '예': 813,\n",
       " '수': 814,\n",
       " '장': 815,\n",
       " '로': 816,\n",
       " '회': 817,\n",
       " '고': 818,\n",
       " '려': 819,\n",
       " '파': 820,\n",
       " '신': 821,\n",
       " '통': 822,\n",
       " '합': 823,\n",
       " '동': 824,\n",
       " 'Ḥ': 825,\n",
       " '¿': 826,\n",
       " 'န': 827,\n",
       " 'ာ': 828,\n",
       " 'း': 829,\n",
       " 'သ': 830,\n",
       " 'ه': 831,\n",
       " 'ُ': 832,\n",
       " 'Е': 833,\n",
       " 'Ď': 834,\n",
       " 'ɥ': 835,\n",
       " 'ț': 836,\n",
       " 'Ẓ': 837,\n",
       " 'ء': 838,\n",
       " 'ك': 839,\n",
       " 'ش': 840,\n",
       " '汉': 841,\n",
       " 'ữ': 842,\n",
       " '河': 843,\n",
       " '湖': 844,\n",
       " '沖': 845,\n",
       " '滑': 846,\n",
       " 'ŋ': 847,\n",
       " '中': 848,\n",
       " '蝴': 849,\n",
       " '蝶': 850,\n",
       " '虫': 851,\n",
       " '批': 852,\n",
       " '把': 853,\n",
       " '枇': 854,\n",
       " '杷': 855,\n",
       " '琵': 856,\n",
       " '琶': 857,\n",
       " '八': 858,\n",
       " '分': 859,\n",
       " '章': 860,\n",
       " '草': 861,\n",
       " '隶': 862,\n",
       " '隸': 863,\n",
       " '今': 864,\n",
       " '頓': 865,\n",
       " '顿': 866,\n",
       " '松': 867,\n",
       " '木': 868,\n",
       " '粁': 869,\n",
       " '米': 870,\n",
       " '千': 871,\n",
       " '㓾': 872,\n",
       " '常': 873,\n",
       " '用': 874,\n",
       " '標': 875,\n",
       " '準': 876,\n",
       " '體': 877,\n",
       " '表': 878,\n",
       " '次': 879,\n",
       " '现': 880,\n",
       " '代': 881,\n",
       " '平': 882,\n",
       " '考': 883,\n",
       " '他': 884,\n",
       " '她': 885,\n",
       " '牠': 886,\n",
       " '它': 887,\n",
       " '祂': 888,\n",
       " '和': 889,\n",
       " '咊': 890,\n",
       " '龢': 891,\n",
       " '齉': 892,\n",
       " '龘': 893,\n",
       " '籲': 894,\n",
       " '鬱': 895,\n",
       " '憂': 896,\n",
       " '豔': 897,\n",
       " '釁': 898,\n",
       " '挑': 899,\n",
       " '鱻': 900,\n",
       " '𪚥': 901,\n",
       " '龍': 902,\n",
       " '𠔻': 903,\n",
       " '興': 904,\n",
       " '受': 905,\n",
       " '又': 906,\n",
       " '祐': 907,\n",
       " '菩': 908,\n",
       " '薩': 909,\n",
       " '萨': 910,\n",
       " '十': 911,\n",
       " '厘': 912,\n",
       " '瓦': 913,\n",
       " '瓩': 914,\n",
       " '糎': 915,\n",
       " '圕': 916,\n",
       " '圖': 917,\n",
       " '書': 918,\n",
       " '館': 919,\n",
       " '社': 920,\n",
       " '会': 921,\n",
       " '主': 922,\n",
       " '义': 923,\n",
       " '礻': 924,\n",
       " '囍': 925,\n",
       " '喜': 926,\n",
       " '双': 927,\n",
       " '雙': 928,\n",
       " '廿': 929,\n",
       " '二': 930,\n",
       " '卅': 931,\n",
       " '卌': 932,\n",
       " '四': 933,\n",
       " '七': 934,\n",
       " '门': 935,\n",
       " '問': 936,\n",
       " '題': 937,\n",
       " '问': 938,\n",
       " '题': 939,\n",
       " '合': 940,\n",
       " '体': 941,\n",
       " '节': 942,\n",
       " '節': 943,\n",
       " '珊': 944,\n",
       " '瑚': 945,\n",
       " '胡': 946,\n",
       " '块': 947,\n",
       " '塊': 948,\n",
       " '篆': 949,\n",
       " '新': 950,\n",
       " '旧': 951,\n",
       " '当': 952,\n",
       " 'た': 953,\n",
       " 'つ': 954,\n",
       " '竜': 955,\n",
       " '來': 956,\n",
       " '来': 957,\n",
       " '雲': 958,\n",
       " '云': 959,\n",
       " '雨': 960,\n",
       " '叠': 961,\n",
       " '覆': 962,\n",
       " '像': 963,\n",
       " '물': 964,\n",
       " '사': 965,\n",
       " '람': 966,\n",
       " '인': 967,\n",
       " '큰': 968,\n",
       " '작': 969,\n",
       " '을': 970,\n",
       " '소': 971,\n",
       " '아': 972,\n",
       " '래': 973,\n",
       " '하': 974,\n",
       " '비': 975,\n",
       " '부': 976,\n",
       " '父': 977,\n",
       " '나': 978,\n",
       " '라': 979,\n",
       " '름': 980,\n",
       " '风': 981,\n",
       " '动': 982,\n",
       " '仪': 983,\n",
       " 'デ': 984,\n",
       " 'ジ': 985,\n",
       " 'モ': 986,\n",
       " 'マ': 987,\n",
       " 'メ': 988,\n",
       " '˚': 989,\n",
       " '妹': 990,\n",
       " '仔': 991,\n",
       " '時': 992,\n",
       " '都': 993,\n",
       " '院': 994,\n",
       " '庁': 995,\n",
       " 'い': 996,\n",
       " 'ろ': 997,\n",
       " 'は': 998,\n",
       " '良': 999,\n",
       " 'Н': 1000,\n",
       " 'ņ': 1001,\n",
       " ...}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "011710ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train examples to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130319it [00:48, 2709.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 129900 / 130319 instances of features in total\n",
      "Converting dev examples to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6078it [00:02, 2476.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 5951 / 6078 instances of features in total\n"
     ]
    }
   ],
   "source": [
    "build_features(train_examples, \"train\",'./train.npz', word2idx_dict, char2idx_dict)\n",
    "dev_meta = build_features(dev_examples, \"dev\",'./dev.npz', word2idx_dict, char2idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91495bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train10k = random_choice_K(10000,train_examples)\n",
    "train20k = random_choice_K(20000,train_examples)\n",
    "train30k = random_choice_K(30000,train_examples)\n",
    "train40k = random_choice_K(40000,train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c584870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train examples to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "249it [00:00, 2476.77it/s]\u001b[A\n",
      "515it [00:00, 2576.19it/s]\u001b[A\n",
      "804it [00:00, 2711.57it/s]\u001b[A\n",
      "1106it [00:00, 2825.83it/s]\u001b[A\n",
      "1389it [00:00, 2791.76it/s]\u001b[A\n",
      "1677it [00:00, 2820.75it/s]\u001b[A\n",
      "1960it [00:00, 2764.97it/s]\u001b[A\n",
      "2237it [00:00, 2753.19it/s]\u001b[A\n",
      "2513it [00:00, 2557.90it/s]\u001b[A\n",
      "2772it [00:01, 2480.18it/s]\u001b[A\n",
      "3022it [00:01, 2429.42it/s]\u001b[A\n",
      "3267it [00:01, 2303.61it/s]\u001b[A\n",
      "3499it [00:01, 2248.54it/s]\u001b[A\n",
      "3728it [00:01, 2256.79it/s]\u001b[A\n",
      "3957it [00:01, 2261.72it/s]\u001b[A\n",
      "4184it [00:01, 2160.94it/s]\u001b[A\n",
      "4402it [00:01, 2028.59it/s]\u001b[A\n",
      "4607it [00:01, 1869.87it/s]\u001b[A\n",
      "4816it [00:02, 1927.04it/s]\u001b[A\n",
      "5030it [00:02, 1984.63it/s]\u001b[A\n",
      "5268it [00:02, 2092.88it/s]\u001b[A\n",
      "5480it [00:02, 2097.49it/s]\u001b[A\n",
      "5719it [00:02, 2179.45it/s]\u001b[A\n",
      "5996it [00:02, 2350.67it/s]\u001b[A\n",
      "6270it [00:02, 2461.34it/s]\u001b[A\n",
      "6518it [00:02, 2465.38it/s]\u001b[A\n",
      "6766it [00:02, 2144.35it/s]\u001b[A\n",
      "7019it [00:03, 2247.81it/s]\u001b[A\n",
      "7279it [00:03, 2342.70it/s]\u001b[A\n",
      "7519it [00:03, 2258.11it/s]\u001b[A\n",
      "7754it [00:03, 2280.34it/s]\u001b[A\n",
      "8030it [00:03, 2413.58it/s]\u001b[A\n",
      "8324it [00:03, 2561.29it/s]\u001b[A\n",
      "8583it [00:03, 2479.02it/s]\u001b[A\n",
      "8834it [00:03, 2252.00it/s]\u001b[A\n",
      "9070it [00:03, 2278.07it/s]\u001b[A\n",
      "9302it [00:03, 2213.10it/s]\u001b[A\n",
      "9527it [00:04, 2207.81it/s]\u001b[A\n",
      "9771it [00:04, 2272.51it/s]\u001b[A\n",
      "10000it [00:04, 2322.61it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 9967 / 10000 instances of features in total\n",
      "Converting train examples to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "273it [00:00, 2715.76it/s]\u001b[A\n",
      "545it [00:00, 2617.91it/s]\u001b[A\n",
      "808it [00:00, 2363.29it/s]\u001b[A\n",
      "1071it [00:00, 2455.02it/s]\u001b[A\n",
      "1319it [00:00, 2335.15it/s]\u001b[A\n",
      "1555it [00:00, 2316.40it/s]\u001b[A\n",
      "1829it [00:00, 2443.27it/s]\u001b[A\n",
      "2088it [00:00, 2487.64it/s]\u001b[A\n",
      "2338it [00:00, 2282.77it/s]\u001b[A\n",
      "2580it [00:01, 2318.12it/s]\u001b[A\n",
      "2855it [00:01, 2438.90it/s]\u001b[A\n",
      "3142it [00:01, 2560.43it/s]\u001b[A\n",
      "3429it [00:01, 2646.72it/s]\u001b[A\n",
      "3696it [00:01, 2457.34it/s]\u001b[A\n",
      "3946it [00:01, 2460.73it/s]\u001b[A\n",
      "4223it [00:01, 2547.41it/s]\u001b[A\n",
      "4481it [00:01, 2362.78it/s]\u001b[A\n",
      "4722it [00:01, 2339.37it/s]\u001b[A\n",
      "4983it [00:02, 2410.98it/s]\u001b[A\n",
      "5242it [00:02, 2458.32it/s]\u001b[A\n",
      "5495it [00:02, 2475.30it/s]\u001b[A\n",
      "5744it [00:02, 2297.79it/s]\u001b[A\n",
      "5986it [00:02, 2328.25it/s]\u001b[A\n",
      "6241it [00:02, 2387.93it/s]\u001b[A\n",
      "6510it [00:02, 2473.67it/s]\u001b[A\n",
      "6763it [00:02, 2489.65it/s]\u001b[A\n",
      "7014it [00:02, 2342.07it/s]\u001b[A\n",
      "7268it [00:03, 2394.51it/s]\u001b[A\n",
      "7510it [00:03, 2357.51it/s]\u001b[A\n",
      "7748it [00:03, 2349.30it/s]\u001b[A\n",
      "8000it [00:03, 2394.88it/s]\u001b[A\n",
      "8247it [00:03, 2412.86it/s]\u001b[A\n",
      "8489it [00:03, 2383.70it/s]\u001b[A\n",
      "8745it [00:03, 2431.56it/s]\u001b[A\n",
      "8989it [00:03, 2419.45it/s]\u001b[A\n",
      "9232it [00:03, 2392.24it/s]\u001b[A\n",
      "9472it [00:03, 2366.33it/s]\u001b[A\n",
      "9709it [00:04, 2351.87it/s]\u001b[A\n",
      "9945it [00:04, 2166.88it/s]\u001b[A\n",
      "10165it [00:04, 2102.67it/s]\u001b[A\n",
      "10378it [00:04, 2061.46it/s]\u001b[A\n",
      "10586it [00:04, 2052.18it/s]\u001b[A\n",
      "10793it [00:04, 2045.00it/s]\u001b[A\n",
      "11004it [00:04, 2062.87it/s]\u001b[A\n",
      "11211it [00:04, 2045.95it/s]\u001b[A\n",
      "11416it [00:04, 2008.74it/s]\u001b[A\n",
      "11618it [00:05, 1963.52it/s]\u001b[A\n",
      "11842it [00:05, 2041.49it/s]\u001b[A\n",
      "12079it [00:05, 2134.67it/s]\u001b[A\n",
      "12299it [00:05, 2150.59it/s]\u001b[A\n",
      "12525it [00:05, 2179.48it/s]\u001b[A\n",
      "12756it [00:05, 2214.45it/s]\u001b[A\n",
      "12990it [00:05, 2248.67it/s]\u001b[A\n",
      "13216it [00:05, 2215.33it/s]\u001b[A\n",
      "13457it [00:05, 2269.15it/s]\u001b[A\n",
      "13685it [00:05, 2242.40it/s]\u001b[A\n",
      "13910it [00:06, 2236.63it/s]\u001b[A\n",
      "14142it [00:06, 2260.14it/s]\u001b[A\n",
      "14369it [00:06, 2262.44it/s]\u001b[A\n",
      "14610it [00:06, 2302.60it/s]\u001b[A\n",
      "14844it [00:06, 2309.73it/s]\u001b[A\n",
      "15085it [00:06, 2338.83it/s]\u001b[A\n",
      "15324it [00:06, 2352.52it/s]\u001b[A\n",
      "15569it [00:06, 2381.10it/s]\u001b[A\n",
      "15817it [00:06, 2410.34it/s]\u001b[A\n",
      "16065it [00:06, 2423.67it/s]\u001b[A\n",
      "16314it [00:07, 2443.38it/s]\u001b[A\n",
      "16562it [00:07, 2453.65it/s]\u001b[A\n",
      "16808it [00:07, 2390.80it/s]\u001b[A\n",
      "17048it [00:07, 2338.14it/s]\u001b[A\n",
      "17283it [00:07, 2326.16it/s]\u001b[A\n",
      "17516it [00:07, 2326.31it/s]\u001b[A\n",
      "17757it [00:07, 2347.32it/s]\u001b[A\n",
      "18002it [00:07, 2373.69it/s]\u001b[A\n",
      "18240it [00:07, 2346.58it/s]\u001b[A\n",
      "18475it [00:07, 2326.46it/s]\u001b[A\n",
      "18712it [00:08, 2338.12it/s]\u001b[A\n",
      "18955it [00:08, 2362.91it/s]\u001b[A\n",
      "19195it [00:08, 2370.09it/s]\u001b[A\n",
      "19433it [00:08, 2358.60it/s]\u001b[A\n",
      "19683it [00:08, 2398.03it/s]\u001b[A\n",
      "20000it [00:08, 2327.80it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 19942 / 20000 instances of features in total\n",
      "Converting train examples to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "270it [00:00, 2684.93it/s]\u001b[A\n",
      "539it [00:00, 2663.26it/s]\u001b[A\n",
      "815it [00:00, 2700.23it/s]\u001b[A\n",
      "1086it [00:00, 2625.55it/s]\u001b[A\n",
      "1384it [00:00, 2745.38it/s]\u001b[A\n",
      "1702it [00:00, 2887.90it/s]\u001b[A\n",
      "1992it [00:00, 2867.58it/s]\u001b[A\n",
      "2280it [00:00, 2796.28it/s]\u001b[A\n",
      "2563it [00:00, 2801.87it/s]\u001b[A\n",
      "2844it [00:01, 2783.22it/s]\u001b[A\n",
      "3123it [00:01, 2727.53it/s]\u001b[A\n",
      "3399it [00:01, 2732.87it/s]\u001b[A\n",
      "3683it [00:01, 2762.36it/s]\u001b[A\n",
      "3961it [00:01, 2767.07it/s]\u001b[A\n",
      "4238it [00:01, 2766.83it/s]\u001b[A\n",
      "4515it [00:01, 2763.79it/s]\u001b[A\n",
      "4792it [00:01, 2658.09it/s]\u001b[A\n",
      "5062it [00:01, 2666.10it/s]\u001b[A\n",
      "5330it [00:01, 2660.25it/s]\u001b[A\n",
      "5597it [00:02, 2659.58it/s]\u001b[A\n",
      "5864it [00:02, 2642.38it/s]\u001b[A\n",
      "6129it [00:02, 2601.32it/s]\u001b[A\n",
      "6403it [00:02, 2637.86it/s]\u001b[A\n",
      "6681it [00:02, 2679.18it/s]\u001b[A\n",
      "6950it [00:02, 2624.52it/s]\u001b[A\n",
      "7213it [00:02, 2606.79it/s]\u001b[A\n",
      "7478it [00:02, 2619.18it/s]\u001b[A\n",
      "7745it [00:02, 2630.15it/s]\u001b[A\n",
      "8011it [00:02, 2634.76it/s]\u001b[A\n",
      "8293it [00:03, 2688.83it/s]\u001b[A\n",
      "8577it [00:03, 2728.96it/s]\u001b[A\n",
      "8869it [00:03, 2781.52it/s]\u001b[A\n",
      "9151it [00:03, 2789.30it/s]\u001b[A\n",
      "9430it [00:03, 2736.17it/s]\u001b[A\n",
      "9704it [00:03, 2733.03it/s]\u001b[A\n",
      "9978it [00:03, 2722.52it/s]\u001b[A\n",
      "10255it [00:03, 2735.06it/s]\u001b[A\n",
      "10529it [00:03, 2678.96it/s]\u001b[A\n",
      "10798it [00:03, 2665.83it/s]\u001b[A\n",
      "11065it [00:04, 2662.88it/s]\u001b[A\n",
      "11339it [00:04, 2680.89it/s]\u001b[A\n",
      "11608it [00:04, 2656.18it/s]\u001b[A\n",
      "11878it [00:04, 2664.85it/s]\u001b[A\n",
      "12145it [00:04, 2563.61it/s]\u001b[A\n",
      "12403it [00:04, 2506.46it/s]\u001b[A\n",
      "12655it [00:04, 2478.17it/s]\u001b[A\n",
      "12904it [00:04, 2367.86it/s]\u001b[A\n",
      "13142it [00:04, 2348.53it/s]\u001b[A\n",
      "13378it [00:05, 2308.78it/s]\u001b[A\n",
      "13611it [00:05, 2312.67it/s]\u001b[A\n",
      "13847it [00:05, 2322.72it/s]\u001b[A\n",
      "14080it [00:05, 2321.25it/s]\u001b[A\n",
      "14313it [00:05, 2266.76it/s]\u001b[A\n",
      "14541it [00:05, 2215.62it/s]\u001b[A\n",
      "14774it [00:05, 2248.20it/s]\u001b[A\n",
      "15017it [00:05, 2297.52it/s]\u001b[A\n",
      "15248it [00:05, 2034.98it/s]\u001b[A\n",
      "15458it [00:06, 2016.92it/s]\u001b[A\n",
      "15664it [00:06, 1992.83it/s]\u001b[A\n",
      "15866it [00:06, 1874.23it/s]\u001b[A\n",
      "16057it [00:06, 1873.31it/s]\u001b[A\n",
      "16255it [00:06, 1894.64it/s]\u001b[A\n",
      "16446it [00:06, 1869.35it/s]\u001b[A\n",
      "16634it [00:06, 1861.26it/s]\u001b[A\n",
      "16821it [00:06, 1829.33it/s]\u001b[A\n",
      "17005it [00:06, 1406.66it/s]\u001b[A\n",
      "17161it [00:07, 1279.31it/s]\u001b[A\n",
      "17351it [00:07, 1423.56it/s]\u001b[A\n",
      "17559it [00:07, 1587.13it/s]\u001b[A\n",
      "17730it [00:07, 1470.94it/s]\u001b[A\n",
      "17887it [00:07, 1456.19it/s]\u001b[A\n",
      "18043it [00:07, 1483.19it/s]\u001b[A\n",
      "18197it [00:07, 1362.93it/s]\u001b[A\n",
      "18339it [00:07, 1333.07it/s]\u001b[A\n",
      "18476it [00:08, 1285.18it/s]\u001b[A\n",
      "18616it [00:08, 1315.58it/s]\u001b[A\n",
      "18769it [00:08, 1371.21it/s]\u001b[A\n",
      "18919it [00:08, 1406.87it/s]\u001b[A\n",
      "19093it [00:08, 1498.92it/s]\u001b[A\n",
      "19245it [00:08, 1429.38it/s]\u001b[A\n",
      "19390it [00:08, 1349.91it/s]\u001b[A\n",
      "19532it [00:08, 1367.58it/s]\u001b[A\n",
      "19679it [00:08, 1394.89it/s]\u001b[A\n",
      "19820it [00:08, 1392.67it/s]\u001b[A\n",
      "19973it [00:09, 1429.99it/s]\u001b[A\n",
      "20128it [00:09, 1463.51it/s]\u001b[A\n",
      "20275it [00:09, 1284.07it/s]\u001b[A\n",
      "20437it [00:09, 1370.99it/s]\u001b[A\n",
      "20591it [00:09, 1410.26it/s]\u001b[A\n",
      "20745it [00:09, 1446.27it/s]\u001b[A\n",
      "20892it [00:09, 1445.96it/s]\u001b[A\n",
      "21039it [00:09, 1452.88it/s]\u001b[A\n",
      "21202it [00:09, 1500.74it/s]\u001b[A\n",
      "21353it [00:10, 1362.04it/s]\u001b[A\n",
      "21493it [00:10, 1339.12it/s]\u001b[A\n",
      "21640it [00:10, 1372.44it/s]\u001b[A\n",
      "21779it [00:10, 1279.49it/s]\u001b[A\n",
      "21910it [00:10, 1270.10it/s]\u001b[A\n",
      "22066it [00:10, 1350.16it/s]\u001b[A\n",
      "22226it [00:10, 1420.48it/s]\u001b[A\n",
      "22375it [00:10, 1436.62it/s]\u001b[A\n",
      "22532it [00:10, 1470.10it/s]\u001b[A\n",
      "22688it [00:11, 1493.05it/s]\u001b[A\n",
      "22851it [00:11, 1529.52it/s]\u001b[A\n",
      "23033it [00:11, 1612.54it/s]\u001b[A\n",
      "23195it [00:11, 1537.87it/s]\u001b[A\n",
      "23350it [00:11, 1512.79it/s]\u001b[A\n",
      "23502it [00:11, 1502.83it/s]\u001b[A\n",
      "23653it [00:11, 1490.87it/s]\u001b[A\n",
      "23803it [00:11, 1464.27it/s]\u001b[A\n",
      "23958it [00:11, 1487.26it/s]\u001b[A\n",
      "24129it [00:11, 1551.87it/s]\u001b[A\n",
      "24285it [00:12, 1529.21it/s]\u001b[A\n",
      "24439it [00:12, 1294.15it/s]\u001b[A\n",
      "24613it [00:12, 1408.94it/s]\u001b[A\n",
      "24777it [00:12, 1471.61it/s]\u001b[A\n",
      "24944it [00:12, 1524.97it/s]\u001b[A\n",
      "25108it [00:12, 1556.21it/s]\u001b[A\n",
      "25267it [00:12, 1493.60it/s]\u001b[A\n",
      "25446it [00:12, 1573.31it/s]\u001b[A\n",
      "25606it [00:12, 1562.68it/s]\u001b[A\n",
      "25764it [00:13, 1514.95it/s]\u001b[A\n",
      "25919it [00:13, 1520.56it/s]\u001b[A\n",
      "26097it [00:13, 1591.60it/s]\u001b[A\n",
      "26263it [00:13, 1610.07it/s]\u001b[A\n",
      "26433it [00:13, 1636.12it/s]\u001b[A\n",
      "26598it [00:13, 1637.60it/s]\u001b[A\n",
      "26763it [00:13, 1583.54it/s]\u001b[A\n",
      "26922it [00:13, 1564.42it/s]\u001b[A\n",
      "27095it [00:13, 1612.12it/s]\u001b[A\n",
      "27268it [00:13, 1645.57it/s]\u001b[A\n",
      "27433it [00:14, 1628.21it/s]\u001b[A\n",
      "27617it [00:14, 1687.30it/s]\u001b[A\n",
      "27794it [00:14, 1707.33it/s]\u001b[A\n",
      "28011it [00:14, 1840.28it/s]\u001b[A\n",
      "28237it [00:14, 1960.22it/s]\u001b[A\n",
      "28434it [00:14, 1958.24it/s]\u001b[A\n",
      "28673it [00:14, 2081.41it/s]\u001b[A\n",
      "28882it [00:14, 1989.26it/s]\u001b[A\n",
      "29082it [00:14, 1907.87it/s]\u001b[A\n",
      "29274it [00:15, 1791.96it/s]\u001b[A\n",
      "29455it [00:15, 1750.02it/s]\u001b[A\n",
      "29637it [00:15, 1767.17it/s]\u001b[A\n",
      "29815it [00:15, 1721.67it/s]\u001b[A\n",
      "30000it [00:15, 1937.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 29906 / 30000 instances of features in total\n",
      "Converting train examples to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "306it [00:00, 3041.05it/s]\u001b[A\n",
      "611it [00:00, 2573.65it/s]\u001b[A\n",
      "906it [00:00, 2720.67it/s]\u001b[A\n",
      "1203it [00:00, 2809.76it/s]\u001b[A\n",
      "1496it [00:00, 2842.64it/s]\u001b[A\n",
      "1805it [00:00, 2921.70it/s]\u001b[A\n",
      "2099it [00:00, 1969.55it/s]\u001b[A\n",
      "2363it [00:00, 2124.35it/s]\u001b[A\n",
      "2637it [00:01, 2277.37it/s]\u001b[A\n",
      "2906it [00:01, 2383.80it/s]\u001b[A\n",
      "3199it [00:01, 2532.12it/s]\u001b[A\n",
      "3492it [00:01, 2639.37it/s]\u001b[A\n",
      "3768it [00:01, 2636.23it/s]\u001b[A\n",
      "4066it [00:01, 2729.41it/s]\u001b[A\n",
      "4345it [00:01, 2721.45it/s]\u001b[A\n",
      "4622it [00:01, 2735.22it/s]\u001b[A\n",
      "4899it [00:01, 2484.30it/s]\u001b[A\n",
      "5154it [00:02, 2063.56it/s]\u001b[A\n",
      "5439it [00:02, 2254.31it/s]\u001b[A\n",
      "5730it [00:02, 2420.30it/s]\u001b[A\n",
      "6021it [00:02, 2551.74it/s]\u001b[A\n",
      "6310it [00:02, 2641.46it/s]\u001b[A\n",
      "6602it [00:02, 2712.45it/s]\u001b[A\n",
      "6882it [00:02, 2737.64it/s]\u001b[A\n",
      "7161it [00:02, 2736.89it/s]\u001b[A\n",
      "7448it [00:02, 2770.31it/s]\u001b[A\n",
      "7728it [00:03, 2588.13it/s]\u001b[A\n",
      "7999it [00:03, 2615.27it/s]\u001b[A\n",
      "8279it [00:03, 2664.91it/s]\u001b[A\n",
      "8548it [00:03, 2665.06it/s]\u001b[A\n",
      "8837it [00:03, 2728.65it/s]\u001b[A\n",
      "9112it [00:03, 2733.06it/s]\u001b[A\n",
      "9391it [00:03, 2746.97it/s]\u001b[A\n",
      "9673it [00:03, 2767.28it/s]\u001b[A\n",
      "9951it [00:03, 2756.63it/s]\u001b[A\n",
      "10227it [00:03, 2746.87it/s]\u001b[A\n",
      "10502it [00:04, 2733.62it/s]\u001b[A\n",
      "10781it [00:04, 2747.81it/s]\u001b[A\n",
      "11063it [00:04, 2764.17it/s]\u001b[A\n",
      "11347it [00:04, 2778.58it/s]\u001b[A\n",
      "11633it [00:04, 2796.24it/s]\u001b[A\n",
      "11913it [00:04, 2791.63it/s]\u001b[A\n",
      "12193it [00:04, 2787.40it/s]\u001b[A\n",
      "12472it [00:04, 2755.24it/s]\u001b[A\n",
      "12754it [00:04, 2767.41it/s]\u001b[A\n",
      "13031it [00:04, 2757.16it/s]\u001b[A\n",
      "13307it [00:05, 2739.08it/s]\u001b[A\n",
      "13581it [00:05, 2675.67it/s]\u001b[A\n",
      "13849it [00:05, 2664.42it/s]\u001b[A\n",
      "14133it [00:05, 2711.19it/s]\u001b[A\n",
      "14415it [00:05, 2733.90it/s]\u001b[A\n",
      "14689it [00:05, 2710.11it/s]\u001b[A\n",
      "14965it [00:05, 2719.84it/s]\u001b[A\n",
      "15238it [00:05, 2716.10it/s]\u001b[A\n",
      "15517it [00:05, 2732.07it/s]\u001b[A\n",
      "15793it [00:05, 2733.58it/s]\u001b[A\n",
      "16072it [00:06, 2745.13it/s]\u001b[A\n",
      "16347it [00:06, 2700.71it/s]\u001b[A\n",
      "16619it [00:06, 2704.36it/s]\u001b[A\n",
      "16897it [00:06, 2719.81it/s]\u001b[A\n",
      "17176it [00:06, 2736.72it/s]\u001b[A\n",
      "17450it [00:06, 2623.39it/s]\u001b[A\n",
      "17722it [00:06, 2641.64it/s]\u001b[A\n",
      "17990it [00:06, 2650.37it/s]\u001b[A\n",
      "18271it [00:06, 2689.23it/s]\u001b[A\n",
      "18541it [00:07, 2689.07it/s]\u001b[A\n",
      "18816it [00:07, 2706.46it/s]\u001b[A\n",
      "19087it [00:07, 2677.16it/s]\u001b[A\n",
      "19355it [00:07, 2656.82it/s]\u001b[A\n",
      "19621it [00:07, 2181.48it/s]\u001b[A\n",
      "19853it [00:07, 2191.07it/s]\u001b[A\n",
      "20091it [00:07, 2241.12it/s]\u001b[A\n",
      "20323it [00:07, 2259.19it/s]\u001b[A\n",
      "20558it [00:07, 2282.63it/s]\u001b[A\n",
      "20791it [00:07, 2281.11it/s]\u001b[A\n",
      "21037it [00:08, 2332.02it/s]\u001b[A\n",
      "21273it [00:08, 2317.63it/s]\u001b[A\n",
      "21507it [00:08, 2162.79it/s]\u001b[A\n",
      "21755it [00:08, 2249.34it/s]\u001b[A\n",
      "21983it [00:08, 2254.61it/s]\u001b[A\n",
      "22211it [00:08, 1942.60it/s]\u001b[A\n",
      "22460it [00:08, 2082.71it/s]\u001b[A\n",
      "22705it [00:08, 2179.17it/s]\u001b[A\n",
      "22944it [00:08, 2237.65it/s]\u001b[A\n",
      "23205it [00:09, 2339.54it/s]\u001b[A\n",
      "23483it [00:09, 2465.09it/s]\u001b[A\n",
      "23733it [00:09, 2473.97it/s]\u001b[A\n",
      "23983it [00:09, 2468.14it/s]\u001b[A\n",
      "24232it [00:09, 2465.07it/s]\u001b[A\n",
      "24480it [00:09, 2464.70it/s]\u001b[A\n",
      "24729it [00:09, 2458.41it/s]\u001b[A\n",
      "24976it [00:09, 2040.67it/s]\u001b[A\n",
      "25217it [00:09, 2135.51it/s]\u001b[A\n",
      "25441it [00:10, 2147.14it/s]\u001b[A\n",
      "25663it [00:10, 2112.19it/s]\u001b[A\n",
      "25880it [00:10, 2096.05it/s]\u001b[A\n",
      "26097it [00:10, 2114.08it/s]\u001b[A\n",
      "26326it [00:10, 2160.53it/s]\u001b[A\n",
      "26579it [00:10, 2263.60it/s]\u001b[A\n",
      "26808it [00:10, 2260.99it/s]\u001b[A\n",
      "27036it [00:10, 2200.59it/s]\u001b[A\n",
      "27258it [00:10, 1988.16it/s]\u001b[A\n",
      "27462it [00:11, 1805.31it/s]\u001b[A\n",
      "27672it [00:11, 1879.97it/s]\u001b[A\n",
      "27883it [00:11, 1939.87it/s]\u001b[A\n",
      "28086it [00:11, 1964.13it/s]\u001b[A\n",
      "28286it [00:11, 1974.09it/s]\u001b[A\n",
      "28486it [00:11, 1923.69it/s]\u001b[A\n",
      "28690it [00:11, 1952.97it/s]\u001b[A\n",
      "28903it [00:11, 2004.11it/s]\u001b[A\n",
      "29105it [00:11, 1942.46it/s]\u001b[A\n",
      "29340it [00:11, 2058.28it/s]\u001b[A\n",
      "29548it [00:12, 1992.97it/s]\u001b[A\n",
      "29749it [00:12, 1903.40it/s]\u001b[A\n",
      "29944it [00:12, 1915.71it/s]\u001b[A\n",
      "30144it [00:12, 1937.89it/s]\u001b[A\n",
      "30352it [00:12, 1974.02it/s]\u001b[A\n",
      "30556it [00:12, 1993.22it/s]\u001b[A\n",
      "30806it [00:12, 2138.28it/s]\u001b[A\n",
      "31072it [00:12, 2290.12it/s]\u001b[A\n",
      "31360it [00:12, 2460.00it/s]\u001b[A\n",
      "31644it [00:13, 2572.81it/s]\u001b[A\n",
      "31935it [00:13, 2666.08it/s]\u001b[A\n",
      "32202it [00:13, 2665.67it/s]\u001b[A\n",
      "32482it [00:13, 2704.86it/s]\u001b[A\n",
      "32759it [00:13, 2718.17it/s]\u001b[A\n",
      "33031it [00:13, 2691.83it/s]\u001b[A\n",
      "33301it [00:13, 2666.89it/s]\u001b[A\n",
      "33568it [00:13, 2619.90it/s]\u001b[A\n",
      "33831it [00:13, 2574.59it/s]\u001b[A\n",
      "34089it [00:13, 2546.98it/s]\u001b[A\n",
      "34344it [00:14, 2312.61it/s]\u001b[A\n",
      "34600it [00:14, 2380.09it/s]\u001b[A\n",
      "34842it [00:14, 2379.59it/s]\u001b[A\n",
      "35083it [00:14, 2372.93it/s]\u001b[A\n",
      "35332it [00:14, 2405.49it/s]\u001b[A\n",
      "35574it [00:14, 2371.56it/s]\u001b[A\n",
      "35813it [00:14, 2290.58it/s]\u001b[A\n",
      "36052it [00:14, 2318.55it/s]\u001b[A\n",
      "36311it [00:14, 2396.74it/s]\u001b[A\n",
      "36566it [00:15, 2435.85it/s]\u001b[A\n",
      "36834it [00:15, 2504.94it/s]\u001b[A\n",
      "37093it [00:15, 2523.85it/s]\u001b[A\n",
      "37346it [00:15, 2512.83it/s]\u001b[A\n",
      "37598it [00:15, 2447.36it/s]\u001b[A\n",
      "37844it [00:15, 2422.41it/s]\u001b[A\n",
      "38087it [00:15, 2402.05it/s]\u001b[A\n",
      "38340it [00:15, 2432.98it/s]\u001b[A\n",
      "38587it [00:15, 2441.84it/s]\u001b[A\n",
      "38850it [00:15, 2491.56it/s]\u001b[A\n",
      "39101it [00:16, 2494.69it/s]\u001b[A\n",
      "39355it [00:16, 2505.35it/s]\u001b[A\n",
      "39606it [00:16, 2492.37it/s]\u001b[A\n",
      "40000it [00:16, 2439.47it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 39879 / 40000 instances of features in total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 39879}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_features(train10k, \"train\",'./train10k.npz', word2idx_dict, char2idx_dict)\n",
    "build_features(train20k, \"train\",'./train20k.npz', word2idx_dict, char2idx_dict)\n",
    "build_features(train30k, \"train\",'./train30k.npz', word2idx_dict, char2idx_dict)\n",
    "build_features(train40k, \"train\",'./train40k.npz', word2idx_dict, char2idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b687c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev10k = random_choice_K(10000,dev_examples)\n",
    "dev20k = random_choice_K(20000,dev_examples)\n",
    "dev30k = random_choice_K(30000,dev_examples)\n",
    "dev40k = random_choice_K(40000,dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca8d4605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting dev examples to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "247it [00:00, 2455.86it/s]\u001b[A\n",
      "493it [00:00, 2369.31it/s]\u001b[A\n",
      "739it [00:00, 2392.52it/s]\u001b[A\n",
      "1014it [00:00, 2524.96it/s]\u001b[A\n",
      "1297it [00:00, 2632.39it/s]\u001b[A\n",
      "1584it [00:00, 2707.81it/s]\u001b[A\n",
      "1865it [00:00, 2736.46it/s]\u001b[A\n",
      "2141it [00:00, 2739.48it/s]\u001b[A\n",
      "2416it [00:00, 2738.37it/s]\u001b[A\n",
      "2690it [00:01, 2652.52it/s]\u001b[A\n",
      "2956it [00:01, 2645.05it/s]\u001b[A\n",
      "3242it [00:01, 2704.87it/s]\u001b[A\n",
      "3521it [00:01, 2726.09it/s]\u001b[A\n",
      "3796it [00:01, 2729.04it/s]\u001b[A\n",
      "4070it [00:01, 2711.25it/s]\u001b[A\n",
      "4342it [00:01, 2642.63it/s]\u001b[A\n",
      "4619it [00:01, 2675.80it/s]\u001b[A\n",
      "4898it [00:01, 2704.31it/s]\u001b[A\n",
      "5169it [00:01, 2654.97it/s]\u001b[A\n",
      "5435it [00:02, 2582.53it/s]\u001b[A\n",
      "5694it [00:02, 2543.82it/s]\u001b[A\n",
      "5949it [00:02, 2541.82it/s]\u001b[A\n",
      "6204it [00:02, 2540.31it/s]\u001b[A\n",
      "6459it [00:02, 2539.04it/s]\u001b[A\n",
      "6714it [00:02, 2514.97it/s]\u001b[A\n",
      "6973it [00:02, 2533.57it/s]\u001b[A\n",
      "7251it [00:02, 2602.30it/s]\u001b[A\n",
      "7512it [00:02, 2584.30it/s]\u001b[A\n",
      "7772it [00:02, 2585.09it/s]\u001b[A\n",
      "8036it [00:03, 2597.45it/s]\u001b[A\n",
      "8319it [00:03, 2661.59it/s]\u001b[A\n",
      "8587it [00:03, 2662.80it/s]\u001b[A\n",
      "8854it [00:03, 2365.17it/s]\u001b[A\n",
      "9097it [00:03, 2165.74it/s]\u001b[A\n",
      "9321it [00:03, 2151.25it/s]\u001b[A\n",
      "9541it [00:03, 2078.83it/s]\u001b[A\n",
      "10000it [00:03, 2524.67it/s][A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 9779 / 10000 instances of features in total\n",
      "Converting dev examples to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "180it [00:00, 1795.52it/s]\u001b[A\n",
      "369it [00:00, 1849.58it/s]\u001b[A\n",
      "561it [00:00, 1877.33it/s]\u001b[A\n",
      "749it [00:00, 1783.01it/s]\u001b[A\n",
      "928it [00:00, 1740.32it/s]\u001b[A\n",
      "1114it [00:00, 1776.25it/s]\u001b[A\n",
      "1293it [00:00, 1676.64it/s]\u001b[A\n",
      "1514it [00:00, 1833.22it/s]\u001b[A\n",
      "1700it [00:00, 1780.01it/s]\u001b[A\n",
      "1880it [00:01, 1772.67it/s]\u001b[A\n",
      "2059it [00:01, 1683.74it/s]\u001b[A\n",
      "2245it [00:01, 1726.28it/s]\u001b[A\n",
      "2447it [00:01, 1808.07it/s]\u001b[A\n",
      "2657it [00:01, 1891.15it/s]\u001b[A\n",
      "2868it [00:01, 1952.06it/s]\u001b[A\n",
      "3114it [00:01, 2098.55it/s]\u001b[A\n",
      "3372it [00:01, 2238.88it/s]\u001b[A\n",
      "3646it [00:01, 2387.61it/s]\u001b[A\n",
      "3912it [00:01, 2468.09it/s]\u001b[A\n",
      "4195it [00:02, 2571.86it/s]\u001b[A\n",
      "4469it [00:02, 2617.14it/s]\u001b[A\n",
      "4746it [00:02, 2660.17it/s]\u001b[A\n",
      "5030it [00:02, 2709.59it/s]\u001b[A\n",
      "5302it [00:02, 2709.77it/s]\u001b[A\n",
      "5588it [00:02, 2750.01it/s]\u001b[A\n",
      "5864it [00:02, 2627.04it/s]\u001b[A\n",
      "6128it [00:02, 2587.74it/s]\u001b[A\n",
      "6388it [00:02, 2566.37it/s]\u001b[A\n",
      "6646it [00:03, 2154.89it/s]\u001b[A\n",
      "6873it [00:03, 1965.73it/s]\u001b[A\n",
      "7080it [00:03, 1890.19it/s]\u001b[A\n",
      "7329it [00:03, 2038.90it/s]\u001b[A\n",
      "7578it [00:03, 2154.85it/s]\u001b[A\n",
      "7816it [00:03, 2214.48it/s]\u001b[A\n",
      "8078it [00:03, 2325.00it/s]\u001b[A\n",
      "8335it [00:03, 2391.41it/s]\u001b[A\n",
      "8578it [00:03, 2364.60it/s]\u001b[A\n",
      "8817it [00:04, 2368.16it/s]\u001b[A\n",
      "9076it [00:04, 2428.58it/s]\u001b[A\n",
      "9343it [00:04, 2495.66it/s]\u001b[A\n",
      "9604it [00:04, 2525.54it/s]\u001b[A\n",
      "9858it [00:04, 2024.75it/s]\u001b[A\n",
      "10077it [00:04, 1819.78it/s]\u001b[A\n",
      "10289it [00:04, 1889.94it/s]\u001b[A\n",
      "10506it [00:04, 1959.13it/s]\u001b[A\n",
      "10712it [00:04, 1983.93it/s]\u001b[A\n",
      "10918it [00:05, 1945.49it/s]\u001b[A\n",
      "11133it [00:05, 1998.75it/s]\u001b[A\n",
      "11346it [00:05, 2032.48it/s]\u001b[A\n",
      "11552it [00:05, 1905.82it/s]\u001b[A\n",
      "11773it [00:05, 1987.30it/s]\u001b[A\n",
      "12012it [00:05, 2098.20it/s]\u001b[A\n",
      "12246it [00:05, 2164.45it/s]\u001b[A\n",
      "12507it [00:05, 2290.15it/s]\u001b[A\n",
      "12742it [00:05, 2304.37it/s]\u001b[A\n",
      "12981it [00:06, 2325.80it/s]\u001b[A\n",
      "13260it [00:06, 2458.43it/s]\u001b[A\n",
      "13533it [00:06, 2534.68it/s]\u001b[A\n",
      "13788it [00:06, 2450.36it/s]\u001b[A\n",
      "14035it [00:06, 2427.22it/s]\u001b[A\n",
      "14279it [00:06, 2359.59it/s]\u001b[A\n",
      "14516it [00:06, 2305.86it/s]\u001b[A\n",
      "14760it [00:06, 2340.79it/s]\u001b[A\n",
      "14995it [00:06, 2339.80it/s]\u001b[A\n",
      "15230it [00:06, 2319.75it/s]\u001b[A\n",
      "15471it [00:07, 2342.85it/s]\u001b[A\n",
      "15716it [00:07, 2370.65it/s]\u001b[A\n",
      "15954it [00:07, 2342.02it/s]\u001b[A\n",
      "16191it [00:07, 2346.59it/s]\u001b[A\n",
      "16436it [00:07, 2373.23it/s]\u001b[A\n",
      "16674it [00:07, 2374.20it/s]\u001b[A\n",
      "16912it [00:07, 2351.22it/s]\u001b[A\n",
      "17148it [00:07, 2282.45it/s]\u001b[A\n",
      "17377it [00:07, 2248.27it/s]\u001b[A\n",
      "17621it [00:07, 2300.36it/s]\u001b[A\n",
      "17852it [00:08, 2285.32it/s]\u001b[A\n",
      "18086it [00:08, 2297.79it/s]\u001b[A\n",
      "18316it [00:08, 2254.74it/s]\u001b[A\n",
      "18542it [00:08, 2195.49it/s]\u001b[A\n",
      "18789it [00:08, 2271.13it/s]\u001b[A\n",
      "19043it [00:08, 2345.41it/s]\u001b[A\n",
      "19288it [00:08, 2374.11it/s]\u001b[A\n",
      "19533it [00:08, 2392.82it/s]\u001b[A\n",
      "20000it [00:09, 2216.79it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 19597 / 20000 instances of features in total\n",
      "Converting dev examples to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "224it [00:00, 2226.31it/s]\u001b[A\n",
      "478it [00:00, 2403.89it/s]\u001b[A\n",
      "737it [00:00, 2487.43it/s]\u001b[A\n",
      "1008it [00:00, 2569.20it/s]\u001b[A\n",
      "1275it [00:00, 2600.35it/s]\u001b[A\n",
      "1563it [00:00, 2690.51it/s]\u001b[A\n",
      "1833it [00:00, 2654.28it/s]\u001b[A\n",
      "2099it [00:00, 2645.62it/s]\u001b[A\n",
      "2388it [00:00, 2720.71it/s]\u001b[A\n",
      "2669it [00:01, 2743.42it/s]\u001b[A\n",
      "2944it [00:01, 2540.43it/s]\u001b[A\n",
      "3218it [00:01, 2597.23it/s]\u001b[A\n",
      "3504it [00:01, 2669.38it/s]\u001b[A\n",
      "3789it [00:01, 2717.16it/s]\u001b[A\n",
      "4063it [00:01, 2533.35it/s]\u001b[A\n",
      "4331it [00:01, 2569.92it/s]\u001b[A\n",
      "4609it [00:01, 2625.76it/s]\u001b[A\n",
      "4887it [00:01, 2666.38it/s]\u001b[A\n",
      "5166it [00:01, 2700.40it/s]\u001b[A\n",
      "5445it [00:02, 2720.37it/s]\u001b[A\n",
      "5718it [00:02, 2633.47it/s]\u001b[A\n",
      "5983it [00:02, 2406.80it/s]\u001b[A\n",
      "6230it [00:02, 2420.77it/s]\u001b[A\n",
      "6476it [00:02, 2274.72it/s]\u001b[A\n",
      "6707it [00:02, 2216.43it/s]\u001b[A\n",
      "6931it [00:02, 2174.63it/s]\u001b[A\n",
      "7150it [00:02, 1839.50it/s]\u001b[A\n",
      "7343it [00:03, 1210.83it/s]\u001b[A\n",
      "7566it [00:03, 1401.90it/s]\u001b[A\n",
      "7788it [00:03, 1573.76it/s]\u001b[A\n",
      "7993it [00:03, 1683.64it/s]\u001b[A\n",
      "8186it [00:03, 1627.01it/s]\u001b[A\n",
      "8366it [00:03, 1655.17it/s]\u001b[A\n",
      "8556it [00:03, 1716.66it/s]\u001b[A\n",
      "8786it [00:03, 1871.59it/s]\u001b[A\n",
      "9051it [00:04, 2085.17it/s]\u001b[A\n",
      "9335it [00:04, 2295.82it/s]\u001b[A\n",
      "9577it [00:04, 2327.67it/s]\u001b[A\n",
      "9815it [00:04, 2206.98it/s]\u001b[A\n",
      "10056it [00:04, 2263.50it/s]\u001b[A\n",
      "10319it [00:04, 2366.39it/s]\u001b[A\n",
      "10589it [00:04, 2458.98it/s]\u001b[A\n",
      "10874it [00:04, 2571.74it/s]\u001b[A\n",
      "11162it [00:04, 2658.01it/s]\u001b[A\n",
      "11451it [00:04, 2721.68it/s]\u001b[A\n",
      "11725it [00:05, 2714.44it/s]\u001b[A\n",
      "11998it [00:05, 2074.92it/s]\u001b[A\n",
      "12229it [00:05, 1904.04it/s]\u001b[A\n",
      "12437it [00:05, 1655.78it/s]\u001b[A\n",
      "12630it [00:05, 1715.16it/s]\u001b[A\n",
      "12869it [00:05, 1878.24it/s]\u001b[A\n",
      "13070it [00:05, 1700.18it/s]\u001b[A\n",
      "13332it [00:06, 1924.21it/s]\u001b[A\n",
      "13596it [00:06, 2107.34it/s]\u001b[A\n",
      "13861it [00:06, 2250.28it/s]\u001b[A\n",
      "14150it [00:06, 2424.77it/s]\u001b[A\n",
      "14401it [00:06, 2007.86it/s]\u001b[A\n",
      "14619it [00:06, 1986.19it/s]\u001b[A\n",
      "14846it [00:06, 2056.37it/s]\u001b[A\n",
      "15072it [00:06, 2108.08it/s]\u001b[A\n",
      "15312it [00:06, 2184.96it/s]\u001b[A\n",
      "15537it [00:07, 2053.70it/s]\u001b[A\n",
      "15748it [00:07, 2001.72it/s]\u001b[A\n",
      "16042it [00:07, 2255.87it/s]\u001b[A\n",
      "16328it [00:07, 2420.40it/s]\u001b[A\n",
      "16603it [00:07, 2510.14it/s]\u001b[A\n",
      "16878it [00:07, 2579.24it/s]\u001b[A\n",
      "17160it [00:07, 2645.33it/s]\u001b[A\n",
      "17427it [00:07, 2565.59it/s]\u001b[A\n",
      "17686it [00:08, 2093.91it/s]\u001b[A\n",
      "17911it [00:08, 2028.40it/s]\u001b[A\n",
      "18173it [00:08, 2176.32it/s]\u001b[A\n",
      "18441it [00:08, 2306.66it/s]\u001b[A\n",
      "18709it [00:08, 2406.23it/s]\u001b[A\n",
      "18960it [00:08, 2431.95it/s]\u001b[A\n",
      "19209it [00:08, 2410.37it/s]\u001b[A\n",
      "19466it [00:08, 2454.38it/s]\u001b[A\n",
      "19714it [00:08, 2182.69it/s]\u001b[A\n",
      "19940it [00:08, 2067.09it/s]\u001b[A\n",
      "20153it [00:09, 1951.72it/s]\u001b[A\n",
      "20353it [00:09, 1854.94it/s]\u001b[A\n",
      "20563it [00:09, 1916.05it/s]\u001b[A\n",
      "20779it [00:09, 1979.41it/s]\u001b[A\n",
      "21017it [00:09, 2087.80it/s]\u001b[A\n",
      "21267it [00:09, 2201.97it/s]\u001b[A\n",
      "21490it [00:09, 2175.29it/s]\u001b[A\n",
      "21710it [00:09, 2114.90it/s]\u001b[A\n",
      "21923it [00:09, 2109.95it/s]\u001b[A\n",
      "22135it [00:10, 2091.53it/s]\u001b[A\n",
      "22345it [00:10, 2054.84it/s]\u001b[A\n",
      "22588it [00:10, 2159.22it/s]\u001b[A\n",
      "22838it [00:10, 2258.13it/s]\u001b[A\n",
      "23105it [00:10, 2375.02it/s]\u001b[A\n",
      "23375it [00:10, 2467.23it/s]\u001b[A\n",
      "23651it [00:10, 2548.88it/s]\u001b[A\n",
      "23934it [00:10, 2627.62it/s]\u001b[A\n",
      "24215it [00:10, 2680.79it/s]\u001b[A\n",
      "24484it [00:11, 2344.27it/s]\u001b[A\n",
      "24727it [00:11, 2191.92it/s]\u001b[A\n",
      "24971it [00:11, 2251.23it/s]\u001b[A\n",
      "25209it [00:11, 2283.43it/s]\u001b[A\n",
      "25442it [00:11, 2260.68it/s]\u001b[A\n",
      "25671it [00:11, 1956.22it/s]\u001b[A\n",
      "25876it [00:11, 1967.39it/s]\u001b[A\n",
      "26119it [00:11, 2088.55it/s]\u001b[A\n",
      "26361it [00:11, 2177.21it/s]\u001b[A\n",
      "26598it [00:12, 2228.42it/s]\u001b[A\n",
      "26825it [00:12, 2199.16it/s]\u001b[A\n",
      "27057it [00:12, 2230.49it/s]\u001b[A\n",
      "27302it [00:12, 2290.76it/s]\u001b[A\n",
      "27554it [00:12, 2354.31it/s]\u001b[A\n",
      "27791it [00:12, 2263.88it/s]\u001b[A\n",
      "28030it [00:12, 2296.33it/s]\u001b[A\n",
      "28285it [00:12, 2366.37it/s]\u001b[A\n",
      "28539it [00:12, 2413.49it/s]\u001b[A\n",
      "28794it [00:12, 2449.94it/s]\u001b[A\n",
      "29041it [00:13, 2451.57it/s]\u001b[A\n",
      "29287it [00:13, 2421.52it/s]\u001b[A\n",
      "29540it [00:13, 2452.99it/s]\u001b[A\n",
      "30000it [00:13, 2228.45it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 29356 / 30000 instances of features in total\n",
      "Converting dev examples to indices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "243it [00:00, 2414.90it/s]\u001b[A\n",
      "523it [00:00, 2632.94it/s]\u001b[A\n",
      "799it [00:00, 2684.52it/s]\u001b[A\n",
      "1094it [00:00, 2782.26it/s]\u001b[A\n",
      "1373it [00:00, 2780.01it/s]\u001b[A\n",
      "1652it [00:00, 2698.10it/s]\u001b[A\n",
      "1923it [00:00, 2412.48it/s]\u001b[A\n",
      "2170it [00:00, 2404.69it/s]\u001b[A\n",
      "2428it [00:00, 2451.92it/s]\u001b[A\n",
      "2676it [00:01, 2413.86it/s]\u001b[A\n",
      "2922it [00:01, 2423.58it/s]\u001b[A\n",
      "3184it [00:01, 2477.22it/s]\u001b[A\n",
      "3454it [00:01, 2538.76it/s]\u001b[A\n",
      "3715it [00:01, 2555.64it/s]\u001b[A\n",
      "4006it [00:01, 2656.35it/s]\u001b[A\n",
      "4277it [00:01, 2671.22it/s]\u001b[A\n",
      "4545it [00:01, 2653.74it/s]\u001b[A\n",
      "4820it [00:01, 2677.81it/s]\u001b[A\n",
      "5090it [00:01, 2680.24it/s]\u001b[A\n",
      "5359it [00:02, 2662.30it/s]\u001b[A\n",
      "5626it [00:02, 2514.52it/s]\u001b[A\n",
      "5880it [00:02, 2221.50it/s]\u001b[A\n",
      "6117it [00:02, 2257.68it/s]\u001b[A\n",
      "6400it [00:02, 2411.18it/s]\u001b[A\n",
      "6659it [00:02, 2457.89it/s]\u001b[A\n",
      "6909it [00:02, 2207.34it/s]\u001b[A\n",
      "7137it [00:02, 2171.89it/s]\u001b[A\n",
      "7409it [00:02, 2317.27it/s]\u001b[A\n",
      "7673it [00:03, 2403.14it/s]\u001b[A\n",
      "7954it [00:03, 2515.19it/s]\u001b[A\n",
      "8229it [00:03, 2579.27it/s]\u001b[A\n",
      "8490it [00:03, 2524.59it/s]\u001b[A\n",
      "8751it [00:03, 2545.42it/s]\u001b[A\n",
      "9014it [00:03, 2566.29it/s]\u001b[A\n",
      "9287it [00:03, 2610.50it/s]\u001b[A\n",
      "9559it [00:03, 2638.86it/s]\u001b[A\n",
      "9841it [00:03, 2687.12it/s]\u001b[A\n",
      "10111it [00:04, 2456.34it/s]\u001b[A\n",
      "10361it [00:04, 2440.72it/s]\u001b[A\n",
      "10608it [00:04, 2197.12it/s]\u001b[A\n",
      "10879it [00:04, 2330.34it/s]\u001b[A\n",
      "11165it [00:04, 2472.59it/s]\u001b[A\n",
      "11418it [00:04, 2471.22it/s]\u001b[A\n",
      "11674it [00:04, 2492.94it/s]\u001b[A\n",
      "11940it [00:04, 2537.34it/s]\u001b[A\n",
      "12206it [00:04, 2564.90it/s]\u001b[A\n",
      "12464it [00:05, 2254.40it/s]\u001b[A\n",
      "12698it [00:05, 1992.88it/s]\u001b[A\n",
      "12907it [00:05, 2009.65it/s]\u001b[A\n",
      "13152it [00:05, 2122.86it/s]\u001b[A\n",
      "13371it [00:05, 2048.74it/s]\u001b[A\n",
      "13581it [00:05, 2032.20it/s]\u001b[A\n",
      "13797it [00:05, 2064.61it/s]\u001b[A\n",
      "14013it [00:05, 2088.59it/s]\u001b[A\n",
      "14261it [00:05, 2197.93it/s]\u001b[A\n",
      "14483it [00:06, 2163.31it/s]\u001b[A\n",
      "14726it [00:06, 2237.27it/s]\u001b[A\n",
      "14963it [00:06, 2272.65it/s]\u001b[A\n",
      "15192it [00:06, 2160.00it/s]\u001b[A\n",
      "15410it [00:06, 1703.00it/s]\u001b[A\n",
      "15653it [00:06, 1876.86it/s]\u001b[A\n",
      "15893it [00:06, 2008.61it/s]\u001b[A\n",
      "16167it [00:06, 2201.62it/s]\u001b[A\n",
      "16420it [00:06, 2289.26it/s]\u001b[A\n",
      "16658it [00:07, 2250.77it/s]\u001b[A\n",
      "16889it [00:07, 1929.55it/s]\u001b[A\n",
      "17094it [00:07, 1928.20it/s]\u001b[A\n",
      "17319it [00:07, 2010.46it/s]\u001b[A\n",
      "17527it [00:07, 2021.11it/s]\u001b[A\n",
      "17744it [00:07, 2059.90it/s]\u001b[A\n",
      "18002it [00:07, 2205.26it/s]\u001b[A\n",
      "18226it [00:07, 2051.81it/s]\u001b[A\n",
      "18436it [00:07, 1868.92it/s]\u001b[A\n",
      "18680it [00:08, 2017.56it/s]\u001b[A\n",
      "18942it [00:08, 2180.27it/s]\u001b[A\n",
      "19194it [00:08, 2272.22it/s]\u001b[A\n",
      "19456it [00:08, 2368.11it/s]\u001b[A\n",
      "19701it [00:08, 2388.13it/s]\u001b[A\n",
      "19943it [00:08, 2258.26it/s]\u001b[A\n",
      "20188it [00:08, 2309.19it/s]\u001b[A\n",
      "20452it [00:08, 2399.46it/s]\u001b[A\n",
      "20717it [00:08, 2467.92it/s]\u001b[A\n",
      "20966it [00:09, 2420.43it/s]\u001b[A\n",
      "21211it [00:09, 2425.15it/s]\u001b[A\n",
      "21478it [00:09, 2493.44it/s]\u001b[A\n",
      "21740it [00:09, 2526.94it/s]\u001b[A\n",
      "21994it [00:09, 2526.98it/s]\u001b[A\n",
      "22254it [00:09, 2544.56it/s]\u001b[A\n",
      "22525it [00:09, 2589.77it/s]\u001b[A\n",
      "22785it [00:09, 2580.58it/s]\u001b[A\n",
      "23066it [00:09, 2643.52it/s]\u001b[A\n",
      "23337it [00:09, 2658.90it/s]\u001b[A\n",
      "23610it [00:10, 2676.02it/s]\u001b[A\n",
      "23882it [00:10, 2685.04it/s]\u001b[A\n",
      "24152it [00:10, 2685.42it/s]\u001b[A\n",
      "24421it [00:10, 2658.55it/s]\u001b[A\n",
      "24687it [00:10, 2265.12it/s]\u001b[A\n",
      "24924it [00:10, 2160.36it/s]\u001b[A\n",
      "25148it [00:10, 2058.98it/s]\u001b[A\n",
      "25360it [00:10, 2050.26it/s]\u001b[A\n",
      "25569it [00:10, 2026.71it/s]\u001b[A\n",
      "25775it [00:11, 1942.25it/s]\u001b[A\n",
      "25995it [00:11, 2009.57it/s]\u001b[A\n",
      "26198it [00:11, 1830.38it/s]\u001b[A\n",
      "26385it [00:11, 1751.47it/s]\u001b[A\n",
      "26563it [00:11, 1708.32it/s]\u001b[A\n",
      "26789it [00:11, 1854.40it/s]\u001b[A\n",
      "26985it [00:11, 1880.74it/s]\u001b[A\n",
      "27227it [00:11, 2030.78it/s]\u001b[A\n",
      "27433it [00:11, 1879.26it/s]\u001b[A\n",
      "27625it [00:12, 1852.18it/s]\u001b[A\n",
      "27845it [00:12, 1946.04it/s]\u001b[A\n",
      "28109it [00:12, 2139.41it/s]\u001b[A\n",
      "28370it [00:12, 2271.53it/s]\u001b[A\n",
      "28640it [00:12, 2393.50it/s]\u001b[A\n",
      "28905it [00:12, 2465.15it/s]\u001b[A\n",
      "29179it [00:12, 2542.44it/s]\u001b[A\n",
      "29448it [00:12, 2581.99it/s]\u001b[A\n",
      "29719it [00:12, 2618.05it/s]\u001b[A\n",
      "29982it [00:12, 2556.57it/s]\u001b[A\n",
      "30266it [00:13, 2635.72it/s]\u001b[A\n",
      "30537it [00:13, 2655.59it/s]\u001b[A\n",
      "30810it [00:13, 2673.61it/s]\u001b[A\n",
      "31078it [00:13, 2609.16it/s]\u001b[A\n",
      "31341it [00:13, 2614.42it/s]\u001b[A\n",
      "31616it [00:13, 2649.99it/s]\u001b[A\n",
      "31882it [00:13, 2621.70it/s]\u001b[A\n",
      "32150it [00:13, 2634.91it/s]\u001b[A\n",
      "32416it [00:13, 2638.25it/s]\u001b[A\n",
      "32691it [00:13, 2667.31it/s]\u001b[A\n",
      "32976it [00:14, 2717.36it/s]\u001b[A\n",
      "33248it [00:14, 2634.31it/s]\u001b[A\n",
      "33514it [00:14, 2638.00it/s]\u001b[A\n",
      "33779it [00:14, 2621.99it/s]\u001b[A\n",
      "34052it [00:14, 2648.81it/s]\u001b[A\n",
      "34318it [00:14, 2521.15it/s]\u001b[A\n",
      "34572it [00:14, 2521.64it/s]\u001b[A\n",
      "34851it [00:14, 2595.92it/s]\u001b[A\n",
      "35120it [00:14, 2618.24it/s]\u001b[A\n",
      "35392it [00:15, 2643.59it/s]\u001b[A\n",
      "35657it [00:15, 2553.00it/s]\u001b[A\n",
      "35914it [00:15, 2503.31it/s]\u001b[A\n",
      "36166it [00:15, 2434.25it/s]\u001b[A\n",
      "36428it [00:15, 2485.21it/s]\u001b[A\n",
      "36678it [00:15, 2388.84it/s]\u001b[A\n",
      "36918it [00:15, 2233.18it/s]\u001b[A\n",
      "37144it [00:15, 2219.12it/s]\u001b[A\n",
      "37368it [00:15, 2198.92it/s]\u001b[A\n",
      "37589it [00:16, 2168.46it/s]\u001b[A\n",
      "37813it [00:16, 2185.42it/s]\u001b[A\n",
      "38033it [00:16, 2169.52it/s]\u001b[A\n",
      "38259it [00:16, 2192.55it/s]\u001b[A\n",
      "38521it [00:16, 2313.93it/s]\u001b[A\n",
      "38769it [00:16, 2360.33it/s]\u001b[A\n",
      "39039it [00:16, 2457.15it/s]\u001b[A\n",
      "39286it [00:16, 2287.56it/s]\u001b[A\n",
      "39518it [00:16, 2045.09it/s]\u001b[A\n",
      "39766it [00:16, 2157.20it/s]\u001b[A\n",
      "40000it [00:17, 2340.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 39167 / 40000 instances of features in total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total': 39167}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_features(dev10k, \"dev\",'./dev10k.npz', word2idx_dict, char2idx_dict)\n",
    "build_features(dev20k, \"dev\",'./dev20k.npz', word2idx_dict, char2idx_dict)\n",
    "build_features(dev30k, \"dev\",'./dev30k.npz', word2idx_dict, char2idx_dict)\n",
    "build_features(dev40k, \"dev\",'./dev40k.npz', word2idx_dict, char2idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4d895a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130319"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9539642b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6078"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19943d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Train a model on SQuAD [-h] [--train_record_file TRAIN_RECORD_FILE]\n",
      "                              [--dev_record_file DEV_RECORD_FILE]\n",
      "                              [--test_record_file TEST_RECORD_FILE]\n",
      "                              [--word_emb_file WORD_EMB_FILE]\n",
      "                              [--char_emb_file CHAR_EMB_FILE]\n",
      "                              [--train_eval_file TRAIN_EVAL_FILE]\n",
      "                              [--dev_eval_file DEV_EVAL_FILE]\n",
      "                              [--test_eval_file TEST_EVAL_FILE] --name NAME\n",
      "                              [--max_ans_len MAX_ANS_LEN]\n",
      "                              [--num_workers NUM_WORKERS]\n",
      "                              [--save_dir SAVE_DIR] [--batch_size BATCH_SIZE]\n",
      "                              [--use_squad_v2 USE_SQUAD_V2]\n",
      "                              [--hidden_size HIDDEN_SIZE]\n",
      "                              [--num_visuals NUM_VISUALS]\n",
      "                              [--load_path LOAD_PATH]\n",
      "                              [--eval_steps EVAL_STEPS] [--lr LR]\n",
      "                              [--l2_wd L2_WD] [--num_epochs NUM_EPOCHS]\n",
      "                              [--drop_prob DROP_PROB]\n",
      "                              [--metric_name {NLL,EM,F1}]\n",
      "                              [--max_checkpoints MAX_CHECKPOINTS]\n",
      "                              [--max_grad_norm MAX_GRAD_NORM] [--seed SEED]\n",
      "                              [--ema_decay EMA_DECAY]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --train_record_file TRAIN_RECORD_FILE\n",
      "  --dev_record_file DEV_RECORD_FILE\n",
      "  --test_record_file TEST_RECORD_FILE\n",
      "  --word_emb_file WORD_EMB_FILE\n",
      "  --char_emb_file CHAR_EMB_FILE\n",
      "  --train_eval_file TRAIN_EVAL_FILE\n",
      "  --dev_eval_file DEV_EVAL_FILE\n",
      "  --test_eval_file TEST_EVAL_FILE\n",
      "  --name NAME, -n NAME  Name to identify training or test run.\n",
      "  --max_ans_len MAX_ANS_LEN\n",
      "                        Maximum length of a predicted answer.\n",
      "  --num_workers NUM_WORKERS\n",
      "                        Number of sub-processes to use per data loader.\n",
      "  --save_dir SAVE_DIR   Base directory for saving information.\n",
      "  --batch_size BATCH_SIZE\n",
      "                        Batch size per GPU. Scales automatically when multiple\n",
      "                        GPUs are available.\n",
      "  --use_squad_v2 USE_SQUAD_V2\n",
      "                        Whether to use SQuAD 2.0 (unanswerable) questions.\n",
      "  --hidden_size HIDDEN_SIZE\n",
      "                        Number of features in encoder hidden layers.\n",
      "  --num_visuals NUM_VISUALS\n",
      "                        Number of examples to visualize in TensorBoard.\n",
      "  --load_path LOAD_PATH\n",
      "                        Path to load as a model checkpoint.\n",
      "  --eval_steps EVAL_STEPS\n",
      "                        Number of steps between successive evaluations.\n",
      "  --lr LR               Learning rate.\n",
      "  --l2_wd L2_WD         L2 weight decay.\n",
      "  --num_epochs NUM_EPOCHS\n",
      "                        Number of epochs for which to train. Negative means\n",
      "                        forever.\n",
      "  --drop_prob DROP_PROB\n",
      "                        Probability of zeroing an activation in dropout\n",
      "                        layers.\n",
      "  --metric_name {NLL,EM,F1}\n",
      "                        Name of dev metric to determine best checkpoint.\n",
      "  --max_checkpoints MAX_CHECKPOINTS\n",
      "                        Maximum number of checkpoints to keep on disk.\n",
      "  --max_grad_norm MAX_GRAD_NORM\n",
      "                        Maximum gradient norm for gradient clipping.\n",
      "  --seed SEED           Random seed for reproducibility.\n",
      "  --ema_decay EMA_DECAY\n",
      "                        Decay rate for exponential moving average of\n",
      "                        parameters.\n"
     ]
    }
   ],
   "source": [
    "!python train.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d0a0e744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train.py -n baseline --train_record_file ./train10k.npz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
